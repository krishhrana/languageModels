{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0OQVdtmF0VS",
        "outputId": "3c2a4559-981f-414f-e517-1c71935992c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-04 16:57:41--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2023-10-04 16:57:42 (23.8 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchsummaryX wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7qKK114cKQi",
        "outputId": "0d1ed6be-7016-47ba-a7b8-eaffb13cad0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchsummaryX\n",
            "  Downloading torchsummaryX-1.3.0-py3-none-any.whl (3.6 kB)\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.15.11-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchsummaryX) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchsummaryX) (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from torchsummaryX) (1.5.3)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.37-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.0/190.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.31.0-py2.py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.8/224.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Collecting pathtools (from wandb)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->torchsummaryX) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->torchsummaryX) (2023.3.post1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchsummaryX) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchsummaryX) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchsummaryX) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchsummaryX) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchsummaryX) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchsummaryX) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchsummaryX) (3.27.5)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchsummaryX) (17.0.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchsummaryX) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchsummaryX) (1.3.0)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=0fd5de308ae320a3f56dbcdac7c1d82335c72f162bcabcf941f3eccfb279e851\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb, torchsummaryX\n",
            "Successfully installed GitPython-3.1.37 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.31.0 setproctitle-1.3.3 smmap-5.0.1 torchsummaryX-1.3.0 wandb-0.15.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipk92L2tEDKB",
        "outputId": "dbb3300b-245e-4fab-b647-3b412435ebb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vNgc2JFotW2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import wandb\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "aPOCSCdc8m63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('input.txt', 'r') as f:\n",
        "    text = f.read()\n",
        "\n",
        "print(len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3-KGlKJF-Sq",
        "outputId": "3caaa144-0de3-45f5-944c-e5eee5851405"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1115394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = sorted(list(set(text)))\n",
        "vocab_size = len(vocabulary)\n",
        "print(vocabulary)\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1Gu_xIHGHen",
        "outputId": "3ff94f7c-f7fb-4ec0-f1fa-c8145d8ada60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_to_int = {v:i for i, v in enumerate(vocabulary)}\n",
        "int_to_vocab = {i:v for i, v in enumerate(vocabulary)}\n",
        "\n",
        "encode = lambda x: [vocab_to_int[i] for i in x]\n",
        "decode = lambda x: \"\".join([int_to_vocab[i] for i in x])\n",
        "\n",
        "enc_text = \"Hi there!\"\n",
        "enc = encode(enc_text)\n",
        "dec = decode(enc)\n",
        "print(enc)\n",
        "print(dec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b82YdqnFGX7I",
        "outputId": "7271fb61-832b-44a5-eb4e-bd7b3fcdc7aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20, 47, 1, 58, 46, 43, 56, 43, 2]\n",
            "Hi there!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decode([20, 47, 1, 58, 46, 43, 56, 43, 2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "B0HRWqZWota-",
        "outputId": "fd1b7f4b-3518-4eda-8b69-4b67cda64e37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hi there!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = torch.tensor(encode(text), dtype = torch.long)\n",
        "train_data = dataset[:int(0.9 * len(dataset))]\n",
        "val_data = dataset[int(0.9 * len(dataset)): int(0.97 * len(dataset))]\n",
        "test_data = dataset[int(0.97 * len(dataset)): ]"
      ],
      "metadata": {
        "id": "yjajDl5TPGL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ShaksphereDataLoader(torch.utils.data.DataLoader):\n",
        "    def __init__(self, dataset, seq_len, batch_size):\n",
        "        self.dataset = dataset\n",
        "        self.seq_len = seq_len\n",
        "        self.batch_size = batch_size\n",
        "        self.sub_seq = (len(dataset) // self.seq_len)\n",
        "        self.num_batches = self.sub_seq // self.batch_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_batches\n",
        "\n",
        "    def __iter__(self):\n",
        "        offsets = torch.randperm(len(self.dataset) - self.seq_len)[:self.sub_seq]\n",
        "        inputs = torch.stack([self.dataset[i: i + self.seq_len] for i in offsets])\n",
        "        outputs = torch.stack([self.dataset[i + 1: i + 1 + self.seq_len] for i in offsets])\n",
        "        rem = inputs.shape[0] % self.batch_size\n",
        "        if rem != 0:\n",
        "            inputs = inputs[:-rem, :].reshape(self.num_batches, self.batch_size, self.seq_len)\n",
        "            outputs = outputs[:-rem, :].reshape(self.num_batches, self.batch_size, self.seq_len)\n",
        "        else:\n",
        "            inputs = inputs.reshape(self.num_batches, self.batch_size, self.seq_len)\n",
        "            outputs = outputs.reshape(self.num_batches, self.batch_size, self.seq_len)\n",
        "\n",
        "        batch_idx = 0\n",
        "        while batch_idx < self.num_batches:\n",
        "            yield inputs[batch_idx, : , :].to(device), outputs[batch_idx, :, :].to(device)\n",
        "            batch_idx = batch_idx + 1\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "v9Bx6PEctfhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ModelConfig = {\n",
        "    'seq_len': 256,\n",
        "    \"batch_size\": 128,\n",
        "    'embed_dim': 512,\n",
        "    'qk_dim': 512\n",
        "}\n",
        "\n",
        "seq_len = ModelConfig['seq_len']\n",
        "batch_size = ModelConfig['batch_size']\n",
        "embed_dim = ModelConfig['embed_dim']\n",
        "qk_dim = ModelConfig['qk_dim']\n",
        "value_dim = ModelConfig['embed_dim']\n",
        "model_size = ModelConfig['embed_dim']"
      ],
      "metadata": {
        "id": "bCvKqVdagWEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = ShaksphereDataLoader(train_data, seq_len = ModelConfig['seq_len'], batch_size = ModelConfig['batch_size'])\n",
        "val_loader = ShaksphereDataLoader(val_data, seq_len = ModelConfig['seq_len'], batch_size = ModelConfig['batch_size'])\n",
        "print(len(train_loader))\n",
        "print(len(val_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4KsyXeWwTFT",
        "outputId": "d6aa0c5f-c58b-4aef-e06b-8038f2ccc51a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in train_loader:\n",
        "    x, y = i[0], i[1]\n",
        "    break\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8PbJU1CPGTE",
        "outputId": "e70311ee-f064-4e07-880b-f5c15efb4d9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 256])\n",
            "torch.Size([128, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.device)\n",
        "print(y.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElD9FCq3reSB",
        "outputId": "fddcdf44-267d-4ce6-ac3c-10f02311659b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MaskedAttention(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.query_layer = torch.nn.Linear(embed_dim, embed_dim, bias = False)\n",
        "        self.key_layer = torch.nn.Linear(embed_dim, qk_dim, bias = False)\n",
        "        self.value_layer = torch.nn.Linear(embed_dim, value_dim, bias = False)\n",
        "        self.mask = torch.tril(torch.ones(seq_len, seq_len)).to(device)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, tok_embeddings, return_attention_weights = False):\n",
        "        B, T, C = tok_embeddings.shape\n",
        "        Q = self.query_layer(tok_embeddings) # (B, T, qk)\n",
        "        K = self.key_layer(tok_embeddings)   # (B, T, qk)\n",
        "        V = self.value_layer(tok_embeddings) # (B, T, v)\n",
        "\n",
        "        affinities = (Q @ K.transpose(-1, -2)) * K.shape[-1] ** -0.5 # (B, T, T)\n",
        "        affinities = affinities.masked_fill(self.mask[:T, :T] == 0, float('-inf'))\n",
        "\n",
        "        attention_weights = F.softmax(affinities, dim = -1) # (B, T, T)\n",
        "\n",
        "        if return_attention_weights:\n",
        "            return attention_weights @ V, attention_weights\n",
        "        return attention_weights @ V  # (B, T, v)"
      ],
      "metadata": {
        "id": "-VC6Ulm-z061"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(torch.nn.Module):\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.head_size = head_size\n",
        "        self.mini_head_size = int(self.head_size / self.num_heads)\n",
        "\n",
        "        self.query = torch.nn.Linear(embed_dim, self.head_size)\n",
        "        self.key = torch.nn.Linear(embed_dim, self.head_size)\n",
        "        self.value = torch.nn.Linear(embed_dim, self.head_size)\n",
        "        self.up_project = torch.nn.Linear(self.num_heads * self.mini_head_size, head_size)\n",
        "        self.mask = torch.tril(torch.ones(seq_len, seq_len)).to(device)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, tok_embeddings, return_attention_weights = False):\n",
        "        B, T, C = tok_embeddings.shape\n",
        "        Q = self.query(tok_embeddings)\n",
        "        K = self.key(tok_embeddings)\n",
        "        V = self.value(tok_embeddings)\n",
        "\n",
        "        # Reshape into N sub heads for parallel processing\n",
        "        mini_Q = Q.view(B, T, self.num_heads, self.mini_head_size).permute(0, 2, 1, 3) # (B, nh, T, mini_head)\n",
        "        mini_K = K.view(B, T, self.num_heads, self.mini_head_size).permute(0, 2, 1, 3) # (B, nh, T, mini_head)\n",
        "        mini_V = V.view(B, T, self.num_heads, self.mini_head_size).permute(0, 2, 1, 3) # (B, nh, T, mini_head)\n",
        "\n",
        "        # Scaled dot Product\n",
        "        affinities = (mini_Q @ mini_K.transpose(-1, -2)) * (self.mini_head_size ** -0.5) #  (B, nh, T, T)\n",
        "        # Makes it causal decoder\n",
        "        affinities = affinities.masked_fill(self.mask[:T, :T] == 0, float(\"-inf\"))\n",
        "        attention_weights = F.softmax(affinities, dim = -1) # (B, nh, T, T)\n",
        "\n",
        "        # weighted vlaues for each head\n",
        "        mini_head_weighted_values = attention_weights @ mini_V # (B, nh, T, mini_head)\n",
        "        # Concatenating each mini_head outputs\n",
        "        mini_head_weighted_values = mini_head_weighted_values.permute(0, 2, 1, 3)\n",
        "        head_weighted_values = mini_head_weighted_values.reshape(B, T, self.mini_head_size * self.num_heads) # (B, T, head_size)\n",
        "\n",
        "        if return_attention_weights:\n",
        "            return self.up_project(head_weighted_values), attention_weights\n",
        "        return self.up_project(head_weighted_values) # (B, T, head_size)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Qe23hrp2BHIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(torch.nn.Module):\n",
        "    def __init__(self, num_heads):\n",
        "        super().__init__()\n",
        "        self.attention = MultiHeadAttention(num_heads=num_heads, head_size=model_size)\n",
        "        self.layer_norm_1 = torch.nn.LayerNorm(model_size)\n",
        "        self.linear_1 = torch.nn.Linear(model_size, model_size)\n",
        "        self.linear_2 = torch.nn.Linear(model_size, model_size)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.layer_norm_2 = torch.nn.LayerNorm(model_size)\n",
        "        self.dropout_1 = torch.nn.Dropout(0.1)\n",
        "        self.dropout_2 = torch.nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, embeddings, return_attention_weights = False):\n",
        "        # tokens ---> (B, T, embed_size)\n",
        "        B, T, C = embeddings.shape\n",
        "\n",
        "        # Attention\n",
        "        if return_attention_weights:\n",
        "            weighted_values, attention_weights = self.attention.forward(embeddings, return_attention_weights)\n",
        "        else:\n",
        "            weighted_values = self.attention.forward(embeddings) # (B, T, embed_dim)\n",
        "\n",
        "        # Attention Norm + dropout\n",
        "        weighted_values_drp = self.dropout_1(weighted_values)\n",
        "        norm_values = self.layer_norm_1(weighted_values_drp + embeddings) # (B, T, embed_dim)\n",
        "\n",
        "        # FFN + dropout\n",
        "        linear_1 = self.linear_1(norm_values)\n",
        "        act_vals = self.relu(linear_1)\n",
        "        linear_2 = self.linear_2(act_vals)\n",
        "        linear_2_drp = self.dropout_2(linear_2)\n",
        "\n",
        "        # LayerNorm\n",
        "        ffn_norm = self.layer_norm_2(norm_values + linear_2_drp) # (B, T, embed_dim)\n",
        "\n",
        "\n",
        "        if return_attention_weights:\n",
        "            return ffn_norm, attention_weights\n",
        "        return ffn_norm # (B, T, embed_dim)\n"
      ],
      "metadata": {
        "id": "72653NNeNqAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LanguageModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.embedding_layer = torch.nn.Embedding(vocab_size, embed_dim)\n",
        "        self.positional_embedding = torch.nn.Embedding(seq_len, embed_dim)\n",
        "        self.dropout_0 = torch.nn.Dropout(0.1)\n",
        "        self.decoder_block_1 = DecoderBlock(num_heads=8)\n",
        "        self.decoder_block_2 = DecoderBlock(num_heads=8)\n",
        "        self.decoder_block_3 = DecoderBlock(num_heads=8)\n",
        "\n",
        "        self.projection = torch.nn.Linear(model_size, vocab_size)\n",
        "        self.projection.weight = self.embedding_layer.weight\n",
        "\n",
        "    def forward(self, tokens, return_attention_weights = False):\n",
        "        B, T = tokens.shape\n",
        "        # Token and Positional Embeddings + dropout\n",
        "        tok_embs = self.embedding_layer(tokens) # (B, T, embed_dim)\n",
        "        pos_embs = self.positional_embedding(torch.arange(T).to(device))\n",
        "        pos_tok_embs = tok_embs + pos_embs # (B, T, embed_dim)\n",
        "        pos_tok_embs_drp = self.dropout_0(pos_tok_embs)\n",
        "\n",
        "        # Decoder Blocks\n",
        "        decoder_1 = self.decoder_block_1.forward(pos_tok_embs)\n",
        "        decoder_2 = self.decoder_block_2.forward(decoder_1)\n",
        "        if return_attention_weights:\n",
        "            decoder_3, last_layer_attention_weights = self.decoder_block_3.forward(decoder_2, return_attention_weights=True)\n",
        "        else:\n",
        "            decoder_3 = self.decoder_block_3.forward(decoder_2)\n",
        "\n",
        "        # projection layer\n",
        "        logits = self.projection(decoder_3) # (B, T, vocab_size)\n",
        "\n",
        "        if return_attention_weights:\n",
        "            return logits, last_layer_attention_weights\n",
        "        return logits # (B, T, vocab_size)\n",
        "\n"
      ],
      "metadata": {
        "id": "CibOSqOQTL4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummaryX import summary\n",
        "model = LanguageModel()\n",
        "model.to(device)\n",
        "#model.load_state_dict(torch.load('/content/drive/MyDrive/ShakGPT_3_512.pt', map_location = device))\n",
        "summary(model, x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fllG6UIz-kMK",
        "outputId": "b694eb1b-32e7-45cb-d528-57ce0a81cb8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================================================================================\n",
            "                                               Kernel Shape     Output Shape  \\\n",
            "Layer                                                                          \n",
            "0_embedding_layer                                 [512, 65]  [128, 256, 512]   \n",
            "1_positional_embedding                           [512, 256]       [256, 512]   \n",
            "2_dropout_0                                               -  [128, 256, 512]   \n",
            "3_decoder_block_1.attention.Linear_query         [512, 512]  [128, 256, 512]   \n",
            "4_decoder_block_1.attention.Linear_key           [512, 512]  [128, 256, 512]   \n",
            "5_decoder_block_1.attention.Linear_value         [512, 512]  [128, 256, 512]   \n",
            "6_decoder_block_1.attention.Linear_up_project    [512, 512]  [128, 256, 512]   \n",
            "7_decoder_block_1.Dropout_dropout_1                       -  [128, 256, 512]   \n",
            "8_decoder_block_1.LayerNorm_layer_norm_1              [512]  [128, 256, 512]   \n",
            "9_decoder_block_1.Linear_linear_1                [512, 512]  [128, 256, 512]   \n",
            "10_decoder_block_1.ReLU_relu                              -  [128, 256, 512]   \n",
            "11_decoder_block_1.Linear_linear_2               [512, 512]  [128, 256, 512]   \n",
            "12_decoder_block_1.Dropout_dropout_2                      -  [128, 256, 512]   \n",
            "13_decoder_block_1.LayerNorm_layer_norm_2             [512]  [128, 256, 512]   \n",
            "14_decoder_block_2.attention.Linear_query        [512, 512]  [128, 256, 512]   \n",
            "15_decoder_block_2.attention.Linear_key          [512, 512]  [128, 256, 512]   \n",
            "16_decoder_block_2.attention.Linear_value        [512, 512]  [128, 256, 512]   \n",
            "17_decoder_block_2.attention.Linear_up_project   [512, 512]  [128, 256, 512]   \n",
            "18_decoder_block_2.Dropout_dropout_1                      -  [128, 256, 512]   \n",
            "19_decoder_block_2.LayerNorm_layer_norm_1             [512]  [128, 256, 512]   \n",
            "20_decoder_block_2.Linear_linear_1               [512, 512]  [128, 256, 512]   \n",
            "21_decoder_block_2.ReLU_relu                              -  [128, 256, 512]   \n",
            "22_decoder_block_2.Linear_linear_2               [512, 512]  [128, 256, 512]   \n",
            "23_decoder_block_2.Dropout_dropout_2                      -  [128, 256, 512]   \n",
            "24_decoder_block_2.LayerNorm_layer_norm_2             [512]  [128, 256, 512]   \n",
            "25_decoder_block_3.attention.Linear_query        [512, 512]  [128, 256, 512]   \n",
            "26_decoder_block_3.attention.Linear_key          [512, 512]  [128, 256, 512]   \n",
            "27_decoder_block_3.attention.Linear_value        [512, 512]  [128, 256, 512]   \n",
            "28_decoder_block_3.attention.Linear_up_project   [512, 512]  [128, 256, 512]   \n",
            "29_decoder_block_3.Dropout_dropout_1                      -  [128, 256, 512]   \n",
            "30_decoder_block_3.LayerNorm_layer_norm_1             [512]  [128, 256, 512]   \n",
            "31_decoder_block_3.Linear_linear_1               [512, 512]  [128, 256, 512]   \n",
            "32_decoder_block_3.ReLU_relu                              -  [128, 256, 512]   \n",
            "33_decoder_block_3.Linear_linear_2               [512, 512]  [128, 256, 512]   \n",
            "34_decoder_block_3.Dropout_dropout_2                      -  [128, 256, 512]   \n",
            "35_decoder_block_3.LayerNorm_layer_norm_2             [512]  [128, 256, 512]   \n",
            "36_projection                                     [512, 65]   [128, 256, 65]   \n",
            "\n",
            "                                                  Params Mult-Adds  \n",
            "Layer                                                               \n",
            "0_embedding_layer                                 33.28k    33.28k  \n",
            "1_positional_embedding                          131.072k  131.072k  \n",
            "2_dropout_0                                            -         -  \n",
            "3_decoder_block_1.attention.Linear_query        262.656k  262.144k  \n",
            "4_decoder_block_1.attention.Linear_key          262.656k  262.144k  \n",
            "5_decoder_block_1.attention.Linear_value        262.656k  262.144k  \n",
            "6_decoder_block_1.attention.Linear_up_project   262.656k  262.144k  \n",
            "7_decoder_block_1.Dropout_dropout_1                    -         -  \n",
            "8_decoder_block_1.LayerNorm_layer_norm_1          1.024k     512.0  \n",
            "9_decoder_block_1.Linear_linear_1               262.656k  262.144k  \n",
            "10_decoder_block_1.ReLU_relu                           -         -  \n",
            "11_decoder_block_1.Linear_linear_2              262.656k  262.144k  \n",
            "12_decoder_block_1.Dropout_dropout_2                   -         -  \n",
            "13_decoder_block_1.LayerNorm_layer_norm_2         1.024k     512.0  \n",
            "14_decoder_block_2.attention.Linear_query       262.656k  262.144k  \n",
            "15_decoder_block_2.attention.Linear_key         262.656k  262.144k  \n",
            "16_decoder_block_2.attention.Linear_value       262.656k  262.144k  \n",
            "17_decoder_block_2.attention.Linear_up_project  262.656k  262.144k  \n",
            "18_decoder_block_2.Dropout_dropout_1                   -         -  \n",
            "19_decoder_block_2.LayerNorm_layer_norm_1         1.024k     512.0  \n",
            "20_decoder_block_2.Linear_linear_1              262.656k  262.144k  \n",
            "21_decoder_block_2.ReLU_relu                           -         -  \n",
            "22_decoder_block_2.Linear_linear_2              262.656k  262.144k  \n",
            "23_decoder_block_2.Dropout_dropout_2                   -         -  \n",
            "24_decoder_block_2.LayerNorm_layer_norm_2         1.024k     512.0  \n",
            "25_decoder_block_3.attention.Linear_query       262.656k  262.144k  \n",
            "26_decoder_block_3.attention.Linear_key         262.656k  262.144k  \n",
            "27_decoder_block_3.attention.Linear_value       262.656k  262.144k  \n",
            "28_decoder_block_3.attention.Linear_up_project  262.656k  262.144k  \n",
            "29_decoder_block_3.Dropout_dropout_1                   -         -  \n",
            "30_decoder_block_3.LayerNorm_layer_norm_1         1.024k     512.0  \n",
            "31_decoder_block_3.Linear_linear_1              262.656k  262.144k  \n",
            "32_decoder_block_3.ReLU_relu                           -         -  \n",
            "33_decoder_block_3.Linear_linear_2              262.656k  262.144k  \n",
            "34_decoder_block_3.Dropout_dropout_2                   -         -  \n",
            "35_decoder_block_3.LayerNorm_layer_norm_2         1.024k     512.0  \n",
            "36_projection                                    33.345k    33.28k  \n",
            "-------------------------------------------------------------------------------------------------\n",
            "                         Totals\n",
            "Total params          4.931649M\n",
            "Trainable params      4.931649M\n",
            "Non-trainable params        0.0\n",
            "Mult-Adds             4.919296M\n",
            "=================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchsummaryX/torchsummaryX.py:101: FutureWarning: The default value of numeric_only in DataFrame.sum is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
            "  df_sum = df.sum()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               Kernel Shape     Output Shape  \\\n",
              "Layer                                                                          \n",
              "0_embedding_layer                                 [512, 65]  [128, 256, 512]   \n",
              "1_positional_embedding                           [512, 256]       [256, 512]   \n",
              "2_dropout_0                                               -  [128, 256, 512]   \n",
              "3_decoder_block_1.attention.Linear_query         [512, 512]  [128, 256, 512]   \n",
              "4_decoder_block_1.attention.Linear_key           [512, 512]  [128, 256, 512]   \n",
              "5_decoder_block_1.attention.Linear_value         [512, 512]  [128, 256, 512]   \n",
              "6_decoder_block_1.attention.Linear_up_project    [512, 512]  [128, 256, 512]   \n",
              "7_decoder_block_1.Dropout_dropout_1                       -  [128, 256, 512]   \n",
              "8_decoder_block_1.LayerNorm_layer_norm_1              [512]  [128, 256, 512]   \n",
              "9_decoder_block_1.Linear_linear_1                [512, 512]  [128, 256, 512]   \n",
              "10_decoder_block_1.ReLU_relu                              -  [128, 256, 512]   \n",
              "11_decoder_block_1.Linear_linear_2               [512, 512]  [128, 256, 512]   \n",
              "12_decoder_block_1.Dropout_dropout_2                      -  [128, 256, 512]   \n",
              "13_decoder_block_1.LayerNorm_layer_norm_2             [512]  [128, 256, 512]   \n",
              "14_decoder_block_2.attention.Linear_query        [512, 512]  [128, 256, 512]   \n",
              "15_decoder_block_2.attention.Linear_key          [512, 512]  [128, 256, 512]   \n",
              "16_decoder_block_2.attention.Linear_value        [512, 512]  [128, 256, 512]   \n",
              "17_decoder_block_2.attention.Linear_up_project   [512, 512]  [128, 256, 512]   \n",
              "18_decoder_block_2.Dropout_dropout_1                      -  [128, 256, 512]   \n",
              "19_decoder_block_2.LayerNorm_layer_norm_1             [512]  [128, 256, 512]   \n",
              "20_decoder_block_2.Linear_linear_1               [512, 512]  [128, 256, 512]   \n",
              "21_decoder_block_2.ReLU_relu                              -  [128, 256, 512]   \n",
              "22_decoder_block_2.Linear_linear_2               [512, 512]  [128, 256, 512]   \n",
              "23_decoder_block_2.Dropout_dropout_2                      -  [128, 256, 512]   \n",
              "24_decoder_block_2.LayerNorm_layer_norm_2             [512]  [128, 256, 512]   \n",
              "25_decoder_block_3.attention.Linear_query        [512, 512]  [128, 256, 512]   \n",
              "26_decoder_block_3.attention.Linear_key          [512, 512]  [128, 256, 512]   \n",
              "27_decoder_block_3.attention.Linear_value        [512, 512]  [128, 256, 512]   \n",
              "28_decoder_block_3.attention.Linear_up_project   [512, 512]  [128, 256, 512]   \n",
              "29_decoder_block_3.Dropout_dropout_1                      -  [128, 256, 512]   \n",
              "30_decoder_block_3.LayerNorm_layer_norm_1             [512]  [128, 256, 512]   \n",
              "31_decoder_block_3.Linear_linear_1               [512, 512]  [128, 256, 512]   \n",
              "32_decoder_block_3.ReLU_relu                              -  [128, 256, 512]   \n",
              "33_decoder_block_3.Linear_linear_2               [512, 512]  [128, 256, 512]   \n",
              "34_decoder_block_3.Dropout_dropout_2                      -  [128, 256, 512]   \n",
              "35_decoder_block_3.LayerNorm_layer_norm_2             [512]  [128, 256, 512]   \n",
              "36_projection                                     [512, 65]   [128, 256, 65]   \n",
              "\n",
              "                                                  Params  Mult-Adds  \n",
              "Layer                                                                \n",
              "0_embedding_layer                                33280.0    33280.0  \n",
              "1_positional_embedding                          131072.0   131072.0  \n",
              "2_dropout_0                                          NaN        NaN  \n",
              "3_decoder_block_1.attention.Linear_query        262656.0   262144.0  \n",
              "4_decoder_block_1.attention.Linear_key          262656.0   262144.0  \n",
              "5_decoder_block_1.attention.Linear_value        262656.0   262144.0  \n",
              "6_decoder_block_1.attention.Linear_up_project   262656.0   262144.0  \n",
              "7_decoder_block_1.Dropout_dropout_1                  NaN        NaN  \n",
              "8_decoder_block_1.LayerNorm_layer_norm_1          1024.0      512.0  \n",
              "9_decoder_block_1.Linear_linear_1               262656.0   262144.0  \n",
              "10_decoder_block_1.ReLU_relu                         NaN        NaN  \n",
              "11_decoder_block_1.Linear_linear_2              262656.0   262144.0  \n",
              "12_decoder_block_1.Dropout_dropout_2                 NaN        NaN  \n",
              "13_decoder_block_1.LayerNorm_layer_norm_2         1024.0      512.0  \n",
              "14_decoder_block_2.attention.Linear_query       262656.0   262144.0  \n",
              "15_decoder_block_2.attention.Linear_key         262656.0   262144.0  \n",
              "16_decoder_block_2.attention.Linear_value       262656.0   262144.0  \n",
              "17_decoder_block_2.attention.Linear_up_project  262656.0   262144.0  \n",
              "18_decoder_block_2.Dropout_dropout_1                 NaN        NaN  \n",
              "19_decoder_block_2.LayerNorm_layer_norm_1         1024.0      512.0  \n",
              "20_decoder_block_2.Linear_linear_1              262656.0   262144.0  \n",
              "21_decoder_block_2.ReLU_relu                         NaN        NaN  \n",
              "22_decoder_block_2.Linear_linear_2              262656.0   262144.0  \n",
              "23_decoder_block_2.Dropout_dropout_2                 NaN        NaN  \n",
              "24_decoder_block_2.LayerNorm_layer_norm_2         1024.0      512.0  \n",
              "25_decoder_block_3.attention.Linear_query       262656.0   262144.0  \n",
              "26_decoder_block_3.attention.Linear_key         262656.0   262144.0  \n",
              "27_decoder_block_3.attention.Linear_value       262656.0   262144.0  \n",
              "28_decoder_block_3.attention.Linear_up_project  262656.0   262144.0  \n",
              "29_decoder_block_3.Dropout_dropout_1                 NaN        NaN  \n",
              "30_decoder_block_3.LayerNorm_layer_norm_1         1024.0      512.0  \n",
              "31_decoder_block_3.Linear_linear_1              262656.0   262144.0  \n",
              "32_decoder_block_3.ReLU_relu                         NaN        NaN  \n",
              "33_decoder_block_3.Linear_linear_2              262656.0   262144.0  \n",
              "34_decoder_block_3.Dropout_dropout_2                 NaN        NaN  \n",
              "35_decoder_block_3.LayerNorm_layer_norm_2         1024.0      512.0  \n",
              "36_projection                                    33345.0    33280.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-16045281-9929-4897-832a-a429929ef616\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Kernel Shape</th>\n",
              "      <th>Output Shape</th>\n",
              "      <th>Params</th>\n",
              "      <th>Mult-Adds</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Layer</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0_embedding_layer</th>\n",
              "      <td>[512, 65]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>33280.0</td>\n",
              "      <td>33280.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1_positional_embedding</th>\n",
              "      <td>[512, 256]</td>\n",
              "      <td>[256, 512]</td>\n",
              "      <td>131072.0</td>\n",
              "      <td>131072.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2_dropout_0</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3_decoder_block_1.attention.Linear_query</th>\n",
              "      <td>[512, 512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>262656.0</td>\n",
              "      <td>262144.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_decoder_block_1.attention.Linear_key</th>\n",
              "      <td>[512, 512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>262656.0</td>\n",
              "      <td>262144.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_decoder_block_1.attention.Linear_value</th>\n",
              "      <td>[512, 512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>262656.0</td>\n",
              "      <td>262144.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6_decoder_block_1.attention.Linear_up_project</th>\n",
              "      <td>[512, 512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>262656.0</td>\n",
              "      <td>262144.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7_decoder_block_1.Dropout_dropout_1</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8_decoder_block_1.LayerNorm_layer_norm_1</th>\n",
              "      <td>[512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>512.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9_decoder_block_1.Linear_linear_1</th>\n",
              "      <td>[512, 512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>262656.0</td>\n",
              "      <td>262144.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10_decoder_block_1.ReLU_relu</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11_decoder_block_1.Linear_linear_2</th>\n",
              "      <td>[512, 512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>262656.0</td>\n",
              "      <td>262144.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12_decoder_block_1.Dropout_dropout_2</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13_decoder_block_1.LayerNorm_layer_norm_2</th>\n",
              "      <td>[512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>512.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14_decoder_block_2.attention.Linear_query</th>\n",
              "      <td>[512, 512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>262656.0</td>\n",
              "      <td>262144.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15_decoder_block_2.attention.Linear_key</th>\n",
              "      <td>[512, 512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>262656.0</td>\n",
              "      <td>262144.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16_decoder_block_2.attention.Linear_value</th>\n",
              "      <td>[512, 512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>262656.0</td>\n",
              "      <td>262144.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17_decoder_block_2.attention.Linear_up_project</th>\n",
              "      <td>[512, 512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>262656.0</td>\n",
              "      <td>262144.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18_decoder_block_2.Dropout_dropout_1</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19_decoder_block_2.LayerNorm_layer_norm_1</th>\n",
              "      <td>[512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>512.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20_decoder_block_2.Linear_linear_1</th>\n",
              "      <td>[512, 512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>262656.0</td>\n",
              "      <td>262144.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21_decoder_block_2.ReLU_relu</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22_decoder_block_2.Linear_linear_2</th>\n",
              "      <td>[512, 512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>262656.0</td>\n",
              "      <td>262144.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23_decoder_block_2.Dropout_dropout_2</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24_decoder_block_2.LayerNorm_layer_norm_2</th>\n",
              "      <td>[512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>512.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25_decoder_block_3.attention.Linear_query</th>\n",
              "      <td>[512, 512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>262656.0</td>\n",
              "      <td>262144.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26_decoder_block_3.attention.Linear_key</th>\n",
              "      <td>[512, 512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>262656.0</td>\n",
              "      <td>262144.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27_decoder_block_3.attention.Linear_value</th>\n",
              "      <td>[512, 512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>262656.0</td>\n",
              "      <td>262144.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28_decoder_block_3.attention.Linear_up_project</th>\n",
              "      <td>[512, 512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>262656.0</td>\n",
              "      <td>262144.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29_decoder_block_3.Dropout_dropout_1</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30_decoder_block_3.LayerNorm_layer_norm_1</th>\n",
              "      <td>[512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>512.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31_decoder_block_3.Linear_linear_1</th>\n",
              "      <td>[512, 512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>262656.0</td>\n",
              "      <td>262144.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32_decoder_block_3.ReLU_relu</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33_decoder_block_3.Linear_linear_2</th>\n",
              "      <td>[512, 512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>262656.0</td>\n",
              "      <td>262144.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34_decoder_block_3.Dropout_dropout_2</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35_decoder_block_3.LayerNorm_layer_norm_2</th>\n",
              "      <td>[512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>512.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36_projection</th>\n",
              "      <td>[512, 65]</td>\n",
              "      <td>[128, 256, 65]</td>\n",
              "      <td>33345.0</td>\n",
              "      <td>33280.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16045281-9929-4897-832a-a429929ef616')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-16045281-9929-4897-832a-a429929ef616 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-16045281-9929-4897-832a-a429929ef616');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b1720b02-6cd6-468d-b997-57bfb51d91d3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b1720b02-6cd6-468d-b997-57bfb51d91d3')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b1720b02-6cd6-468d-b997-57bfb51d91d3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#x, y = get_batch('train')\n",
        "logits, attention_weights = model.forward(x, return_attention_weights=True)\n",
        "print(logits.shape)\n",
        "B, T, vocab_size = logits.shape\n",
        "logits = logits.view(B*T, vocab_size)\n",
        "print(logits.shape)\n",
        "y = y.view(B*T)\n",
        "loss = F.cross_entropy(logits, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIqFrxOjexh-",
        "outputId": "33c8c875-6598-4c23-8860-2a557edc21d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 256, 65])\n",
            "torch.Size([32768, 65])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOwIedqW6vGd",
        "outputId": "10f1920a-6a1c-406c-d37e-78be514b356f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.2572, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
        "criterion = torch.nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "scheduler =  torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=4) #TODO"
      ],
      "metadata": {
        "id": "bhU8Y1xbnVyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer.param_groups[0]['lr'] = 5e-5"
      ],
      "metadata": {
        "id": "xvNgfzVkYqpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot(attention_weights):\n",
        "    plt.figure(figsize=(64, 64))\n",
        "    fig, ax = plt.subplots()\n",
        "    cax = ax.matshow(attention_weights[0, 0, :50, :50].detach().cpu().numpy(), cmap='viridis')\n",
        "\n",
        "# Set the axis labels (optional)\n",
        "    ax.set_xticks(np.arange(50))\n",
        "    ax.set_yticks(np.arange(50))\n",
        "    ax.set_xticklabels(decode(x[0][:50].detach().cpu().numpy()))\n",
        "    ax.set_yticklabels(decode(x[0][:50].detach().cpu().numpy()))\n",
        "\n",
        "    # Rotate the tick labels and set their alignment (optional)\n",
        "    plt.setp(ax.get_xticklabels(), rotation=90, ha=\"right\", rotation_mode=\"anchor\")\n",
        "\n",
        "    # Add a colorbar\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "e2hmCO00dJWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(attention_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "HcO1zS6TonjZ",
        "outputId": "cc8c8ef1-223f-4329-a6c5-d2b7a08d12de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 6400x6400 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer():\n",
        "    def __init__(self, model, train_loader, val_loader, optimizer, criterion):\n",
        "        self.model = model\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.epoch = 0\n",
        "        self.optimizer = optimizer\n",
        "        self.criterion = criterion\n",
        "        train_loss = 0\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "        for x, y in self.train_loader:\n",
        "            logits, attention_weights = self.model.forward(x, return_attention_weights=True)\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            y = y.view(B*T)\n",
        "            loss = self.criterion(logits, y)\n",
        "            total_loss = total_loss + loss.item()\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "\n",
        "        epoch_loss = total_loss / len(train_loader)\n",
        "        self.epoch = self.epoch + 1\n",
        "        print(f\"Epoch: {self.epoch}\\nTrain Loss: {epoch_loss}, Train Perplexity: {np.exp(epoch_loss)}, LR: {self.optimizer.param_groups[0]['lr']}\")\n",
        "        return epoch_loss\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def validate(self):\n",
        "        self.model.eval()\n",
        "        total_loss = 0\n",
        "        for x, y in self.val_loader:\n",
        "            logits = self.model.forward(x)\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            y = y.view(B*T)\n",
        "            val_loss = self.criterion(logits, y)\n",
        "            total_loss = total_loss + val_loss.item()\n",
        "\n",
        "        epoch_loss = total_loss / len(self.val_loader)\n",
        "        print(f'Validation Loss: {epoch_loss}')\n",
        "        return epoch_loss\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def generate(self, max_tokens, prompt, temperature = 1, top_p = 1):\n",
        "        self.model.eval()\n",
        "        for i in range(max_tokens):\n",
        "            logits = self.model.forward(prompt)\n",
        "            logit = logits[:, -1, :] # (B, C)\n",
        "            logit = logit / temperature\n",
        "            probs = F.softmax(logit, dim = -1)\n",
        "            weighted_probs = self.topPTransform(probs, top_p)\n",
        "            #token = torch.argmax(probs, dim = -1).view(-1, 1)\n",
        "            token = torch.multinomial(weighted_probs, num_samples = 1) # (B, 1)\n",
        "            prompt = torch.cat((prompt, token), dim = -1) # (B, T + 1)\n",
        "        return prompt\n",
        "\n",
        "    def topPTransform(self, probs, top_p):\n",
        "        probs_sorted_vals, probs_sort_idx = torch.sort(probs, descending=True)\n",
        "        prob_cumsum = torch.cumsum(probs_sorted_vals, dim = -1)\n",
        "\n",
        "        absolute_diff = torch.abs(prob_cumsum - top_p)\n",
        "        closest_index = torch.argmin(absolute_diff).item()\n",
        "        idx_to_remove = probs_sort_idx[:, closest_index + 1:]\n",
        "\n",
        "        mask = torch.ones_like(probs)\n",
        "        mask[:, idx_to_remove] = 0\n",
        "\n",
        "        probs = probs * mask\n",
        "        weighted_probs = probs / torch.sum(probs, dim = -1)\n",
        "        return weighted_probs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def save(self, path):\n",
        "        torch.save(self.model.state_dict(), path)\n",
        "        print(\"Model saved at \" + path)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GA6HkdLy6zXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wandb_config(epochs):\n",
        "        d = dict()\n",
        "        d['epochs'] = epochs\n",
        "        d['lr'] = 1e-4\n",
        "\n",
        "        return d\n"
      ],
      "metadata": {
        "id": "oxYfUAJKNpnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login(key=\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4zQ0X0sNymy",
        "outputId": "57f4197d-075d-413f-a4c2-16507874e5e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 800\n",
        "run = wandb.init(\n",
        "    name = \"shakGPT-decoder_3_512\", ## Wandb creates random run names if you skip this field\n",
        "    #reinit = True, ### Allows reinitalizing runs when you re-run this cell\n",
        "    #run_id = \"hr8c7o0i\", ### Insert specific run id here if you want to resume a previous run\n",
        "    resume = \"True\", ### You need this to resume previous runs, but comment out reinit = True when using this\n",
        "    project = \"shakespeare\", ### Project should be created in your wandb account\n",
        "    config = wandb_config(epochs) ### Wandb Config for your run\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "zsRAEBSFN227",
        "outputId": "6ca93067-cc18-4d39-c02f-52be54208bc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkrana\u001b[0m (\u001b[33mllm-tuning\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20231004_001820-True</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Resuming run <strong><a href='https://wandb.ai/llm-tuning/shakespeare/runs/True' target=\"_blank\">shakGPT-decoder_3_512</a></strong> to <a href='https://wandb.ai/llm-tuning/shakespeare' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/llm-tuning/shakespeare' target=\"_blank\">https://wandb.ai/llm-tuning/shakespeare</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/llm-tuning/shakespeare/runs/True' target=\"_blank\">https://wandb.ai/llm-tuning/shakespeare/runs/True</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(model = model, train_loader=train_loader, val_loader=val_loader, optimizer=optimizer, criterion = criterion)\n",
        "best_val_loss = float('inf')\n",
        "for epoch in range(epochs):\n",
        "    train_loss = trainer.train()\n",
        "    val_loss = trainer.validate()\n",
        "    #scheduler.step(val_loss)\n",
        "    if val_loss < best_val_loss:\n",
        "        trainer.save('/content/drive/MyDrive/ShakGPT_3_512.pt')\n",
        "        best_val_loss = val_loss\n",
        "    print(\"Generation: \" + decode(trainer.generate(prompt =\n",
        "                            torch.tensor(encode(\"BARNARDO: Who's there?\\nFRANCISCO: Nay, answer me. Stand and unfold yourself.\\nBARNARDO:\")).view(1, -1).to(device),\n",
        "                            max_tokens=170,\n",
        "                            top_p = 0.7)[0].tolist()))\n",
        "    wandb.log({\n",
        "            'train_loss': train_loss,\n",
        "            'val_loss': val_loss,\n",
        "            'lr'        : optimizer.param_groups[0]['lr'],\n",
        "        })\n",
        "\n",
        "    print('\\n')\n",
        "    if epoch == 700:\n",
        "        optimizer.param_groups[0]['lr'] = 1e-5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fWiLDswz_KCJ",
        "outputId": "706fbe81-567c-47f6-cf17-6bc903bd9150"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\n",
            "Train Loss: 1.8642677625020345, Train Perplexity: 6.451210337973911, LR: 0.0001\n",
            "Validation Loss: 1.9744486808776855\n",
            "Model saved at /content/drive/MyDrive/ShakGPT_3_512.pt\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I told you have some to my hand.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "What shall not have a sister from my father?\n",
            "\n",
            "BUCKINGHAM:\n",
            "Ay, my lord, and then, and the last dead.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Br\n",
            "\n",
            "\n",
            "Epoch: 2\n",
            "Train Loss: 1.804576607545217, Train Perplexity: 6.077397779358238, LR: 0.0001\n",
            "Validation Loss: 1.9553383588790894\n",
            "Model saved at /content/drive/MyDrive/ShakGPT_3_512.pt\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I am a for bear the man.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "No bare you to be sense of all our tribunes;\n",
            "For state hath me but a place to do.\n",
            "\n",
            "PAULINA:\n",
            "I have thee, then stand and more wi\n",
            "\n",
            "\n",
            "Epoch: 3\n",
            "Train Loss: 1.8078783988952636, Train Perplexity: 6.097497242633839, LR: 0.0001\n",
            "Validation Loss: 1.9523974061012268\n",
            "Model saved at /content/drive/MyDrive/ShakGPT_3_512.pt\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "What we do been in the day to the maid?\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "She is a siderer, I cannot do attend it.\n",
            "\n",
            "PARIS:\n",
            "This is a leave out of death, but that when you are.\n",
            "\n",
            "LUCIO:\n",
            "Th\n",
            "\n",
            "\n",
            "Epoch: 4\n",
            "Train Loss: 1.8016536712646485, Train Perplexity: 6.059659868917225, LR: 0.0001\n",
            "Validation Loss: 1.9452933073043823\n",
            "Model saved at /content/drive/MyDrive/ShakGPT_3_512.pt\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "He shall not him at the matter of his charge;\n",
            "The many haste of the hath a mind.\n",
            "\n",
            "PAULINA:\n",
            "Give me said, sir, as he has made\n",
            "As with me as I may should stand for I live.\n",
            "\n",
            "\n",
            "Epoch: 5\n",
            "Train Loss: 1.8040508389472962, Train Perplexity: 6.074203314297074, LR: 0.0001\n",
            "Validation Loss: 1.9691829681396484\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I will be all, a mother, for I will take your hands.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Why, who you do not so?\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Some on, and love a contrary, with my stand looks.\n",
            "\n",
            "BUCKIN\n",
            "\n",
            "\n",
            "Epoch: 6\n",
            "Train Loss: 1.804090682665507, Train Perplexity: 6.074445337963813, LR: 0.0001\n",
            "Validation Loss: 1.9879435300827026\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Not you must be past that I have bold,\n",
            "I do beggard my count to my father;\n",
            "And therefore I may not for my bear you\n",
            "A man's sake to my mood him mistress'd.\n",
            "\n",
            "DUKE VINCENTI\n",
            "\n",
            "\n",
            "Epoch: 7\n",
            "Train Loss: 1.8012478987375895, Train Perplexity: 6.057201524217198, LR: 0.0001\n",
            "Validation Loss: 1.9597021341323853\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Why, I will I have not a man?\n",
            "\n",
            "BAPTISTA:\n",
            "I do not so, I have done that had been good\n",
            "To my father to the king is in the strong,\n",
            "Which is in silent to his house that the \n",
            "\n",
            "\n",
            "Epoch: 8\n",
            "Train Loss: 1.8025060653686524, Train Perplexity: 6.064827289288211, LR: 0.0001\n",
            "Validation Loss: 1.9545480012893677\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Here's for his at head; the winterful and all,\n",
            "And most grief that some in his love,\n",
            "With fearful and souls have in displeased\n",
            "And blood lady strange the fair that shall\n",
            "\n",
            "\n",
            "Epoch: 9\n",
            "Train Loss: 1.799565311272939, Train Perplexity: 6.047018322328085, LR: 0.0001\n",
            "Validation Loss: 1.9786715507507324\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Despite him to the tribunes, he dead!\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Shall well not have been disting to be their country's\n",
            "And life to be so pardon and bed in the bear of\n",
            "with subjec\n",
            "\n",
            "\n",
            "Epoch: 10\n",
            "Train Loss: 1.8017092267672221, Train Perplexity: 6.05999652571815, LR: 0.0001\n",
            "Validation Loss: 1.9450480937957764\n",
            "Model saved at /content/drive/MyDrive/ShakGPT_3_512.pt\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "A man good at once marriage and my sons.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "What thou art so look'dtood we mercy on a\n",
            "cause? O most be gone, in the still of death!\n",
            "How man discipiness mad\n",
            "\n",
            "\n",
            "Epoch: 11\n",
            "Train Loss: 1.8038154125213623, Train Perplexity: 6.072773454640371, LR: 0.0001\n",
            "Validation Loss: 1.9698927402496338\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Dost thou have me alone, I will have a traitor.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "I thank you, have you to my son him dear.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "I am not well.\n",
            "\n",
            "Provost:\n",
            "What you are hand th\n",
            "\n",
            "\n",
            "Epoch: 12\n",
            "Train Loss: 1.8017942627271017, Train Perplexity: 6.060511865250467, LR: 0.0001\n",
            "Validation Loss: 1.977897047996521\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Here is your good to the common of your lord.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Sir, my lord, it was your with her; and they shall be\n",
            "That do me wounds and with me the crown.\n",
            "\n",
            "DUKE VINCE\n",
            "\n",
            "\n",
            "Epoch: 13\n",
            "Train Loss: 1.8047085841496786, Train Perplexity: 6.078199906610972, LR: 0.0001\n",
            "Validation Loss: 1.9513990879058838\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "When I am the day is my father hence?\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "No honest thou wilt be a good death; and when I lay.\n",
            "\n",
            "POMPEY:\n",
            "Sir, he hath a fearful all in the can him.\n",
            "\n",
            "PAULINA:\n",
            "\n",
            "\n",
            "Epoch: 14\n",
            "Train Loss: 1.7982118010520936, Train Perplexity: 6.038839157763271, LR: 0.0001\n",
            "Validation Loss: 1.9728306531906128\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I have not a banish'd him, my lord; but I did not\n",
            "so much to be my brother, that she would the subject.\n",
            "\n",
            "POLIXENES:\n",
            "No matter, sir, nor now no let him.\n",
            "\n",
            "POLIXENES:\n",
            "What \n",
            "\n",
            "\n",
            "Epoch: 15\n",
            "Train Loss: 1.8028390328089396, Train Perplexity: 6.066847015539389, LR: 0.0001\n",
            "Validation Loss: 1.9652971625328064\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "What, will not for your country?\n",
            "\n",
            "POMPEY:\n",
            "You shall I say, sir; the be this passage of my hand.\n",
            "\n",
            "POLIXENES:\n",
            "He shall not see him worthy born and look.\n",
            "\n",
            "FRIAR LAURENCE:\n",
            "B\n",
            "\n",
            "\n",
            "Epoch: 16\n",
            "Train Loss: 1.8022830963134766, Train Perplexity: 6.063475171223559, LR: 0.0001\n",
            "Validation Loss: 1.9531410932540894\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I would not stay the maid at all this face.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Now I do the strike prince a man, may say the\n",
            "savours of intelligence; and what say you are not\n",
            "A dead many \n",
            "\n",
            "\n",
            "Epoch: 17\n",
            "Train Loss: 1.799890923500061, Train Perplexity: 6.048987626028748, LR: 0.0001\n",
            "Validation Loss: 1.9516328573226929\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Now, not me better than it be an grief;\n",
            "For I have the dukedom of a woman in the fortune,\n",
            "That is this in best an hour, I can so\n",
            "He that be consent and the stand to all \n",
            "\n",
            "\n",
            "Epoch: 18\n",
            "Train Loss: 1.7996419509251913, Train Perplexity: 6.047481781468918, LR: 0.0001\n",
            "Validation Loss: 1.9679060578346252\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Petruchio, noble sorrow to your good dangerous\n",
            "The gates of death and lives, with a children.\n",
            "\n",
            "PERDITA:\n",
            "O, good Camillo, be my brother be granted loss\n",
            "Than I say, there'\n",
            "\n",
            "\n",
            "Epoch: 19\n",
            "Train Loss: 1.7996076544125874, Train Perplexity: 6.047274377490415, LR: 0.0001\n",
            "Validation Loss: 1.9464309811592102\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Great me well, I mean may perjury; I have been\n",
            "I have not heard souls mad her father and pause.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Pray you, do you mercy stay with you.\n",
            "\n",
            "ANGELO:\n",
            "How fares\n",
            "\n",
            "\n",
            "Epoch: 20\n",
            "Train Loss: 1.7979030768076578, Train Perplexity: 6.036975109460279, LR: 0.0001\n",
            "Validation Loss: 1.967514157295227\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I know not beseech you, my lord, my lord.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Here comes the truth friends are you all.\n",
            "\n",
            "BUCKINGHAM:\n",
            "Then will not the lord, my lord;\n",
            "The direction for your\n",
            "\n",
            "\n",
            "Epoch: 21\n",
            "Train Loss: 1.799724292755127, Train Perplexity: 6.047979762687367, LR: 0.0001\n",
            "Validation Loss: 1.9684897661209106\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I do this contraction to my holy troth,\n",
            "And look to you may me breath of the death,\n",
            "Where the touching of your love hand brow,\n",
            "And by the poor of your drinks, and shows\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 22\n",
            "Train Loss: 1.7962175289789835, Train Perplexity: 6.026808070095437, LR: 0.0001\n",
            "Validation Loss: 1.9657660722732544\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Here are in the care in your mistress.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Here is the back of the world from the people.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Now in a more than is not price, if you be prove\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 23\n",
            "Train Loss: 1.7987756689389547, Train Perplexity: 6.0422452254340975, LR: 0.0001\n",
            "Validation Loss: 1.9668198823928833\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Pardon I beseech you, the grace your father hand\n",
            "Than you must die interce way at the more\n",
            "Than the duke of the fearful adversaries.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Sir, you think your\n",
            "\n",
            "\n",
            "Epoch: 24\n",
            "Train Loss: 1.794821818669637, Train Perplexity: 6.018402259342463, LR: 0.0001\n",
            "Validation Loss: 1.9614190459251404\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I think me in your allay, the seem is my heart.\n",
            "\n",
            "PAULINA:\n",
            "Good my father, I have lies the people;\n",
            "And yet me in his lovely son as his head.\n",
            "\n",
            "GREEN:\n",
            "The many haste of the\n",
            "\n",
            "\n",
            "Epoch: 25\n",
            "Train Loss: 1.7971532344818115, Train Perplexity: 6.032450026764415, LR: 0.0001\n",
            "Validation Loss: 1.9637700319290161\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "What, my lord?\n",
            "\n",
            "POMPEY:\n",
            "He is so to the direction, that you shall be met\n",
            "Because my tongue bosom thee and of their world.\n",
            "\n",
            "BUCKINGHAM:\n",
            "Hark! the remember you of a child \n",
            "\n",
            "\n",
            "Epoch: 26\n",
            "Train Loss: 1.7930585861206054, Train Perplexity: 6.007799766662642, LR: 0.0001\n",
            "Validation Loss: 1.9587818384170532\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Deserved you have done a sent of your beauty.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Why, sir; you have made you not been to my hand;\n",
            "Who do't bear it is your part, in your grace?\n",
            "\n",
            "DUKE VINCE\n",
            "\n",
            "\n",
            "Epoch: 27\n",
            "Train Loss: 1.793279778957367, Train Perplexity: 6.009128795916181, LR: 0.0001\n",
            "Validation Loss: 1.9657129049301147\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "When I can say you were may not be put one.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Northumberland, but thou that be so bear\n",
            "Which the man to stand upon thy former is word.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "I \n",
            "\n",
            "\n",
            "Epoch: 28\n",
            "Train Loss: 1.8007421414057414, Train Perplexity: 6.054138824692497, LR: 0.0001\n",
            "Validation Loss: 1.9634904265403748\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I do deserves your brother, you must deny sent.\n",
            "\n",
            "POLIXENES:\n",
            "He shall be should the matter strong than the rest.\n",
            "\n",
            "PRINCE EDWARD:\n",
            "My father of York, that do have I speak,\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 29\n",
            "Train Loss: 1.795305355389913, Train Perplexity: 6.021313081520238, LR: 0.0001\n",
            "Validation Loss: 1.9587387442588806\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I do not like show the last; for I saw to\n",
            "A words that been beggar shall have been my soul.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "You have been a shamed of death; I would not be such\n",
            "Be hang\n",
            "\n",
            "\n",
            "Epoch: 30\n",
            "Train Loss: 1.797028414408366, Train Perplexity: 6.031697102900002, LR: 0.0001\n",
            "Validation Loss: 1.9649407267570496\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I am I do not mine eyes man at the same to\n",
            "And I would wish an so my master sin and blood my daughter.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "A grave from men. There is that she way.\n",
            "\n",
            "Provost\n",
            "\n",
            "\n",
            "Epoch: 31\n",
            "Train Loss: 1.7961328347524008, Train Perplexity: 6.026297655862052, LR: 0.0001\n",
            "Validation Loss: 1.971890926361084\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "How I am a barr'd better begin to go the\n",
            "Should be than I might have been to the confess?\n",
            "\n",
            "BUCKINGHAM:\n",
            "Then we do me, and I will for thee for I\n",
            "Have some to the stoop th\n",
            "\n",
            "\n",
            "Epoch: 32\n",
            "Train Loss: 1.795654296875, Train Perplexity: 6.023414534069741, LR: 0.0001\n",
            "Validation Loss: 1.964854121208191\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I am sorry for this four highness bed.\n",
            "\n",
            "VIRGILIA:\n",
            "O, gentleman, believe me the fiery sovereign!\n",
            "In made the heavens of our friends,\n",
            "Such as so death as we to my fortune \n",
            "\n",
            "\n",
            "Epoch: 33\n",
            "Train Loss: 1.7929861664772033, Train Perplexity: 6.007364699699797, LR: 0.0001\n",
            "Validation Loss: 1.9531525373458862\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I thank your good my lord, and some other,\n",
            "And will cannot my brother with you;\n",
            "You were that stay you to the lambs not a warrant,\n",
            "That brains may we are to be as one to\n",
            "\n",
            "\n",
            "Epoch: 34\n",
            "Train Loss: 1.7955992420514424, Train Perplexity: 6.023082925173772, LR: 0.0001\n",
            "Validation Loss: 1.978383183479309\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I do not mine own my heart born to them babe,\n",
            "Which never wish be hold of me her beauty,\n",
            "Which was denied me doth for war; I am I do.\n",
            "\n",
            "BUCKINGHAM:\n",
            "He did I do this from \n",
            "\n",
            "\n",
            "Epoch: 35\n",
            "Train Loss: 1.7902782042821248, Train Perplexity: 5.991118989513031, LR: 0.0001\n",
            "Validation Loss: 1.9686300158500671\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I shall be done.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "I will say you.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "The princely since I call him as a tell\n",
            "As for you to an answer.\n",
            "\n",
            "PARIS:\n",
            "I will the friar to him that \n",
            "\n",
            "\n",
            "Epoch: 36\n",
            "Train Loss: 1.7951835672060648, Train Perplexity: 6.020579801388992, LR: 0.0001\n",
            "Validation Loss: 1.9453886151313782\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "You will make him to me to the safeguard;\n",
            "And you are month on to him of you to do.\n",
            "\n",
            "ABHORSON:\n",
            "What is your honour?\n",
            "\n",
            "POMPEY:\n",
            "Sir, if the morning hath he had speak it bee\n",
            "\n",
            "\n",
            "Epoch: 37\n",
            "Train Loss: 1.792352028687795, Train Perplexity: 6.0035564103466745, LR: 0.0001\n",
            "Validation Loss: 1.947898030281067\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Good morrow, your mother, noble must have leaved.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Well, I have seen thee, and married thee here.\n",
            "\n",
            "POMPEY:\n",
            "Sir, but I say, and so hath had as a bear.\n",
            "\n",
            "ES\n",
            "\n",
            "\n",
            "Epoch: 38\n",
            "Train Loss: 1.789979056517283, Train Perplexity: 5.9893270277024655, LR: 0.0001\n",
            "Validation Loss: 1.971941351890564\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "You must be married in this more word.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "No down me to do him.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "It is not to death, indeed.\n",
            "\n",
            "LUCIO:\n",
            "O more much a better, but than is my g\n",
            "\n",
            "\n",
            "Epoch: 39\n",
            "Train Loss: 1.7919899503389993, Train Perplexity: 6.0013830460425375, LR: 0.0001\n",
            "Validation Loss: 1.9708651304244995\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I have not do't.\n",
            "\n",
            "AUFIDIUS:\n",
            "And as 'twere as the gods of will.\n",
            "\n",
            "POLIXENES:\n",
            "No, sir; for you are so be so much extremes\n",
            "In every wounded weary one way in all.\n",
            "\n",
            "DUKE VINCE\n",
            "\n",
            "\n",
            "Epoch: 40\n",
            "Train Loss: 1.7916524012883503, Train Perplexity: 5.999357626751176, LR: 0.0001\n",
            "Validation Loss: 1.9664639234542847\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Down I will deliver it, I will speak not have\n",
            "Your hate of hath had not been a son,\n",
            "To prison any to the king's not love.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "The nor none property better w\n",
            "\n",
            "\n",
            "Epoch: 41\n",
            "Train Loss: 1.78858540058136, Train Perplexity: 5.980985780302683, LR: 0.0001\n",
            "Validation Loss: 1.9616608619689941\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "He will not me were it.\n",
            "\n",
            "PRINCE:\n",
            "Why, then I will be continue and your father's son.\n",
            "\n",
            "ABHORSON:\n",
            "He would have been any suit in your honours and\n",
            "But in your such with his\n",
            "\n",
            "\n",
            "Epoch: 42\n",
            "Train Loss: 1.7904406627019247, Train Perplexity: 5.9920923763022, LR: 0.0001\n",
            "Validation Loss: 1.9622327089309692\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "How I do bear me? shall have be that worthy so?\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Well, that means the matter to desire him.\n",
            "\n",
            "Provost:\n",
            "I pray you, my lord; I am pardon to be good.\n",
            "\n",
            "DUKE \n",
            "\n",
            "\n",
            "Epoch: 43\n",
            "Train Loss: 1.7916807492574056, Train Perplexity: 5.9995276987661175, LR: 0.0001\n",
            "Validation Loss: 1.963458001613617\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Death, my lord, what says I shall desire I be?\n",
            "\n",
            "POMPEY:\n",
            "Nay, being now made it, for a towith thee.\n",
            "\n",
            "ISABELLA:\n",
            "I would the see that the world.\n",
            "\n",
            "ANGELO:\n",
            "Thou wouldst thou \n",
            "\n",
            "\n",
            "Epoch: 44\n",
            "Train Loss: 1.7874746481577555, Train Perplexity: 5.974346074069221, LR: 0.0001\n",
            "Validation Loss: 1.9734737873077393\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Here is no room and afflicts to do them.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "I think you to be dispatch.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "I am all accused in the stand bears to be supposed;\n",
            "Which is your \n",
            "\n",
            "\n",
            "Epoch: 45\n",
            "Train Loss: 1.7900142828623453, Train Perplexity: 5.989538013519142, LR: 0.0001\n",
            "Validation Loss: 1.9501537084579468\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I am all for your good night; I have done that\n",
            "the to do speak my tongue for him.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "But shall not be made me for the base, and say\n",
            "deposed manner a foolis\n",
            "\n",
            "\n",
            "Epoch: 46\n",
            "Train Loss: 1.786555818716685, Train Perplexity: 5.96885919014649, LR: 0.0001\n",
            "Validation Loss: 1.9626736044883728\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I do mercy, for I come, and I will find a short.\n",
            "\n",
            "PARIS:\n",
            "The dead hath done shame to thee honour with\n",
            "the field thee die to thy love me to thy death.\n",
            "\n",
            "JOHN OF GAUNT:\n",
            "I h\n",
            "\n",
            "\n",
            "Epoch: 47\n",
            "Train Loss: 1.786331880092621, Train Perplexity: 5.967522681685734, LR: 0.0001\n",
            "Validation Loss: 1.9798952341079712\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Why, I say, I say, sir, have I was for thee?\n",
            "\n",
            "BAPTISTA:\n",
            "Here comes must I will tell me and let him.\n",
            "\n",
            "KING RICHARD II:\n",
            "Ay, madam, you must not be but a gentleman.\n",
            "\n",
            "PRINCE\n",
            "\n",
            "\n",
            "Epoch: 48\n",
            "Train Loss: 1.7842806021372477, Train Perplexity: 5.955294180276151, LR: 0.0001\n",
            "Validation Loss: 1.9665471911430359\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "When I was an in an barren and brains, and heart\n",
            "I thank your death. We did stricted my tender him,\n",
            "With the people at all your hands heart\n",
            "Upon his life. Your father's \n",
            "\n",
            "\n",
            "Epoch: 49\n",
            "Train Loss: 1.7896876215934754, Train Perplexity: 5.987581782961475, LR: 0.0001\n",
            "Validation Loss: 1.960686206817627\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Go, go, and you both, to give me not the king.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Now it shall not to my confessio.\n",
            "This is a charity and friend the cares of grace\n",
            "I do the people, the sh\n",
            "\n",
            "\n",
            "Epoch: 50\n",
            "Train Loss: 1.785895844300588, Train Perplexity: 5.964921195418531, LR: 0.0001\n",
            "Validation Loss: 1.9499329328536987\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "What will then I will see here in heart?\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "She worship, a wife, and her dead love a word.\n",
            "Therefore live to say a look'd from the law;\n",
            "And therefore shall\n",
            "\n",
            "\n",
            "Epoch: 51\n",
            "Train Loss: 1.783212125301361, Train Perplexity: 5.948934484592438, LR: 0.0001\n",
            "Validation Loss: 1.9567883610725403\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO: I shall hear you have too much\n",
            "The from of the first me dead of mine.\n",
            "\n",
            "PAUGE:\n",
            "You may be so.\n",
            "\n",
            "ESCALUS:\n",
            "We shall swear of all hear your power.\n",
            "\n",
            "ESCALUS:\n",
            "How far the bell?\n",
            "\n",
            "\n",
            "Epoch: 52\n",
            "Train Loss: 1.7855948170026144, Train Perplexity: 5.963125861544259, LR: 0.0001\n",
            "Validation Loss: 1.964343011379242\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "When I shall we have here the rest for thee?\n",
            "\n",
            "BUCKINGHAM:\n",
            "Her lived in all soon thy tongue to his hand,\n",
            "It come to be but a party of mine and persuade\n",
            "Of a land-mortal p\n",
            "\n",
            "\n",
            "Epoch: 53\n",
            "Train Loss: 1.7863515496253968, Train Perplexity: 5.967640061223109, LR: 0.0001\n",
            "Validation Loss: 1.9663426876068115\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "How now, I have not a court is too much\n",
            "That I would the gallow for him?\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Not home, sir, my lord.\n",
            "\n",
            "Provost:\n",
            "How should have been a pretty of the war\n",
            "thes\n",
            "\n",
            "\n",
            "Epoch: 54\n",
            "Train Loss: 1.7830770015716553, Train Perplexity: 5.948130696683737, LR: 0.0001\n",
            "Validation Loss: 1.9545392990112305\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "How now, my lord?\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "I think you, sir, I have done to been a more.\n",
            "\n",
            "POMPEY:\n",
            "I cannot the blood stand upon the limit of such\n",
            "as it as a play is court: there\n",
            "\n",
            "\n",
            "Epoch: 55\n",
            "Train Loss: 1.7847588459650676, Train Perplexity: 5.958142944108283, LR: 0.0001\n",
            "Validation Loss: 1.9588719606399536\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "How I am in my courteous blood for a cold\n",
            "And lady apparent and bed her a maid?\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Sir, I would they have a tongue as a departure\n",
            "that a man made more for \n",
            "\n",
            "\n",
            "Epoch: 56\n",
            "Train Loss: 1.7819584210713704, Train Perplexity: 5.9414809535031665, LR: 0.0001\n",
            "Validation Loss: 1.9792653322219849\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO: this mark is the first of the house,\n",
            "Or all as a confirm that the crown have that made\n",
            "The pretty died in her well before the father's love.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Then farthe\n",
            "\n",
            "\n",
            "Epoch: 57\n",
            "Train Loss: 1.7840203364690146, Train Perplexity: 5.953744423339807, LR: 0.0001\n",
            "Validation Loss: 1.9656495451927185\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "You are a servant of mother; I am sure better and\n",
            "Than your with your hands in the matter.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "And he do you will the depart.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "The duke that\n",
            "\n",
            "\n",
            "Epoch: 58\n",
            "Train Loss: 1.7790300726890564, Train Perplexity: 5.924107677282062, LR: 0.0001\n",
            "Validation Loss: 1.9653847217559814\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "What says then?\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Why, I would you do not have been great stain'd?\n",
            "\n",
            "BUCKINGHAM:\n",
            "Well, my lord.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Ay, my lord.\n",
            "\n",
            "KING RICHARD II:\n",
            "Why, what t\n",
            "\n",
            "\n",
            "Epoch: 59\n",
            "Train Loss: 1.7818457682927449, Train Perplexity: 5.940811666863811, LR: 0.0001\n",
            "Validation Loss: 1.9583656191825867\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Good my lord, I doubt not to myself you and me.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Sir, you are a such a precious a man\n",
            "To beseech you, a cause of your with a profit the\n",
            "causes of your br\n",
            "\n",
            "\n",
            "Epoch: 60\n",
            "Train Loss: 1.7827940424283346, Train Perplexity: 5.946447856816136, LR: 0.0001\n",
            "Validation Loss: 1.960514783859253\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Why, I have all the world the life will have heart\n",
            "With a sister for your good love.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "So think you are too true.\n",
            "\n",
            "BUCKINGHAM:\n",
            "Well, sir, if you were but \n",
            "\n",
            "\n",
            "Epoch: 61\n",
            "Train Loss: 1.7790581345558167, Train Perplexity: 5.924273921134921, LR: 0.0001\n",
            "Validation Loss: 1.9555978178977966\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Go, the mark is face of death.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "I do dear my power said at my lord.\n",
            "\n",
            "ANGELO:\n",
            "I will and thee, my lord.\n",
            "\n",
            "ISABELLA:\n",
            "Do you me not?\n",
            "\n",
            "ANGELO:\n",
            "Good morrow the\n",
            "\n",
            "\n",
            "Epoch: 62\n",
            "Train Loss: 1.7792463382085164, Train Perplexity: 5.9253889960537665, LR: 0.0001\n",
            "Validation Loss: 1.9694874286651611\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Here are no more.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Then, I am doubt.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "I hear my lord of his honour lords;\n",
            "But I have seen made hearts many short a dismal bosom.\n",
            "\n",
            "DUKE VI\n",
            "\n",
            "\n",
            "Epoch: 63\n",
            "Train Loss: 1.7782228271166483, Train Perplexity: 5.919327397278628, LR: 0.0001\n",
            "Validation Loss: 1.9447978734970093\n",
            "Model saved at /content/drive/MyDrive/ShakGPT_3_512.pt\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Not be thy father sick, I will find thee a dead.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Faith, I speak no more.\n",
            "\n",
            "ISABELLA:\n",
            "Say, where is a should have a thousand with him?\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Si\n",
            "\n",
            "\n",
            "Epoch: 64\n",
            "Train Loss: 1.7792656421661377, Train Perplexity: 5.92550338061587, LR: 0.0001\n",
            "Validation Loss: 1.9669257402420044\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "What then?\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "How will you to the duke and well of the king?\n",
            "\n",
            "POMPEY:\n",
            "Yet once so to sight, father is that would I committed\n",
            "the strong all the warlike in \n",
            "\n",
            "\n",
            "Epoch: 65\n",
            "Train Loss: 1.7798825939496359, Train Perplexity: 5.929160258437319, LR: 0.0001\n",
            "Validation Loss: 1.9707974195480347\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "How! I dost my father?\n",
            "\n",
            "PAUREY:\n",
            "If God's right, and there is like to meet,\n",
            "That makes your good friends, and his life,\n",
            "He double love to many means have less.\n",
            "\n",
            "KING RICH\n",
            "\n",
            "\n",
            "Epoch: 66\n",
            "Train Loss: 1.7766311287879943, Train Perplexity: 5.909913108095398, LR: 0.0001\n",
            "Validation Loss: 1.9781218767166138\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "He comes are a more of your wish'd at love.\n",
            "\n",
            "PRINCE:\n",
            "Ay, but your father's sake a son of of imposition,\n",
            "And the people of our removed come.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Thou shalt b\n",
            "\n",
            "\n",
            "Epoch: 67\n",
            "Train Loss: 1.7804357687632242, Train Perplexity: 5.932441027893872, LR: 0.0001\n",
            "Validation Loss: 1.9637433290481567\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I will be the found that would not so much.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Go you think it well to me; if the report it will\n",
            "I have too true.\n",
            "\n",
            "PARIS:\n",
            "Go to, go much I have done all th\n",
            "\n",
            "\n",
            "Epoch: 68\n",
            "Train Loss: 1.7801442702611288, Train Perplexity: 5.930711982239823, LR: 0.0001\n",
            "Validation Loss: 1.965946912765503\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I do not pass, in this face for the great your freeling:\n",
            "The more beating thanks, and I the windows.\n",
            "\n",
            "PARIS:\n",
            "This wisdom more souls than the lawful that these sound\n",
            "When\n",
            "\n",
            "\n",
            "Epoch: 69\n",
            "Train Loss: 1.7729344288508098, Train Perplexity: 5.888106264192788, LR: 0.0001\n",
            "Validation Loss: 1.9633370637893677\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO: I think you, for I have a thousand as\n",
            "Have done the gate of death.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Not so, my lord, whose stands it is a double think.\n",
            "\n",
            "Provost:\n",
            "I have done.\n",
            "\n",
            "DUKE VINC\n",
            "\n",
            "\n",
            "Epoch: 70\n",
            "Train Loss: 1.77978622118632, Train Perplexity: 5.928588876412346, LR: 0.0001\n",
            "Validation Loss: 1.9673535227775574\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "When I may see here, I will friend thee must be\n",
            "And his hand as we are their courses; which shall I see thee,\n",
            "To die them for this death.\n",
            "\n",
            "BALTHASAR:\n",
            "Marry, that it shal\n",
            "\n",
            "\n",
            "Epoch: 71\n",
            "Train Loss: 1.7770776430765787, Train Perplexity: 5.912552557974643, LR: 0.0001\n",
            "Validation Loss: 1.9578198194503784\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I do beseech you, I pray you, to show from your best.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "You have made you are a too tribunes in his\n",
            "noble can of all our countrymen in bloody as we heart\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 72\n",
            "Train Loss: 1.7726759274800619, Train Perplexity: 5.886584377365775, LR: 0.0001\n",
            "Validation Loss: 1.9893385171890259\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Why, I shall not stay are all, and the formerle.\n",
            "\n",
            "BAGOT:\n",
            "Ah, I will shame you some and me now to stay.\n",
            "\n",
            "HENRY BOLINGBROKE:\n",
            "What means have your honour for words?\n",
            "\n",
            "DUKE O\n",
            "\n",
            "\n",
            "Epoch: 73\n",
            "Train Loss: 1.77804430325826, Train Perplexity: 5.918270750433744, LR: 0.0001\n",
            "Validation Loss: 1.948406994342804\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Death the most lie love, I cannot be not.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "You have made the cause to sense him that shall have\n",
            "The time to your blood the king soul.\n",
            "\n",
            "LORD ROSS:\n",
            "I am a \n",
            "\n",
            "\n",
            "Epoch: 74\n",
            "Train Loss: 1.7732793807983398, Train Perplexity: 5.890137728274487, LR: 0.0001\n",
            "Validation Loss: 1.9651018977165222\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO: I have thee, as you so as I must be.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "And you shall there be content.\n",
            "\n",
            "BUCKINGHAM:\n",
            "I will to you, my lord, in peace of the heart,\n",
            "In that you do many a m\n",
            "\n",
            "\n",
            "Epoch: 75\n",
            "Train Loss: 1.7729750672976177, Train Perplexity: 5.888345552548126, LR: 0.0001\n",
            "Validation Loss: 1.9521079063415527\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I think you, I would not the prince in the ground;\n",
            "The more that you shall to him at him still these die.\n",
            "\n",
            "PAULINA:\n",
            "What men?\n",
            "\n",
            "BENVOLIO:\n",
            "If I shall be a proceeding with \n",
            "\n",
            "\n",
            "Epoch: 76\n",
            "Train Loss: 1.7760242541631064, Train Perplexity: 5.906327619875754, LR: 0.0001\n",
            "Validation Loss: 1.9720342755317688\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO: I have done to see that I have not been\n",
            "I show'd in the moon, hold the gave to their faults\n",
            "Which oft my party brother love out\n",
            "To morrow and possible pardon with our fa\n",
            "\n",
            "\n",
            "Epoch: 77\n",
            "Train Loss: 1.7746087312698364, Train Perplexity: 5.897972992392918, LR: 0.0001\n",
            "Validation Loss: 1.9580316543579102\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "He was better with the deny than you were would\n",
            "But you to the people the duke of the fortune.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "I will give you are better with him being the boar,\n",
            "The p\n",
            "\n",
            "\n",
            "Epoch: 78\n",
            "Train Loss: 1.772384802500407, Train Perplexity: 5.884870895039533, LR: 0.0001\n",
            "Validation Loss: 1.9616142511367798\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "He has been die, and I will show you have a grave;\n",
            "The worth will better than did of her eyes.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Well, well all the morning at once that I see\n",
            "That her my\n",
            "\n",
            "\n",
            "Epoch: 79\n",
            "Train Loss: 1.7700859864552816, Train Perplexity: 5.871358196956824, LR: 0.0001\n",
            "Validation Loss: 1.9599050283432007\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO: then I thank thee to me with you;\n",
            "Who should that the beggar the town his most of person\n",
            "And present with my soul things but the weakness.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "That he shall\n",
            "\n",
            "\n",
            "Epoch: 80\n",
            "Train Loss: 1.7733062187830606, Train Perplexity: 5.890295809822128, LR: 0.0001\n",
            "Validation Loss: 1.9829370975494385\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO: I say, gentle I see your sorrow!\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "I have not made in my heart shall be when I peril.\n",
            "\n",
            "AUTOLYCUS:\n",
            "I will thee a stay with some for the law all.\n",
            "\n",
            "ISABELLA:\n",
            "\n",
            "\n",
            "Epoch: 81\n",
            "Train Loss: 1.7675227165222167, Train Perplexity: 5.8563275930016045, LR: 0.0001\n",
            "Validation Loss: 1.9578616619110107\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "You have made me to your daughter to my cheeks.\n",
            "\n",
            "PAUk:\n",
            "Then the live with the world friend, and the royal.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Bring me as like to live; but if I mistress\n",
            "I\n",
            "\n",
            "\n",
            "Epoch: 82\n",
            "Train Loss: 1.7692801753679912, Train Perplexity: 5.866628897141283, LR: 0.0001\n",
            "Validation Loss: 1.991162896156311\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Stay, a prince, I have found that forth\n",
            "The tender of your love me to your brother and hear me:\n",
            "I have seen and me to your brother call'd to myself,\n",
            "Than my husband brot\n",
            "\n",
            "\n",
            "Epoch: 83\n",
            "Train Loss: 1.77086474498113, Train Perplexity: 5.875932348059426, LR: 0.0001\n",
            "Validation Loss: 1.9636786580085754\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "He hath been with a did death; and it is not.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "He shall not be the princely dangerous it.\n",
            "\n",
            "BARNARDINE:\n",
            "The gods begin of my sight, the more of this\n",
            "Where\n",
            "\n",
            "\n",
            "Epoch: 84\n",
            "Train Loss: 1.7691658059755961, Train Perplexity: 5.86595797272625, LR: 0.0001\n",
            "Validation Loss: 1.9567644000053406\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Here no more in than here for the law a woman.\n",
            "\n",
            "PAULINA:\n",
            "I would they were peril and have no pardon.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Here is your dead mercy, if you must deny have\n",
            "Of y\n",
            "\n",
            "\n",
            "Epoch: 85\n",
            "Train Loss: 1.765777858098348, Train Perplexity: 5.846118040170427, LR: 0.0001\n",
            "Validation Loss: 1.9552912712097168\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Here all the made the royal foot and house,\n",
            "And to be pass do you to a strange: if this good man\n",
            "To her hand you be gone and proceed in mine\n",
            "With harm'd that shall be co\n",
            "\n",
            "\n",
            "Epoch: 86\n",
            "Train Loss: 1.7680869062741598, Train Perplexity: 5.85963260525295, LR: 0.0001\n",
            "Validation Loss: 1.9645441770553589\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO: then I say, I think thee here.\n",
            "\n",
            "AUTOLYCUS:\n",
            "Here thou art the boy stale.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Why, and you have you both mine eyes and be presently\n",
            "Shall I cannot be stoop'd \n",
            "\n",
            "\n",
            "Epoch: 87\n",
            "Train Loss: 1.7693564295768738, Train Perplexity: 5.867076269343432, LR: 0.0001\n",
            "Validation Loss: 1.9783708453178406\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "He has a brother with a bold that both would have\n",
            "A play thing is both our duty.\n",
            "\n",
            "POLIXENES:\n",
            "You know that I may myself and so much.\n",
            "\n",
            "HENRY BOLINGBROKE:\n",
            "I have been a br\n",
            "\n",
            "\n",
            "Epoch: 88\n",
            "Train Loss: 1.7643670121828714, Train Perplexity: 5.83787588398541, LR: 0.0001\n",
            "Validation Loss: 1.9627007246017456\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO: good madam, I do not myself.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Pray you, I know not to be not the run farm;\n",
            "Which we have done of my life dead for him.\n",
            "Well, we stay, what is it do your \n",
            "\n",
            "\n",
            "Epoch: 89\n",
            "Train Loss: 1.766015068689982, Train Perplexity: 5.8475049657797165, LR: 0.0001\n",
            "Validation Loss: 1.9578106999397278\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "You shall be matter disposition.\n",
            "\n",
            "PERIAR PAUREN:\n",
            "That which the poor of my poor mine eyes,\n",
            "That must be gone.\n",
            "\n",
            "PARIS:\n",
            "Then my father's body thing to from hence,\n",
            "That she\n",
            "\n",
            "\n",
            "Epoch: 90\n",
            "Train Loss: 1.7687274773915609, Train Perplexity: 5.863387319110693, LR: 0.0001\n",
            "Validation Loss: 1.9757084250450134\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Good my lord, I do do thee, my lord; for this is a\n",
            "You make a great dead of hear the man.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "A word, and thou mayst as the gallant send to heart.\n",
            "\n",
            "BUCKINGH\n",
            "\n",
            "\n",
            "Epoch: 91\n",
            "Train Loss: 1.766792352994283, Train Perplexity: 5.852051906512844, LR: 0.0001\n",
            "Validation Loss: 1.9718841314315796\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Peace, I hope to privilege thee, and for a gentleman:\n",
            "God knee thou a broken as for thy speech!\n",
            "\n",
            "PARIS:\n",
            "I do me, as I say, love a will be gone,\n",
            "My lord, thou hast as if \n",
            "\n",
            "\n",
            "Epoch: 92\n",
            "Train Loss: 1.7658508658409118, Train Perplexity: 5.846544867631966, LR: 0.0001\n",
            "Validation Loss: 1.979671597480774\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I am a too: I am too bring in this time;\n",
            "And will not so do not her it.\n",
            "\n",
            "BAPTISTA:\n",
            "Good night, I will not my son.\n",
            "\n",
            "KING RICHARD II:\n",
            "Be should not so long, as it to and t\n",
            "\n",
            "\n",
            "Epoch: 93\n",
            "Train Loss: 1.7617974718411764, Train Perplexity: 5.822894482292652, LR: 0.0001\n",
            "Validation Loss: 1.9704850316047668\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I do beseech you, my lordship for you,\n",
            "I do not for your prayers and your bed.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "I do beseech you, the fault of your grace\n",
            "Which you are you stood.\n",
            "\n",
            "BUCKI\n",
            "\n",
            "\n",
            "Epoch: 94\n",
            "Train Loss: 1.763072923819224, Train Perplexity: 5.830326042869915, LR: 0.0001\n",
            "Validation Loss: 1.9716643691062927\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Pray you, my lord, for this news.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Good lord, in him and and him.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "He doth sit in his promise that is high began.\n",
            "\n",
            "PARIS:\n",
            "He mad of love \n",
            "\n",
            "\n",
            "Epoch: 95\n",
            "Train Loss: 1.767989710966746, Train Perplexity: 5.859063104137417, LR: 0.0001\n",
            "Validation Loss: 1.9637573957443237\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO: I do much do not like a man\n",
            "With such a dead sayt in the cause of men\n",
            "To do with me and leave him with him at and look.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "The light is my lord.\n",
            "\n",
            "BARNARDIN\n",
            "\n",
            "\n",
            "Epoch: 96\n",
            "Train Loss: 1.7631212552388509, Train Perplexity: 5.83060783761417, LR: 0.0001\n",
            "Validation Loss: 1.9679122567176819\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "You have made them been a traitor dream a man,\n",
            "That I may not from my cheeks your father's beauty,\n",
            "Or an old be presently be your brother's son,\n",
            "In the earth and life of\n",
            "\n",
            "\n",
            "Epoch: 97\n",
            "Train Loss: 1.7622544844945272, Train Perplexity: 5.825556226929347, LR: 0.0001\n",
            "Validation Loss: 1.957559585571289\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Here not so requite the news that day;\n",
            "And in the seal of his army day in the prince\n",
            "That service the stands of love and see merry breathe.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "And where he\n",
            "\n",
            "\n",
            "Epoch: 98\n",
            "Train Loss: 1.7627609610557555, Train Perplexity: 5.828507481922057, LR: 0.0001\n",
            "Validation Loss: 1.9620875716209412\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "So sorrow that I was my father desperate are;\n",
            "And I do not know thee summer of the blood.\n",
            "\n",
            "BARNARDINE:\n",
            "Good night! but dangerous may with the rest.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "What\n",
            "\n",
            "\n",
            "Epoch: 99\n",
            "Train Loss: 1.7653275648752849, Train Perplexity: 5.843486165437859, LR: 0.0001\n",
            "Validation Loss: 1.9545177817344666\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "What this? no, my lord.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Not all my mind holy to die.\n",
            "\n",
            "Provost:\n",
            "Are you not do not be so seen him?\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "That satisfied and rather the name of\n",
            "\n",
            "\n",
            "Epoch: 100\n",
            "Train Loss: 1.7634294231732686, Train Perplexity: 5.832404920875383, LR: 0.0001\n",
            "Validation Loss: 1.9594643712043762\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Why, I would there I had heard thee with this son\n",
            "That shall be crown'd his man do be my brother's.\n",
            "What bound is the day between the house of Lancaster?\n",
            "The false heave\n",
            "\n",
            "\n",
            "Epoch: 101\n",
            "Train Loss: 1.7633946895599366, Train Perplexity: 5.832202343896202, LR: 0.0001\n",
            "Validation Loss: 1.9831949472427368\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I pray thee, good dear thou shalt not be.\n",
            "\n",
            "PRINCE:\n",
            "So long as the fair drunk, and dreams of my friendly.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "So do you love and die of the market-place, whi\n",
            "\n",
            "\n",
            "Epoch: 102\n",
            "Train Loss: 1.762812868754069, Train Perplexity: 5.828810034182374, LR: 0.0001\n",
            "Validation Loss: 1.9645723104476929\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Pray you, sir, noble I shall should I have been down.\n",
            "\n",
            "PAUGE:\n",
            "He hath heard of breathed the was from me.\n",
            "\n",
            "BUCKINGHAM:\n",
            "Some with you and say, I pray, but love.\n",
            "\n",
            "GREMIO:\n",
            "A\n",
            "\n",
            "\n",
            "Epoch: 103\n",
            "Train Loss: 1.7582379539807638, Train Perplexity: 5.802204630178018, LR: 0.0001\n",
            "Validation Loss: 1.9335967302322388\n",
            "Model saved at /content/drive/MyDrive/ShakGPT_3_512.pt\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Gentlemen, I may are all to thee friends.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Ay, be it be baches and more for than all the world.\n",
            "\n",
            "PARIS:\n",
            "How long may do you, my lord?\n",
            "\n",
            "JULIET:\n",
            "I have a g\n",
            "\n",
            "\n",
            "Epoch: 104\n",
            "Train Loss: 1.7593616167704265, Train Perplexity: 5.808728015975521, LR: 0.0001\n",
            "Validation Loss: 1.9519594311714172\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "You do remember me to the mark of such a lord.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "I promised, where is not proclaim your will.\n",
            "\n",
            "LADY ANNE:\n",
            "I shall seem my thier thing we would I were a\n",
            "A \n",
            "\n",
            "\n",
            "Epoch: 105\n",
            "Train Loss: 1.761070974667867, Train Perplexity: 5.818665702195176, LR: 0.0001\n",
            "Validation Loss: 1.966551423072815\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "You are man are you do not with your servants;\n",
            "What shall have your mother of this father?\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Ay, alas, if you were they shall for his beauty\n",
            "To prison, to\n",
            "\n",
            "\n",
            "Epoch: 106\n",
            "Train Loss: 1.7592729449272155, Train Perplexity: 5.808212968191088, LR: 0.0001\n",
            "Validation Loss: 1.9640191793441772\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I do beseech you, my lords, for I would I had\n",
            "The king's face.\n",
            "\n",
            "PAUTIUS:\n",
            "Go, I'll not hear your honour.\n",
            "\n",
            "AUTOLYCUS:\n",
            "He senators, sir:\n",
            "He has he has own cousin, that I sh\n",
            "\n",
            "\n",
            "Epoch: 107\n",
            "Train Loss: 1.7570542256037394, Train Perplexity: 5.795340459366375, LR: 0.0001\n",
            "Validation Loss: 1.962484061717987\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I have no fought to be seen a thousand.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Why, that is not the king? senate thy form\n",
            "That lives a prince in the service of his found?\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "No,\n",
            "\n",
            "\n",
            "Epoch: 108\n",
            "Train Loss: 1.7567027489344278, Train Perplexity: 5.793303890328407, LR: 0.0001\n",
            "Validation Loss: 1.9619255065917969\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "So shall I know the for the deed.\n",
            "\n",
            "PAURIO:\n",
            "Why, how I shall shall not be the dukedom my complaint?\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "No, sir, not have you been say.\n",
            "\n",
            "LUCIO:\n",
            "I will do sta\n",
            "\n",
            "\n",
            "Epoch: 109\n",
            "Train Loss: 1.7606819113095602, Train Perplexity: 5.816402312905685, LR: 0.0001\n",
            "Validation Loss: 1.983702540397644\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Good my soul as I had lord life done to give;\n",
            "And look the man in the way to go with the towns,\n",
            "I wish an extreme in his sword with the seas,\n",
            "To make him from the presen\n",
            "\n",
            "\n",
            "Epoch: 110\n",
            "Train Loss: 1.760832464694977, Train Perplexity: 5.81727805788637, LR: 0.0001\n",
            "Validation Loss: 1.9649630784988403\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I pray thee, as I am not pretty for myself;\n",
            "For this business and so as I did speak him:\n",
            "I would not stay the house of his body.\n",
            "\n",
            "ABHORSON:\n",
            "God and lords, sir, and all t\n",
            "\n",
            "\n",
            "Epoch: 111\n",
            "Train Loss: 1.7555807828903198, Train Perplexity: 5.786807645045031, LR: 0.0001\n",
            "Validation Loss: 1.9669599533081055\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "How have I say, in the cause! I will not for I,\n",
            "I have to been a man, and shall not see\n",
            "For her be noted to fair enter her die.\n",
            "\n",
            "PAULINA:\n",
            "I'll discover thee and goes to \n",
            "\n",
            "\n",
            "Epoch: 112\n",
            "Train Loss: 1.7577160835266112, Train Perplexity: 5.799177420986804, LR: 0.0001\n",
            "Validation Loss: 1.9754300117492676\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Dear me, brought you the proclaim in the duke.\n",
            "\n",
            "PRINCE EDWARD:\n",
            "I would be a second to the rough.\n",
            "\n",
            "KING RICHARD II:\n",
            "Why, then the prince of Edward and Warwick,\n",
            "And thou b\n",
            "\n",
            "\n",
            "Epoch: 113\n",
            "Train Loss: 1.7555135369300843, Train Perplexity: 5.786418518691976, LR: 0.0001\n",
            "Validation Loss: 1.9703433513641357\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Shall I be not the cause I be straight?\n",
            "\n",
            "POMPEY:\n",
            "What, is a bold with a disorted with the difference?\n",
            "\n",
            "POMPEY:\n",
            "I shall not see thee to shall be thy conscience,\n",
            "I say tho\n",
            "\n",
            "\n",
            "Epoch: 114\n",
            "Train Loss: 1.7548005779584248, Train Perplexity: 5.782294509994488, LR: 0.0001\n",
            "Validation Loss: 1.9793056845664978\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Have I not forget thee to any prove a death,\n",
            "And I am too fair.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Sir, the your dispositions march\n",
            "Since with me so fair subdues to dead,\n",
            "That I may part \n",
            "\n",
            "\n",
            "Epoch: 115\n",
            "Train Loss: 1.7550079425175984, Train Perplexity: 5.783493677274665, LR: 0.0001\n",
            "Validation Loss: 1.9747728109359741\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Why, then the market-have done, madam.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "I hear no power.\n",
            "\n",
            "Provost:\n",
            "Why, then she still see words the sword subject that\n",
            "My strive better\n",
            "\n",
            "\n",
            "Epoch: 116\n",
            "Train Loss: 1.753580391407013, Train Perplexity: 5.775243334746543, LR: 0.0001\n",
            "Validation Loss: 1.9479435682296753\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I will so that not a wing that to be done.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "You are to this father.\n",
            "\n",
            "PARIS:\n",
            "It is a man not doth so far off my weary foe.\n",
            "\n",
            "MARIANA:\n",
            "No, good my lord; I t\n",
            "\n",
            "\n",
            "Epoch: 117\n",
            "Train Loss: 1.754200247923533, Train Perplexity: 5.778824266679416, LR: 0.0001\n",
            "Validation Loss: 1.959136962890625\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "You may not please you and fellow your country:\n",
            "The king many people down me from his shop's bosom;\n",
            "And say you shall shall feel the rest in heaven,\n",
            "And many serves in o\n",
            "\n",
            "\n",
            "Epoch: 118\n",
            "Train Loss: 1.753523623943329, Train Perplexity: 5.774915498135586, LR: 0.0001\n",
            "Validation Loss: 1.950620174407959\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Good my lord, I do deny to do sing of the crown;\n",
            "If they shall be the requend to the king.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "What, madam? what is your doth have this?\n",
            "\n",
            "Provost:\n",
            "Do, sir, \n",
            "\n",
            "\n",
            "Epoch: 119\n",
            "Train Loss: 1.7518341422080994, Train Perplexity: 5.765167121050281, LR: 0.0001\n",
            "Validation Loss: 1.9538663625717163\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "You have the prince in a dispatch'd the with the houses\n",
            "Have like a town him in his for the air,\n",
            "Then weeping the walls of the deed world.\n",
            "\n",
            "ABHORSON:\n",
            "A looks in bloody t\n",
            "\n",
            "\n",
            "Epoch: 120\n",
            "Train Loss: 1.7520654320716857, Train Perplexity: 5.76650069998296, LR: 0.0001\n",
            "Validation Loss: 1.9601525664329529\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Why, noble that we may be right noble wise,\n",
            "And I am no longer and the baits of all.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "The same of death, then by the words of death,\n",
            "When it best against\n",
            "\n",
            "\n",
            "Epoch: 121\n",
            "Train Loss: 1.7505682667096456, Train Perplexity: 5.757873754468212, LR: 0.0001\n",
            "Validation Loss: 1.9662173986434937\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I am myself and so, what I cannot do desperate\n",
            "Her brother to answer by my true love.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "You may not a draw the sun of you deliver'd.\n",
            "\n",
            "AUTOLYCUS:\n",
            "I know th\n",
            "\n",
            "\n",
            "Epoch: 122\n",
            "Train Loss: 1.750567861398061, Train Perplexity: 5.757871420735751, LR: 0.0001\n",
            "Validation Loss: 1.9630548357963562\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Yet I do much as I must eye see that I have.\n",
            "\n",
            "PARIS:\n",
            "How now, my lord!\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "As I thank you have done words, you have todied\n",
            "May some one against your good de\n",
            "\n",
            "\n",
            "Epoch: 123\n",
            "Train Loss: 1.751248308022817, Train Perplexity: 5.761790678181298, LR: 0.0001\n",
            "Validation Loss: 1.9609583616256714\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "God give me against you, gentle joyful banish.\n",
            "\n",
            "ABHORSON:\n",
            "And I may a carried all that I could make him:\n",
            "Then let him in his master live to child; but I have\n",
            "learned it \n",
            "\n",
            "\n",
            "Epoch: 124\n",
            "Train Loss: 1.7518303592999775, Train Perplexity: 5.765145311994005, LR: 0.0001\n",
            "Validation Loss: 1.9703938364982605\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I will them as I do begin to this tongue.\n",
            "\n",
            "PERDITA:\n",
            "You are more advantage of the power\n",
            "That I must not see thee where I beseech you.\n",
            "I shall to hear your cousins you ha\n",
            "\n",
            "\n",
            "Epoch: 125\n",
            "Train Loss: 1.74925088485082, Train Perplexity: 5.750293430225789, LR: 0.0001\n",
            "Validation Loss: 1.9665976762771606\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Pray you, let me some friend you were I can\n",
            "Were a torment dark of name not.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "How now! my chance, I say! my fault is the root?\n",
            "\n",
            "AUFIDIUS:\n",
            "What news?\n",
            "\n",
            "AUF\n",
            "\n",
            "\n",
            "Epoch: 126\n",
            "Train Loss: 1.7483828981717429, Train Perplexity: 5.74530441763903, LR: 0.0001\n",
            "Validation Loss: 1.9641010165214539\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "You shall have no man no with me stand the first speak.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Not you have done, not an your grace doth her honour,\n",
            "With the land of mouth and sear brothers i\n",
            "\n",
            "\n",
            "Epoch: 127\n",
            "Train Loss: 1.7495180090268454, Train Perplexity: 5.751829677795541, LR: 0.0001\n",
            "Validation Loss: 1.9815459251403809\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I will stay we have a tongue to be made.\n",
            "\n",
            "PRINCE:\n",
            "I shall strive a grave be long a word,\n",
            "And lay amend to the set my brother of my son,\n",
            "So that I have been so courtesy, \n",
            "\n",
            "\n",
            "Epoch: 128\n",
            "Train Loss: 1.750884461402893, Train Perplexity: 5.759694651457576, LR: 0.0001\n",
            "Validation Loss: 1.9889466762542725\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "What says that? I have not heard the crown, I am\n",
            "And to my proceed to the king.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "And you have no been did but my proved\n",
            "Of that did not before I may be t\n",
            "\n",
            "\n",
            "Epoch: 129\n",
            "Train Loss: 1.7509927153587341, Train Perplexity: 5.760318194937948, LR: 0.0001\n",
            "Validation Loss: 1.9588019847869873\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "You do bear me brother.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Not be the noble bold to be ruled.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Be not be a duckrding to your draw the honour.\n",
            "\n",
            "ANGELO:\n",
            "What is the words of\n",
            "\n",
            "\n",
            "Epoch: 130\n",
            "Train Loss: 1.7463290055592855, Train Perplexity: 5.733516289258214, LR: 0.0001\n",
            "Validation Loss: 1.9768699407577515\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I have not for a warrant born bear this.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Not hear his faith sent with his palmers from him:\n",
            "The people in a best his reason his fears again,\n",
            "And he was \n",
            "\n",
            "\n",
            "Epoch: 131\n",
            "Train Loss: 1.7478999694188435, Train Perplexity: 5.742530514794224, LR: 0.0001\n",
            "Validation Loss: 1.9750092029571533\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I pray you, I have done for your father's mad.\n",
            "\n",
            "POMPEY:\n",
            "I do beseech you, sir, a man your sight with you; but I\n",
            "\n",
            "ESCALUS:\n",
            "I will give you have your grace.\n",
            "\n",
            "EDWARD:\n",
            "O wis\n",
            "\n",
            "\n",
            "Epoch: 132\n",
            "Train Loss: 1.747869062423706, Train Perplexity: 5.742353033174252, LR: 0.0001\n",
            "Validation Loss: 1.967379868030548\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "You say, the pardon and your dream after\n",
            "Will not stand in the state of all my state,\n",
            "And I mine and my danger to hear hate.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "You will be patient, may yo\n",
            "\n",
            "\n",
            "Epoch: 133\n",
            "Train Loss: 1.746352485815684, Train Perplexity: 5.733650915271271, LR: 0.0001\n",
            "Validation Loss: 1.958585262298584\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I do beseech you, sir, my lord, that I am not to dear\n",
            "He hath done some in sight shameless and monstrous with\n",
            "The senate, but with the king's good death,\n",
            "That the first \n",
            "\n",
            "\n",
            "Epoch: 134\n",
            "Train Loss: 1.7465199470520019, Train Perplexity: 5.734611159941793, LR: 0.0001\n",
            "Validation Loss: 1.9939254522323608\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "How now, my lord?\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "No doubt, and I will think me of all\n",
            "The news of the man.\n",
            "\n",
            "LUCIO:\n",
            "What dost thou?\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Then let the princ\n",
            "\n",
            "\n",
            "Epoch: 135\n",
            "Train Loss: 1.746732529004415, Train Perplexity: 5.7358303643643405, LR: 0.0001\n",
            "Validation Loss: 1.9483197927474976\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I do think I do beseech you, my lords, I will form\n",
            "That I would speak the king have born a start\n",
            "To rank of the report of a present for the\n",
            "That you have shall been in t\n",
            "\n",
            "\n",
            "Epoch: 136\n",
            "Train Loss: 1.7425122181574504, Train Perplexity: 5.711674385983603, LR: 0.0001\n",
            "Validation Loss: 1.9662770628929138\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "You are the duke as for a daughter of my pass\n",
            "As are you are by a maid; and best what,\n",
            "With shall here to be most this life.\n",
            "\n",
            "POLIXENES:\n",
            "Here comes her stones: mark her \n",
            "\n",
            "\n",
            "Epoch: 137\n",
            "Train Loss: 1.7422278801600137, Train Perplexity: 5.710050570793801, LR: 0.0001\n",
            "Validation Loss: 1.9684857726097107\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "You are all, and the dead of my good to my heart,\n",
            "Which now the bolds of the noble possess'd.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Many heaven and and let him to be ready.\n",
            "\n",
            "LORD BENBURY:\n",
            "Th\n",
            "\n",
            "\n",
            "Epoch: 138\n",
            "Train Loss: 1.7422626932462058, Train Perplexity: 5.710249358736674, LR: 0.0001\n",
            "Validation Loss: 1.967935860157013\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Here not be the bear is not the duke; I'll prince for him.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "He will tell me the will speak.\n",
            "\n",
            "Provost:\n",
            "Now the duke is not banish'd the heard in love.\n",
            "\n",
            "DU\n",
            "\n",
            "\n",
            "Epoch: 139\n",
            "Train Loss: 1.7440594991048177, Train Perplexity: 5.720518791564207, LR: 0.0001\n",
            "Validation Loss: 1.9538641571998596\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "You are more, are not to be at all to fight.\n",
            "\n",
            "BAPTISTA:\n",
            "Why, now I shall I have heard it, Bolingbroke,\n",
            "When the time of this damned with a head.\n",
            "\n",
            "RIVERS:\n",
            "I did in all al\n",
            "\n",
            "\n",
            "Epoch: 140\n",
            "Train Loss: 1.7435235897699992, Train Perplexity: 5.717453933460189, LR: 0.0001\n",
            "Validation Loss: 1.9595283269882202\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Hold, I have that you been a married and both.\n",
            "\n",
            "ABHORSON:\n",
            "My lord, I will serve the heart.\n",
            "\n",
            "POMPEY:\n",
            "No, I am so doubt, he walk: but I speak.\n",
            "\n",
            "Boy:\n",
            "Pardon, good father.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 141\n",
            "Train Loss: 1.7433204690615336, Train Perplexity: 5.71629271810404, LR: 0.0001\n",
            "Validation Loss: 1.966756522655487\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Do you so?\n",
            "\n",
            "PAURENCE:\n",
            "Sir, that you shall be found the king friend.\n",
            "\n",
            "BURIAR LAURENCE:\n",
            "My lord, shall well I see the slape thee town\n",
            "To him that he will be a post to the \n",
            "\n",
            "\n",
            "Epoch: 142\n",
            "Train Loss: 1.7451570590337118, Train Perplexity: 5.726800850599814, LR: 0.0001\n",
            "Validation Loss: 1.9525782465934753\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "You are not to the most mother darkness.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "You will take me for the right are my holy accused\n",
            "He shall show you must read to him and his son.\n",
            "\n",
            "BARNARDINE:\n",
            "\n",
            "\n",
            "Epoch: 143\n",
            "Train Loss: 1.7410860896110534, Train Perplexity: 5.703534609657302, LR: 0.0001\n",
            "Validation Loss: 1.9970607161521912\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "God gidnight! good night! We have no more from that\n",
            "Which is no more but but such more dismissent\n",
            "Than that I have some to his head.\n",
            "\n",
            "PAULINA:\n",
            "O dead!\n",
            "Thou mayst not hav\n",
            "\n",
            "\n",
            "Epoch: 144\n",
            "Train Loss: 1.739633274078369, Train Perplexity: 5.695254442219516, LR: 0.0001\n",
            "Validation Loss: 1.9635043740272522\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "You must reasonable me to arms to the bloody;\n",
            "I speak to my proportion what you are.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Not to do your good lordship, being give me the casely\n",
            "And the fath\n",
            "\n",
            "\n",
            "Epoch: 145\n",
            "Train Loss: 1.7384734829266866, Train Perplexity: 5.6886529654180205, LR: 0.0001\n",
            "Validation Loss: 1.973093867301941\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "What, sir? he will you go with a wing a boot;\n",
            "But now to his shame, from whence is the world,\n",
            "But were dispatch'd the desire his sword supple fortune.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "W\n",
            "\n",
            "\n",
            "Epoch: 146\n",
            "Train Loss: 1.7395081400871277, Train Perplexity: 5.694541816887782, LR: 0.0001\n",
            "Validation Loss: 1.9603766202926636\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "He has by his news; for that we do not love.\n",
            "\n",
            "POMPEY:\n",
            "Ay, sir; I have said a part worthy sworn.\n",
            "\n",
            "ESCALUS:\n",
            "I would not speak it were to the book so hear tog, speak of me,\n",
            "\n",
            "\n",
            "Epoch: 147\n",
            "Train Loss: 1.7385647614796957, Train Perplexity: 5.689172241128282, LR: 0.0001\n",
            "Validation Loss: 1.9574617147445679\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Gentlemen, all the ready to the law the fair;\n",
            "Where is no more than that you will not see,\n",
            "The appeareten prison, do you have thee wounds\n",
            "Of the apparent that you have d\n",
            "\n",
            "\n",
            "Epoch: 148\n",
            "Train Loss: 1.7410244901974996, Train Perplexity: 5.703183286090938, LR: 0.0001\n",
            "Validation Loss: 1.9767335057258606\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I have not breathed by the great man in here,\n",
            "Where you are not she best our blood, and so several\n",
            "To meet your power shall we are so bring her accused.\n",
            "\n",
            "ABHORSON:\n",
            "Well \n",
            "\n",
            "\n",
            "Epoch: 149\n",
            "Train Loss: 1.7381628195444743, Train Perplexity: 5.686885983730016, LR: 0.0001\n",
            "Validation Loss: 2.021210193634033\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "You are a bear; I am so thing.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "You are too sudden.\n",
            "\n",
            "AUFIDIUS:\n",
            "I thank you, sir.\n",
            "\n",
            "POMPEY:\n",
            "No, sir, I would have all.\n",
            "\n",
            "ESCALUS:\n",
            "We shall I be seen to reme\n",
            "\n",
            "\n",
            "Epoch: 150\n",
            "Train Loss: 1.738977813720703, Train Perplexity: 5.691522651859749, LR: 0.0001\n",
            "Validation Loss: 1.9714500308036804\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Here comes the store, and with your father, as he hate,\n",
            "He did her mother fair sounded the lady of death;\n",
            "And with this send the death is wearing peace,\n",
            "And the will she\n",
            "\n",
            "\n",
            "Epoch: 151\n",
            "Train Loss: 1.734923787911733, Train Perplexity: 5.668495779441765, LR: 0.0001\n",
            "Validation Loss: 1.9863284826278687\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Gentlemen, I do beseech you, beseech you,\n",
            "For my heart I have my heart young and man.\n",
            "\n",
            "PARIS:\n",
            "Here's a good made me to see me hath to make them;\n",
            "And I have no more than \n",
            "\n",
            "\n",
            "Epoch: 152\n",
            "Train Loss: 1.7378242492675782, Train Perplexity: 5.68496089907444, LR: 0.0001\n",
            "Validation Loss: 1.9708035588264465\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Have I told me for my word from your son?\n",
            "\n",
            "POLIXENES:\n",
            "What do me now me of your brother?\n",
            "\n",
            "PAULINA:\n",
            "You know, in my company mercy heart to give\n",
            "And my heart with the sun \n",
            "\n",
            "\n",
            "Epoch: 153\n",
            "Train Loss: 1.7349795937538146, Train Perplexity: 5.668812123448913, LR: 0.0001\n",
            "Validation Loss: 1.9806201457977295\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "No, but I do not him, but long as I have\n",
            "He must not the king.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Then have water been by my most blessing suffer;\n",
            "And state in the house of York of pity.\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 154\n",
            "Train Loss: 1.7379977782567342, Train Perplexity: 5.685947490191252, LR: 0.0001\n",
            "Validation Loss: 1.9870266318321228\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Peace, and the state not perform that will not be sentence\n",
            "From the desire to me that make me seen the banishment\n",
            "That I could all the world not from his shortly counsel\n",
            "\n",
            "\n",
            "Epoch: 155\n",
            "Train Loss: 1.73474174340566, Train Perplexity: 5.667463954849269, LR: 0.0001\n",
            "Validation Loss: 1.9549242854118347\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Yet but I am a signify, and a sad many a toward,\n",
            "Having that way not with a life love,\n",
            "And shall have all stay in the little storm;\n",
            "For if I do not so much more done tha\n",
            "\n",
            "\n",
            "Epoch: 156\n",
            "Train Loss: 1.7365654349327087, Train Perplexity: 5.677809091145088, LR: 0.0001\n",
            "Validation Loss: 1.9757403135299683\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Pray, go I have to thee.\n",
            "\n",
            "PARIS:\n",
            "I will not be all:\n",
            "He was a bad by the manly born with us,\n",
            "And the field sent his doom.\n",
            "\n",
            "CAPULET:\n",
            "Here is a little speak most began that\n",
            "\n",
            "\n",
            "Epoch: 157\n",
            "Train Loss: 1.7344269196192423, Train Perplexity: 5.665679983220704, LR: 0.0001\n",
            "Validation Loss: 1.969063639640808\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Go, good far this fault the world goddess,\n",
            "Did you did not the king beg of a doubt,\n",
            "If the duke had for a dispatch'd his stabb'd to you.\n",
            "\n",
            "POLIXENES:\n",
            "I thank thee, sir, t\n",
            "\n",
            "\n",
            "Epoch: 158\n",
            "Train Loss: 1.7343026081720987, Train Perplexity: 5.664975718117951, LR: 0.0001\n",
            "Validation Loss: 1.9933255314826965\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I will show the world with your heart at our father.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "It is a prophet lose this hateful arm, that sad before\n",
            "And make the wind amongst means of death.\n",
            "\n",
            "B\n",
            "\n",
            "\n",
            "Epoch: 159\n",
            "Train Loss: 1.7328189571698507, Train Perplexity: 5.656577103063476, LR: 0.0001\n",
            "Validation Loss: 1.9851842522621155\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Despite not, madam.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "O my name, I shall have no for my death.\n",
            "\n",
            "POMPEY:\n",
            "Sir, you may I be this point in so long, and leave me\n",
            "to all in the particular of \n",
            "\n",
            "\n",
            "Epoch: 160\n",
            "Train Loss: 1.7336959958076477, Train Perplexity: 5.661540315887107, LR: 0.0001\n",
            "Validation Loss: 1.9587489366531372\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Go, for the market-she die that must I did.\n",
            "\n",
            "POMPEY:\n",
            "Sir, I will I be her wash'd a pine own.\n",
            "\n",
            "Second Servingman:\n",
            "Where's the shall were an I now the great to-day?\n",
            "\n",
            "DUKE \n",
            "\n",
            "\n",
            "Epoch: 161\n",
            "Train Loss: 1.7322102944056192, Train Perplexity: 5.653135202792364, LR: 0.0001\n",
            "Validation Loss: 1.9719260931015015\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I do not see them, sir.\n",
            "\n",
            "POLIXENES:\n",
            "What is your grace?\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "I shall not see your wish.\n",
            "\n",
            "BUCKINGHAM:\n",
            "I do live, receive and like to the remember\n",
            "I spilt of d\n",
            "\n",
            "\n",
            "Epoch: 162\n",
            "Train Loss: 1.7307948827743531, Train Perplexity: 5.645139349519975, LR: 0.0001\n",
            "Validation Loss: 1.9555126428604126\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Peace, I have stand and so break against the heart.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Have I think you think'st the duke?\n",
            "\n",
            "BALTHASAR:\n",
            "No, I say, my lord.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "You have leave \n",
            "\n",
            "\n",
            "Epoch: 163\n",
            "Train Loss: 1.730832282702128, Train Perplexity: 5.645350481272058, LR: 0.0001\n",
            "Validation Loss: 1.9795147776603699\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Yea, my name is to none in the bridau; and now the\n",
            "Of burn bear with me with your portion.\n",
            "If you have the sea tongue for the people's to my soul,\n",
            "That it you are for th\n",
            "\n",
            "\n",
            "Epoch: 164\n",
            "Train Loss: 1.7335288047790527, Train Perplexity: 5.660593836261918, LR: 0.0001\n",
            "Validation Loss: 1.9669389724731445\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Dear you but that hath me but that before your should\n",
            "And that I have seen your brother and by him.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "I will tell him and what he was dead fame him.\n",
            "\n",
            "BUCK\n",
            "\n",
            "\n",
            "Epoch: 165\n",
            "Train Loss: 1.7315375844637553, Train Perplexity: 5.649333561383096, LR: 0.0001\n",
            "Validation Loss: 1.966874361038208\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Have I not been done a tapster, nor boy?\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "The words are the royal the gods of you.\n",
            "\n",
            "BALTHASAR:\n",
            "I know not, and I be the cause.\n",
            "\n",
            "RICHARD:\n",
            "Faith, I cannot \n",
            "\n",
            "\n",
            "Epoch: 166\n",
            "Train Loss: 1.73133252064387, Train Perplexity: 5.648175206235618, LR: 0.0001\n",
            "Validation Loss: 1.9645720720291138\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Peace, I will hear the day and from thee.\n",
            "\n",
            "BARNARDINE:\n",
            "And I will not grow to fight well act\n",
            "As thou art denied the same and bend men.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "But did you not d\n",
            "\n",
            "\n",
            "Epoch: 167\n",
            "Train Loss: 1.7320133288701376, Train Perplexity: 5.65202183964068, LR: 0.0001\n",
            "Validation Loss: 1.9903358221054077\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Dear me alone, and I thank I have done sends\n",
            "He had rather had a boura for beauty will but my hand:\n",
            "And so beauty is good be a cause in the wind;\n",
            "And all in pieces and t\n",
            "\n",
            "\n",
            "Epoch: 168\n",
            "Train Loss: 1.7307327191034954, Train Perplexity: 5.644788437842597, LR: 0.0001\n",
            "Validation Loss: 1.971498727798462\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I have no more a fearful superfluiting.\n",
            "\n",
            "POMPEY:\n",
            "Sir, I thought to your house, and you have bour tongue\n",
            "To him that shall be from the begun your patience way.\n",
            "\n",
            "DUKE VINC\n",
            "\n",
            "\n",
            "Epoch: 169\n",
            "Train Loss: 1.724606955051422, Train Perplexity: 5.6103154901201355, LR: 0.0001\n",
            "Validation Loss: 1.9633520245552063\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Why, I think your danger shall stay not for a band?\n",
            "\n",
            "POMPEY:\n",
            "Your mother lives may particious self.\n",
            "\n",
            "BARNARDINE:\n",
            "You have not a bark of tradest a propheture,\n",
            "You have to\n",
            "\n",
            "\n",
            "Epoch: 170\n",
            "Train Loss: 1.7280298511187235, Train Perplexity: 5.62955192031671, LR: 0.0001\n",
            "Validation Loss: 1.9706437587738037\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "He hath been both arties that again.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "How dost thou think me strong the world to you?\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "The valiant that you do me to shall the dark not.\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 171\n",
            "Train Loss: 1.7275620539983114, Train Perplexity: 5.62691904801223, LR: 0.0001\n",
            "Validation Loss: 1.962707281112671\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "What then?\n",
            "\n",
            "BARNARDINE:\n",
            "A brief doom grace beging the man and to me,\n",
            "Which should be made thee hour high for heavens in a\n",
            "And says the setstretched with a warrant of dis\n",
            "\n",
            "\n",
            "Epoch: 172\n",
            "Train Loss: 1.7264923731486002, Train Perplexity: 5.620903258524716, LR: 0.0001\n",
            "Validation Loss: 1.9812920093536377\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "So I have you brought forth the mind of your brother,\n",
            "If you be the matter worse your head a brat's death.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "This is not this for a plant, and that you ar\n",
            "\n",
            "\n",
            "Epoch: 173\n",
            "Train Loss: 1.7280261278152467, Train Perplexity: 5.629530959825493, LR: 0.0001\n",
            "Validation Loss: 2.0071462392807007\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Pray you, let me know no more death to dead.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "I do resolve your honour will; then I must be the\n",
            "In proceeding stones which you were in the garments\n",
            "I wou\n",
            "\n",
            "\n",
            "Epoch: 174\n",
            "Train Loss: 1.7271608710289001, Train Perplexity: 5.624662076679414, LR: 0.0001\n",
            "Validation Loss: 1.961864411830902\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Here comes the market.\n",
            "\n",
            "PARIS:\n",
            "O did me but that here are to the dead!\n",
            "\n",
            "GREMIO:\n",
            "Alas, that mercy to give us the gates of your course,\n",
            "On the rest not on your cousins to \n",
            "\n",
            "\n",
            "Epoch: 175\n",
            "Train Loss: 1.72581680615743, Train Perplexity: 5.617107244198055, LR: 0.0001\n",
            "Validation Loss: 1.9756410121917725\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "So many had rather had been your soul for your honour,\n",
            "You are belly bear the weary the morning of a\n",
            "And your blessing.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "You may love a best alarum.\n",
            "\n",
            "LAD\n",
            "\n",
            "\n",
            "Epoch: 176\n",
            "Train Loss: 1.7276246309280396, Train Perplexity: 5.627271174347461, LR: 0.0001\n",
            "Validation Loss: 1.9771935939788818\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Peace, my lord; I am a coward as thought on a charge.\n",
            "\n",
            "POMPEY:\n",
            "Yes, your pardon, if you had said to your mistress.\n",
            "\n",
            "ABHORSON:\n",
            "Look, you say, sir, sir.\n",
            "\n",
            "Both:\n",
            "Parry, but \n",
            "\n",
            "\n",
            "Epoch: 177\n",
            "Train Loss: 1.7244490146636964, Train Perplexity: 5.609429464687805, LR: 0.0001\n",
            "Validation Loss: 1.9708279371261597\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Gentlemen, for the many thoughts of the tribunes,\n",
            "Hence to his news rise by his brought,\n",
            "And stand what a parley did summer's life\n",
            "And transome at the blood in the head\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 178\n",
            "Train Loss: 1.7272879481315613, Train Perplexity: 5.625376887856671, LR: 0.0001\n",
            "Validation Loss: 1.9780511856079102\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "God I will not say the name I will have him so?\n",
            "\n",
            "POMPEY:\n",
            "I have a word a sent for my sir; I can be\n",
            "That breathe mercy again.\n",
            "\n",
            "ESCALUS:\n",
            "I have done some shall be content \n",
            "\n",
            "\n",
            "Epoch: 179\n",
            "Train Loss: 1.7225830515225729, Train Perplexity: 5.598972235500257, LR: 0.0001\n",
            "Validation Loss: 1.9678263068199158\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Pray you, let me I would not my life to dead;\n",
            "I would I were a fair disliker.\n",
            "\n",
            "PARIS:\n",
            "O my lord!\n",
            "\n",
            "JULIET:\n",
            "My Lord Aumerle, and I have no more heard:\n",
            "Thou shalt not be so\n",
            "\n",
            "\n",
            "Epoch: 180\n",
            "Train Loss: 1.7246415734291076, Train Perplexity: 5.6105097135025375, LR: 0.0001\n",
            "Validation Loss: 1.97713303565979\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I am a barren and not say the noble state;\n",
            "I am as a poor fearful as the sad will I.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "I do not hear me; for the strange of these are\n",
            "Which nothing from t\n",
            "\n",
            "\n",
            "Epoch: 181\n",
            "Train Loss: 1.7239239811897278, Train Perplexity: 5.606485099461767, LR: 0.0001\n",
            "Validation Loss: 1.9629107117652893\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I do beseech you, a pursued to him; a pursue\n",
            "Which I was my son, and all the rest words,\n",
            "That I have done to hear me to be deposed.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "But I will follow yo\n",
            "\n",
            "\n",
            "Epoch: 182\n",
            "Train Loss: 1.7245408376057942, Train Perplexity: 5.609944562653286, LR: 0.0001\n",
            "Validation Loss: 1.9698112607002258\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "God bless now arm now do not spirit!\n",
            "For I met from my son her trusting to be took\n",
            "The other father hath discourse many of my\n",
            "Stands and but that thou speak my fair.\n",
            "\n",
            "AU\n",
            "\n",
            "\n",
            "Epoch: 183\n",
            "Train Loss: 1.7260263363520305, Train Perplexity: 5.6182843210842925, LR: 0.0001\n",
            "Validation Loss: 1.9993101358413696\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Here we shall speak not with him; but I shall appear\n",
            "He shall not did but the grief that I say,\n",
            "I have more done, so deserved against thee,\n",
            "And here shall have the came \n",
            "\n",
            "\n",
            "Epoch: 184\n",
            "Train Loss: 1.724554137388865, Train Perplexity: 5.610019174195167, LR: 0.0001\n",
            "Validation Loss: 1.9767706394195557\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "What come you will be gone?\n",
            "\n",
            "BARNARDINE:\n",
            "Do not I do not for my sir?\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "What say you?\n",
            "\n",
            "ABHORSON:\n",
            "Pardon, Pray you, and I have been a then\n",
            "in the morning of\n",
            "\n",
            "\n",
            "Epoch: 185\n",
            "Train Loss: 1.7210056781768799, Train Perplexity: 5.590147527691879, LR: 0.0001\n",
            "Validation Loss: 1.9606050252914429\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "He that he does me with a does age, so heaven,\n",
            "Your honour toward stands your honour than this:\n",
            "The dead, the trick of my son, if I cannot get\n",
            "As devil speak the truth.\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 186\n",
            "Train Loss: 1.720822024345398, Train Perplexity: 5.589120969948386, LR: 0.0001\n",
            "Validation Loss: 1.9875895380973816\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Dear you so, sir?\n",
            "\n",
            "POMPEY:\n",
            "I do beseech you, sir, be the based: I\n",
            "Do as you think me to my son, and the hearts of his majesty\n",
            "Shall have to be this country to be at all.\n",
            "\n",
            "\n",
            "Epoch: 187\n",
            "Train Loss: 1.7189433614412943, Train Perplexity: 5.578630752592023, LR: 0.0001\n",
            "Validation Loss: 1.9872885942459106\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I do beseech you, my lords, I am glad your there\n",
            "And to this world by my heart the princely\n",
            "Hath been breath not but well me as the sentence.\n",
            "\n",
            "BARNARDINE:\n",
            "He did not req\n",
            "\n",
            "\n",
            "Epoch: 188\n",
            "Train Loss: 1.7194315989812214, Train Perplexity: 5.581355114560604, LR: 0.0001\n",
            "Validation Loss: 1.982442021369934\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "He that shall be with you, and let me form.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "No more remains, for the man that the king\n",
            "Is the fault the court of bearing of the house\n",
            "To your blood of h\n",
            "\n",
            "\n",
            "Epoch: 189\n",
            "Train Loss: 1.7223382711410522, Train Perplexity: 5.5976018846646705, LR: 0.0001\n",
            "Validation Loss: 1.9935413599014282\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "He shall not I be hath done shame, nor no sooner.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Now you that now hast the fault and love the great is from\n",
            "That he sentence and dead how it must deadl\n",
            "\n",
            "\n",
            "Epoch: 190\n",
            "Train Loss: 1.7161805828412373, Train Perplexity: 5.563239502030029, LR: 0.0001\n",
            "Validation Loss: 1.9749401211738586\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Here comes a fort, my lord.\n",
            "\n",
            "POMPEY:\n",
            "Sir, sir, for your honour honour honour loves with\n",
            "The news have been your hands your son.\n",
            "\n",
            "ABHORSON:\n",
            "So the rock in your true bless\n",
            "\n",
            "\n",
            "Epoch: 191\n",
            "Train Loss: 1.7207178393999736, Train Perplexity: 5.588538698017673, LR: 0.0001\n",
            "Validation Loss: 1.9699985980987549\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I do beseech you, I am him from his name;\n",
            "But not your dangerous straight to death,\n",
            "And you so that make the market-way, hath been\n",
            "One word had her rotten brother's for \n",
            "\n",
            "\n",
            "Epoch: 192\n",
            "Train Loss: 1.716665756702423, Train Perplexity: 5.565939295301534, LR: 0.0001\n",
            "Validation Loss: 1.9808275699615479\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Here is the news must return.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "O bring the first thou wilt not do with the\n",
            "sun with such a wise that all show a desire at him\n",
            "And with his friends purpos\n",
            "\n",
            "\n",
            "Epoch: 193\n",
            "Train Loss: 1.7212154626846314, Train Perplexity: 5.591320377057746, LR: 0.0001\n",
            "Validation Loss: 1.9506520628929138\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I will not the man make my heart.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Northumberland, be not the wind.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Sir, you have done, we have done of me word and you.\n",
            "\n",
            "Provost:\n",
            "I hav\n",
            "\n",
            "\n",
            "Epoch: 194\n",
            "Train Loss: 1.715781533718109, Train Perplexity: 5.561019939071771, LR: 0.0001\n",
            "Validation Loss: 1.9832106828689575\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Pray, I pray, I pray you, did I not\n",
            "I see the prince: I know not I will death.\n",
            "\n",
            "POMPEY:\n",
            "My lord, I pray your pains shall I no few the\n",
            "What is this derived with him.\n",
            "\n",
            "ESC\n",
            "\n",
            "\n",
            "Epoch: 195\n",
            "Train Loss: 1.7165709535280864, Train Perplexity: 5.565411651599718, LR: 0.0001\n",
            "Validation Loss: 1.969419538974762\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "He doth me; and I think my noble dead.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Stand be gone.\n",
            "\n",
            "ISABELLA:\n",
            "Be a countenance frame in the prince,\n",
            "And I may not the great prove to say thee.\n",
            "\n",
            "DUKE \n",
            "\n",
            "\n",
            "Epoch: 196\n",
            "Train Loss: 1.7150583028793336, Train Perplexity: 5.5569994919876935, LR: 0.0001\n",
            "Validation Loss: 1.9778068661689758\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I would have made you been so far too foul marge.\n",
            "\n",
            "BARNARDINE:\n",
            "You do not remain and send unshapest me,\n",
            "You know the noble born and your daughter tongue\n",
            "Than your majest\n",
            "\n",
            "\n",
            "Epoch: 197\n",
            "Train Loss: 1.71604319413503, Train Perplexity: 5.5624752282550185, LR: 0.0001\n",
            "Validation Loss: 1.9784283638000488\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "You are not day, my lord, with a month the\n",
            "And that to the field banish and you do bear:\n",
            "When you to deliver he did me her and proportion\n",
            "And her persuade and his cause \n",
            "\n",
            "\n",
            "Epoch: 198\n",
            "Train Loss: 1.7165437062581381, Train Perplexity: 5.565260011391974, LR: 0.0001\n",
            "Validation Loss: 1.976386547088623\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I thought, man; I do not we will for the new thee.\n",
            "\n",
            "BARNARDINE:\n",
            "Good night fair shall well not be disposition.\n",
            "\n",
            "ABHORSON:\n",
            "Good Paul, be gone, sir.\n",
            "\n",
            "BAGOT:\n",
            "My lord, I wil\n",
            "\n",
            "\n",
            "Epoch: 199\n",
            "Train Loss: 1.712205998102824, Train Perplexity: 5.541171819197674, LR: 0.0001\n",
            "Validation Loss: 1.9705362915992737\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "You say, I would not stay with the look.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "He dies with my lord; but what he did subject you are\n",
            "A precious but a little word not of the\n",
            "To speak him and \n",
            "\n",
            "\n",
            "Epoch: 200\n",
            "Train Loss: 1.7117263833681742, Train Perplexity: 5.538514828762774, LR: 0.0001\n",
            "Validation Loss: 1.9881662726402283\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Have I not breathe way your still hear the news?\n",
            "\n",
            "ABHORSON:\n",
            "A most of indeed.\n",
            "\n",
            "POMPEY:\n",
            "No, bring his fortune, but that hand so will to you.\n",
            "\n",
            "BAGOT:\n",
            "And I have been to be\n",
            "\n",
            "\n",
            "Epoch: 201\n",
            "Train Loss: 1.7142518242200215, Train Perplexity: 5.552519697159869, LR: 0.0001\n",
            "Validation Loss: 1.9795029163360596\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Peace, my lord; I will not peace to be no less.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "That hast no man her part of her penitence,\n",
            "Lest her since be in the charity.\n",
            "\n",
            "Second Servingman:\n",
            "This i\n",
            "\n",
            "\n",
            "Epoch: 202\n",
            "Train Loss: 1.7132476369539897, Train Perplexity: 5.546946726207134, LR: 0.0001\n",
            "Validation Loss: 1.9963749647140503\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Farewell, as I will follow you here with the\n",
            "Where is deserves the noble duke here beard,\n",
            "I do receive the air to be holy desire.\n",
            "\n",
            "GREEN:\n",
            "What to her than he said her ma\n",
            "\n",
            "\n",
            "Epoch: 203\n",
            "Train Loss: 1.7150270263353984, Train Perplexity: 5.556825690966896, LR: 0.0001\n",
            "Validation Loss: 1.9861236810684204\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Well, I do not believe it; I say, since that I cannot\n",
            "Your grace may not have tongue and my poor:\n",
            "Your majesty brother, you must revenge.\n",
            "\n",
            "PARIS:\n",
            "Good night, let me be m\n",
            "\n",
            "\n",
            "Epoch: 204\n",
            "Train Loss: 1.713721267382304, Train Perplexity: 5.549574551220722, LR: 0.0001\n",
            "Validation Loss: 1.9833305478096008\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "What news? farewell I must not? Is for thee?\n",
            "\n",
            "POLIXENES:\n",
            "What, do you to him?\n",
            "\n",
            "FRIAR LAURENCE:\n",
            "Be your good father; I have not to me.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "How shall he come \n",
            "\n",
            "\n",
            "Epoch: 205\n",
            "Train Loss: 1.7122630596160888, Train Perplexity: 5.5414880158681825, LR: 0.0001\n",
            "Validation Loss: 2.0116868019104004\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I am a nothing to deep your father's death.\n",
            "\n",
            "PRINCE:\n",
            "He is father and princely father to the king;\n",
            "And then at high desire men of love.\n",
            "\n",
            "BUCKINGHAM:\n",
            "He would not strike \n",
            "\n",
            "\n",
            "Epoch: 206\n",
            "Train Loss: 1.7133493701616922, Train Perplexity: 5.5475110635959854, LR: 0.0001\n",
            "Validation Loss: 1.9686293005943298\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I shall be revenged you to be distress.\n",
            "\n",
            "BARNARDINE:\n",
            "I do not from me; I will be thee and not like my\n",
            "false but with my heart. I was not doing.\n",
            "\n",
            "POMPEY:\n",
            "He cannot should\n",
            "\n",
            "\n",
            "Epoch: 207\n",
            "Train Loss: 1.7111491680145263, Train Perplexity: 5.53531883544415, LR: 0.0001\n",
            "Validation Loss: 1.9640279412269592\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "You are not be too day: and your blood for all\n",
            "He would not straight.\n",
            "\n",
            "BUCKINGHAM:\n",
            "Why, then, you must deep this is done.\n",
            "\n",
            "KING RICHARD III:\n",
            "I know not what are they can\n",
            "\n",
            "\n",
            "Epoch: 208\n",
            "Train Loss: 1.7131947080294292, Train Perplexity: 5.546653140051989, LR: 0.0001\n",
            "Validation Loss: 1.9806866645812988\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Pray you, my lord, with all as I despite;\n",
            "And there best thou not a man with you\n",
            "A place for me and straight be to protector and\n",
            "The loss of his grace of breath, I serve\n",
            "\n",
            "\n",
            "Epoch: 209\n",
            "Train Loss: 1.7125100413958232, Train Perplexity: 5.542856831470017, LR: 0.0001\n",
            "Validation Loss: 1.9846775531768799\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Have you not away to died?\n",
            "\n",
            "BARNARDINE:\n",
            "You will be that I am rest?\n",
            "\n",
            "ABHORSON:\n",
            "My lord, I will not have but heart thee: all this wife\n",
            "Did but thy death to have been with\n",
            "\n",
            "\n",
            "Epoch: 210\n",
            "Train Loss: 1.7090178966522216, Train Perplexity: 5.523534131590681, LR: 0.0001\n",
            "Validation Loss: 1.9786876440048218\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "You shall not be as thou art.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Northumberland, but thou art thou too much\n",
            "To do not love this take the more win you all.\n",
            "\n",
            "ANGELO:\n",
            "Yea, my lord.\n",
            "\n",
            "KING RIC\n",
            "\n",
            "\n",
            "Epoch: 211\n",
            "Train Loss: 1.7060648520787558, Train Perplexity: 5.507246949320636, LR: 0.0001\n",
            "Validation Loss: 1.9794642925262451\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I do not know the friar man I have found.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "I am sorry for a human in alrian; I\n",
            "Have seen the stronger of his subject, and show\n",
            "By this face he air of hea\n",
            "\n",
            "\n",
            "Epoch: 212\n",
            "Train Loss: 1.7110988299051921, Train Perplexity: 5.5350402049723355, LR: 0.0001\n",
            "Validation Loss: 1.9914793372154236\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "He doth not a lady; and be gone a long.\n",
            "\n",
            "PARIS:\n",
            "Have I say, then had been bloody deed well shades their body\n",
            "More warm than you shall deserve me for their mouths.\n",
            "\n",
            "DUKE \n",
            "\n",
            "\n",
            "Epoch: 213\n",
            "Train Loss: 1.7110726157824199, Train Perplexity: 5.534895110650622, LR: 0.0001\n",
            "Validation Loss: 1.9787390232086182\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I would not do I told your honour, I mean,\n",
            "I have to your grace would see her die.\n",
            "\n",
            "POLIXENES:\n",
            "What is the hand?\n",
            "\n",
            "Shepherd:\n",
            "Then fair losses in her she was not in the da\n",
            "\n",
            "\n",
            "Epoch: 214\n",
            "Train Loss: 1.7080135107040406, Train Perplexity: 5.51798915663822, LR: 0.0001\n",
            "Validation Loss: 1.9748576283454895\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "You are a word, I would not like a wind that your honour\n",
            "And ne'er was not at my father's wife; but I\n",
            "Had he doth made him before his mouth that I should still\n",
            "Still the\n",
            "\n",
            "\n",
            "Epoch: 215\n",
            "Train Loss: 1.7100118478139241, Train Perplexity: 5.529026984118838, LR: 0.0001\n",
            "Validation Loss: 1.9750435948371887\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Here's not I, I am a dull: but I would not\n",
            "wash the dangerous devil sent in the life,\n",
            "Or I am desire ever to a traitor's poor\n",
            "contracting and to the senate beauty.\n",
            "\n",
            "BARN\n",
            "\n",
            "\n",
            "Epoch: 216\n",
            "Train Loss: 1.7090840220451355, Train Perplexity: 5.523899389531685, LR: 0.0001\n",
            "Validation Loss: 2.00799822807312\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Have I not a word with you?\n",
            "\n",
            "ABHORSON:\n",
            "Prithee, for a worthier of your majesty, a searing and\n",
            "The rest are that I can we came to be content.\n",
            "Thou art a warm, a guest of \n",
            "\n",
            "\n",
            "Epoch: 217\n",
            "Train Loss: 1.7079240282376607, Train Perplexity: 5.517495415449945, LR: 0.0001\n",
            "Validation Loss: 1.9863820672035217\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "God you do deny sighs of four fair and daughter!\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "I will not so, my lord; being liege.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "You do not with me.\n",
            "\n",
            "BUCKINGHAM:\n",
            "I do report a so\n",
            "\n",
            "\n",
            "Epoch: 218\n",
            "Train Loss: 1.7044272104899088, Train Perplexity: 5.498235433506891, LR: 0.0001\n",
            "Validation Loss: 1.9754477739334106\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "He hath not a word; a brawling words that names\n",
            "Of noble law news, and hanging, and when their hearts\n",
            "To reason a thousand as he had loved for thy foolish,\n",
            "And then thou\n",
            "\n",
            "\n",
            "Epoch: 219\n",
            "Train Loss: 1.7049507021903991, Train Perplexity: 5.501114467633161, LR: 0.0001\n",
            "Validation Loss: 1.9924297332763672\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Sir, I am grace the friar.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "He will all the reverence of his arms,\n",
            "We may not for a large and hold a gentleman:\n",
            "I thank you, good good stand what have be\n",
            "\n",
            "\n",
            "Epoch: 220\n",
            "Train Loss: 1.7049755374590556, Train Perplexity: 5.501251090985407, LR: 0.0001\n",
            "Validation Loss: 2.0024207830429077\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "You may not a fear to say to be your grace.\n",
            "\n",
            "POMPEY:\n",
            "Then and by your sword, I would have spent.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "You must not the speak.\n",
            "\n",
            "AUTOLYCUS:\n",
            "I have done heard a\n",
            "\n",
            "\n",
            "Epoch: 221\n",
            "Train Loss: 1.7061375419298808, Train Perplexity: 5.507647284831479, LR: 0.0001\n",
            "Validation Loss: 1.9992870688438416\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "You have all my send in my sight; I dare not.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Nor none singing, I have soon by my friends,\n",
            "To bring in the heavens and places of the heart\n",
            "As if you to \n",
            "\n",
            "\n",
            "Epoch: 222\n",
            "Train Loss: 1.7068700472513834, Train Perplexity: 5.511683143740182, LR: 0.0001\n",
            "Validation Loss: 1.9676285982131958\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Pray you, my lord, I do not myself;\n",
            "For I say not that I have spoke to say.\n",
            "\n",
            "POMPEY:\n",
            "Here comes the form of the law; some intents pity\n",
            "To me with my soul suffer it.\n",
            "\n",
            "AUF\n",
            "\n",
            "\n",
            "Epoch: 223\n",
            "Train Loss: 1.7046496629714967, Train Perplexity: 5.499458665673901, LR: 0.0001\n",
            "Validation Loss: 1.9823933839797974\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "What news? If then are be not, and then destroying tongue?\n",
            "\n",
            "ABHORSON:\n",
            "My lord, and heart their more strength, heavens with himself.\n",
            "\n",
            "POMPEY:\n",
            "Masters, sir, how a shall be\n",
            "\n",
            "\n",
            "Epoch: 224\n",
            "Train Loss: 1.7033936142921449, Train Perplexity: 5.492555414197262, LR: 0.0001\n",
            "Validation Loss: 1.9726046919822693\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Have you done a man second the king made a better,\n",
            "Did prince friend to the moon and should have heard\n",
            "Have any had been her leaves to death.\n",
            "\n",
            "ABHORSON:\n",
            "Sir, but I will \n",
            "\n",
            "\n",
            "Epoch: 225\n",
            "Train Loss: 1.703072436650594, Train Perplexity: 5.490791611465406, LR: 0.0001\n",
            "Validation Loss: 1.9900742173194885\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "For Gentleman, I do not for the gods begin\n",
            "Which he no more than that hast I was tongue\n",
            "The rocked faint, indeed, I will have him to him;\n",
            "And long as the contrary sins i\n",
            "\n",
            "\n",
            "Epoch: 226\n",
            "Train Loss: 1.704512886206309, Train Perplexity: 5.498706518946597, LR: 0.0001\n",
            "Validation Loss: 2.0017494559288025\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Here comes by my hand; but I have not speak\n",
            "Where is farewell appear.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Many so dispersed here that the man hath hath made\n",
            "Of his party from my father's d\n",
            "\n",
            "\n",
            "Epoch: 227\n",
            "Train Loss: 1.70450119972229, Train Perplexity: 5.498642258776227, LR: 0.0001\n",
            "Validation Loss: 1.9895904064178467\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I do beseech you, a man to see while you do.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "A desperate for my soul shame you are.\n",
            "\n",
            "BARNARDINE:\n",
            "You some with this proud, sir.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "The han\n",
            "\n",
            "\n",
            "Epoch: 228\n",
            "Train Loss: 1.7030523379643758, Train Perplexity: 5.4906812548767325, LR: 0.0001\n",
            "Validation Loss: 1.9761940836906433\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Why, say you have done, what we do not dead?\n",
            "\n",
            "BAPTISTA:\n",
            "Gentlemen, I do not see, if I must dead,\n",
            "In peace the war gates my father, good not.\n",
            "\n",
            "DERBY:\n",
            "I am too soon him as\n",
            "\n",
            "\n",
            "Epoch: 229\n",
            "Train Loss: 1.7006688912709553, Train Perplexity: 5.477610092192817, LR: 0.0001\n",
            "Validation Loss: 1.9917399883270264\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Farewell, farewell.\n",
            "\n",
            "GRE'N:\n",
            "Ay, for all this something that the man dost them.\n",
            "\n",
            "BARNARDINE:\n",
            "He that brought you must despair.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "It is a branding of your h\n",
            "\n",
            "\n",
            "Epoch: 230\n",
            "Train Loss: 1.6997023781140645, Train Perplexity: 5.4723184675947225, LR: 0.0001\n",
            "Validation Loss: 1.970902442932129\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "He made you may be made of the king, and a man\n",
            "Your friends, you think your stronger.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "I have been a torse in this life, and make the world.\n",
            "\n",
            "LADY ANNE:\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 231\n",
            "Train Loss: 1.7018154899279276, Train Perplexity: 5.483894314619958, LR: 0.0001\n",
            "Validation Loss: 1.9805071353912354\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I do beseech you, a man make think you meany\n",
            "To the king, you have no done.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "It is not any things but you may be of the\n",
            "so your ancient bearing in your s\n",
            "\n",
            "\n",
            "Epoch: 232\n",
            "Train Loss: 1.69922087987264, Train Perplexity: 5.469684190126939, LR: 0.0001\n",
            "Validation Loss: 1.9817614555358887\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "He mad I will do your prophet excuse my son.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "He has we have fought it first, where you that did\n",
            "And not the present forth.\n",
            "\n",
            "LUCIO:\n",
            "O, if you love deserv\n",
            "\n",
            "\n",
            "Epoch: 233\n",
            "Train Loss: 1.6995158195495605, Train Perplexity: 5.471297654940532, LR: 0.0001\n",
            "Validation Loss: 1.9924997091293335\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Say I will be gone of death?\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "No more of that I might have done.\n",
            "But now deeds that the life and comes of them,\n",
            "Shall be made a king and from his most re\n",
            "\n",
            "\n",
            "Epoch: 234\n",
            "Train Loss: 1.6992504199345906, Train Perplexity: 5.469845767323254, LR: 0.0001\n",
            "Validation Loss: 1.9899930357933044\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Now I am sure, now I am a maid, though I wish\n",
            "Mistress fast thou hast for my soul that done.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "It is my dear many and hear brothers.\n",
            "\n",
            "ISABELLA:\n",
            "O, the poo\n",
            "\n",
            "\n",
            "Epoch: 235\n",
            "Train Loss: 1.6993623971939087, Train Perplexity: 5.470458299955395, LR: 0.0001\n",
            "Validation Loss: 1.994940459728241\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "What I have been to do not what I to fear?\n",
            "\n",
            "POMPEY:\n",
            "No, but I will not speak thee, sir.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Sir, the should have I been this hand and then.\n",
            "\n",
            "ABHORSON:\n",
            "Good \n",
            "\n",
            "\n",
            "Epoch: 236\n",
            "Train Loss: 1.697686489423116, Train Perplexity: 5.461297994438322, LR: 0.0001\n",
            "Validation Loss: 1.982772171497345\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I never me, I do not lord.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "It is a bank, a word best shall the destroy.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "O you think well that the prince the morning to\n",
            "Do much as my h\n",
            "\n",
            "\n",
            "Epoch: 237\n",
            "Train Loss: 1.6995072722434998, Train Perplexity: 5.471250890284782, LR: 0.0001\n",
            "Validation Loss: 2.000494062900543\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "He was a breathed bands with man; I have not but\n",
            "That I have a fought shadow'd to her now them.\n",
            "\n",
            "ABHORSON:\n",
            "So that I shall have you seen a king and that you\n",
            "have strange\n",
            "\n",
            "\n",
            "Epoch: 238\n",
            "Train Loss: 1.6978646039962768, Train Perplexity: 5.462270817833945, LR: 0.0001\n",
            "Validation Loss: 1.9807220697402954\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I will the world.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "I do beseech you, look with a dispatch a world:\n",
            "When I shall give my heart to say that I consul,\n",
            "I have been with the outward of birth\n",
            "\n",
            "\n",
            "Epoch: 239\n",
            "Train Loss: 1.6968531211217244, Train Perplexity: 5.4567486177217726, LR: 0.0001\n",
            "Validation Loss: 1.9861032366752625\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "You are not the prince of death: I do beseech you,\n",
            "Who sit at the law the faults of his field.\n",
            "\n",
            "AUFIDIUS:\n",
            "This sons are no life: he had he done and pursued;\n",
            "And then he \n",
            "\n",
            "\n",
            "Epoch: 240\n",
            "Train Loss: 1.6970867315928142, Train Perplexity: 5.458023520246469, LR: 0.0001\n",
            "Validation Loss: 1.997071385383606\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "He was not a man, that had now the man together:\n",
            "Not so be the letter of heaven served himself,\n",
            "In the more by his confessors of his son\n",
            "Standing for the devil lose hims\n",
            "\n",
            "\n",
            "Epoch: 241\n",
            "Train Loss: 1.6970740755399067, Train Perplexity: 5.457954443649146, LR: 0.0001\n",
            "Validation Loss: 1.9942070245742798\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I am not a stranger to am I would fair\n",
            "I had been a man new-down have seen their hate.\n",
            "\n",
            "POMPEY:\n",
            "I am sorry, sir, in bloody pains about about the\n",
            "And lamb it thee strengt\n",
            "\n",
            "\n",
            "Epoch: 242\n",
            "Train Loss: 1.6987937132517497, Train Perplexity: 5.467348222573309, LR: 0.0001\n",
            "Validation Loss: 1.9835305213928223\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "What are news? not a doth man are fault the boar sure,\n",
            "Dreaming the slarence of the destroy are fortune.\n",
            "Now for the world of such a straight as many more,\n",
            "That have the\n",
            "\n",
            "\n",
            "Epoch: 243\n",
            "Train Loss: 1.6937602082888286, Train Perplexity: 5.439897442936852, LR: 0.0001\n",
            "Validation Loss: 1.9938956499099731\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I will follow you, and be foul warrant him a with\n",
            "After than a worst and black again.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Not so long as I have found a put to him hither.\n",
            "\n",
            "AUTOLYCUS:\n",
            "A goo\n",
            "\n",
            "\n",
            "Epoch: 244\n",
            "Train Loss: 1.6966146032015483, Train Perplexity: 5.455447240597603, LR: 0.0001\n",
            "Validation Loss: 1.9942347407341003\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I will not hear me from his grace brow dispatch.\n",
            "Would I were not speak nor bear?\n",
            "Well, I am your sorrow no live.\n",
            "\n",
            "BALTHASAR:\n",
            "Five I had no more, my lord, and friends,\n",
            "T\n",
            "\n",
            "\n",
            "Epoch: 245\n",
            "Train Loss: 1.6945709904034933, Train Perplexity: 5.444309802978787, LR: 0.0001\n",
            "Validation Loss: 1.980826735496521\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "You will not passion me: you all despair\n",
            "That I have a more from than a powerful than ever\n",
            "In the most revenge and I have stood to help\n",
            "More than heart's allies, if than\n",
            "\n",
            "\n",
            "Epoch: 246\n",
            "Train Loss: 1.6939332445462545, Train Perplexity: 5.440838823875327, LR: 0.0001\n",
            "Validation Loss: 1.9980892539024353\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "What are not that, and then?\n",
            "\n",
            "BARNARDINE:\n",
            "He was an inform the realm the rich in fire to;\n",
            "For a doubtful arms and the gods are pardon\n",
            "A man forbids a shameful believed t\n",
            "\n",
            "\n",
            "Epoch: 247\n",
            "Train Loss: 1.6957237005233765, Train Perplexity: 5.450589132412452, LR: 0.0001\n",
            "Validation Loss: 1.9896335005760193\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I thank you will go to.\n",
            "\n",
            "POMPEY:\n",
            "Yea, sir, for your honour father's pardon.\n",
            "\n",
            "BARNARDINE:\n",
            "I will give your ancient grave is your grace.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "You will the batt\n",
            "\n",
            "\n",
            "Epoch: 248\n",
            "Train Loss: 1.6929805159568787, Train Perplexity: 5.435657649695928, LR: 0.0001\n",
            "Validation Loss: 2.002245545387268\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Yea, are you do not at a princely farewell.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "So do you to my wounded, and be my revenge,\n",
            "But dishonour tender, for your delivery\n",
            "Your great mistress made\n",
            "\n",
            "\n",
            "Epoch: 249\n",
            "Train Loss: 1.688535952568054, Train Perplexity: 5.411552133640941, LR: 0.0001\n",
            "Validation Loss: 1.9903226494789124\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I thank you, for your daughter to the king, and\n",
            "I will do me to your father; and I have labour to\n",
            "One of the house of the people, he matter were\n",
            "And say 'Be short,' with\n",
            "\n",
            "\n",
            "Epoch: 250\n",
            "Train Loss: 1.690455444653829, Train Perplexity: 5.421949540811217, LR: 0.0001\n",
            "Validation Loss: 1.9959524273872375\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Say, I would not that I had been my heart been.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "O, if I were not by my brother by him, I have\n",
            "With a courtier of his country.\n",
            "\n",
            "ABHORSON:\n",
            "Sir, it is it m\n",
            "\n",
            "\n",
            "Epoch: 251\n",
            "Train Loss: 1.691593074798584, Train Perplexity: 5.428121223932949, LR: 0.0001\n",
            "Validation Loss: 1.9967257976531982\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Here all the Duke of York.\n",
            "\n",
            "AUFIDIUS:\n",
            "No fortune sorrow say 'not the man.'\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Sir, if you love her breath, and you love to do.\n",
            "\n",
            "LADY ANNE:\n",
            "The trumpet is o\n",
            "\n",
            "\n",
            "Epoch: 252\n",
            "Train Loss: 1.6938175678253173, Train Perplexity: 5.440209481881845, LR: 0.0001\n",
            "Validation Loss: 1.993656873703003\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I have not them a duke's time, and not a sword,\n",
            "Have done monasting and death that all this sight.\n",
            "Thou wast mad by my brother, I play'd thy father,\n",
            "Whom I should have l\n",
            "\n",
            "\n",
            "Epoch: 253\n",
            "Train Loss: 1.6891269524892172, Train Perplexity: 5.414751305787418, LR: 0.0001\n",
            "Validation Loss: 1.9803627729415894\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "He that shall be ready at the worse than I start.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "But that I have been stand what he doth done in the fault\n",
            "Hath cannot be consemarriaged to your grace.\n",
            "\n",
            "\n",
            "Epoch: 254\n",
            "Train Loss: 1.6901789863904317, Train Perplexity: 5.4204508052354, LR: 0.0001\n",
            "Validation Loss: 1.9888814687728882\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I beseech you, and therefore I will not please you.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "I would they were a looking are by your father's\n",
            "The sea to be wish one with with you.\n",
            "\n",
            "POMPEY:\n",
            "No, \n",
            "\n",
            "\n",
            "Epoch: 255\n",
            "Train Loss: 1.6899765213330586, Train Perplexity: 5.419353464442462, LR: 0.0001\n",
            "Validation Loss: 1.9838864207267761\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I have done, not I will her; and I here in my\n",
            "As I hard been banish'd and forgot.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Come, you are to be amended.\n",
            "\n",
            "BARNARDINE:\n",
            "What news? for you, defend m\n",
            "\n",
            "\n",
            "Epoch: 256\n",
            "Train Loss: 1.688186490535736, Train Perplexity: 5.4096613320352525, LR: 0.0001\n",
            "Validation Loss: 1.9869298934936523\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "He was better far off man.\n",
            "\n",
            "POMPEY:\n",
            "I do not hand; sir, if you be a worse, sir, it shall\n",
            "be all never from your honour.\n",
            "\n",
            "BARNARDINE:\n",
            "You shall be a worse against that yo\n",
            "\n",
            "\n",
            "Epoch: 257\n",
            "Train Loss: 1.6870758851369223, Train Perplexity: 5.403656667977502, LR: 0.0001\n",
            "Validation Loss: 1.9808820486068726\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Happiness we made now that news sweet bad to hear\n",
            "And by the crown and departing defenced\n",
            "And we are to do't. And you so much men call upon my\n",
            "That were elder sees young\n",
            "\n",
            "\n",
            "Epoch: 258\n",
            "Train Loss: 1.6878743330637613, Train Perplexity: 5.4079729293670695, LR: 0.0001\n",
            "Validation Loss: 1.996741533279419\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Sir, I am not here weary you, my lord.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Give me not the prime hand.\n",
            "\n",
            "Provost:\n",
            "I am here comes are friends, for a man.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Pray you, good nig\n",
            "\n",
            "\n",
            "Epoch: 259\n",
            "Train Loss: 1.687087893486023, Train Perplexity: 5.403721557362798, LR: 0.0001\n",
            "Validation Loss: 1.985842525959015\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Happiness it to my friends my wounds brother's good\n",
            "In bad, to the life and the limits of were\n",
            "To early and which service my son,\n",
            "Or I do not see thee so deep in answer.\n",
            "\n",
            "\n",
            "Epoch: 260\n",
            "Train Loss: 1.6841383616129557, Train Perplexity: 5.387806590784768, LR: 0.0001\n",
            "Validation Loss: 1.9726144671440125\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I think you did I not for dead; I do deliver\n",
            "Do not for your free to see him.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Pray you, sir, if you do the merry thing I have\n",
            "Of prevail, you not privat\n",
            "\n",
            "\n",
            "Epoch: 261\n",
            "Train Loss: 1.6895205497741699, Train Perplexity: 5.416882956678553, LR: 0.0001\n",
            "Validation Loss: 1.979222297668457\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Here's the father of the duke I can do; then.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Believe me, do you to your knowledge?\n",
            "\n",
            "BAPTISTA:\n",
            "Why, how dost thou canst thou comest me?\n",
            "\n",
            "BALTHASAR:\n",
            "I wi\n",
            "\n",
            "\n",
            "Epoch: 262\n",
            "Train Loss: 1.6882435520490011, Train Perplexity: 5.409970024304251, LR: 0.0001\n",
            "Validation Loss: 1.9922200441360474\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "I know not what news? I do not myself; I must forgot.\n",
            "\n",
            "AUTOLYCUS:\n",
            "No, sir, no.\n",
            "\n",
            "DORCAS:\n",
            "I am the lamentation of the cause.\n",
            "\n",
            "BAPTISTA:\n",
            "Gentlemen, gentle Gentleman:\n",
            "I thin\n",
            "\n",
            "\n",
            "Epoch: 263\n",
            "Train Loss: 1.6850910107294719, Train Perplexity: 5.392941725575888, LR: 0.0001\n",
            "Validation Loss: 1.9945311546325684\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "He did some to say 'tis not at your light;\n",
            "It is not my dear more not so soon I.\n",
            "\n",
            "BUCKINGHAM:\n",
            "Nor I do nor rothing resure the gods that which should\n",
            "But then to reprive \n",
            "\n",
            "\n",
            "Epoch: 264\n",
            "Train Loss: 1.6880274693171182, Train Perplexity: 5.408801149493374, LR: 0.0001\n",
            "Validation Loss: 1.9922450184822083\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Here so I did not but such sad as I weight.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "I would her be the day! And there hand.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "My lord, I say, if I were he comes\n",
            "And that she sho\n",
            "\n",
            "\n",
            "Epoch: 265\n",
            "Train Loss: 1.6862589915593464, Train Perplexity: 5.399244258030053, LR: 0.0001\n",
            "Validation Loss: 1.9950054287910461\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "God give you to know your highness state your king!\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Madam, I have said a done that does about him.\n",
            "\n",
            "PARIS:\n",
            "You shall do the duke a with a long.\n",
            "\n",
            "JULIET:\n",
            "\n",
            "\n",
            "Epoch: 266\n",
            "Train Loss: 1.6813960830370585, Train Perplexity: 5.37305196409446, LR: 0.0001\n",
            "Validation Loss: 2.0062347650527954\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Have I not heard a speak nor any nor no wart\n",
            "A princely faith and banishment, as I may not\n",
            "Only they do assure them.\n",
            "\n",
            "POLIXENES:\n",
            "They shall the have been well before his\n",
            "\n",
            "\n",
            "Epoch: 267\n",
            "Train Loss: 1.6827268481254578, Train Perplexity: 5.380206993842404, LR: 0.0001\n",
            "Validation Loss: 1.9884494543075562\n",
            "Generation: BARNARDO: Who's there?\n",
            "FRANCISCO: Nay, answer me. Stand and unfold yourself.\n",
            "BARNARDO:\n",
            "Your daughter disproper me at the heavens!\n",
            "\n",
            "DORSET:\n",
            "If he be honour'd the foe, and bow him from me,\n",
            "But he hath some brother him of the man.\n",
            "\n",
            "BALTHASAR:\n",
            "I do beseech you\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-a9d2225c93bf>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbest_val_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#scheduler.step(val_loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-9a9cd1890dfa>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1175\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                label_smoothing=self.label_smoothing)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3027\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3028\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3029\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from random import uniform\n",
        "import time\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "def topPTransform(probs, top_p):\n",
        "        probs_sorted_vals, probs_sort_idx = torch.sort(probs, descending=True)\n",
        "        prob_cumsum = torch.cumsum(probs_sorted_vals, dim = -1)\n",
        "\n",
        "        absolute_diff = torch.abs(prob_cumsum - top_p)\n",
        "        closest_index = torch.argmin(absolute_diff).item()\n",
        "        idx_to_remove = probs_sort_idx[:, closest_index + 1:]\n",
        "\n",
        "        mask = torch.ones_like(probs)\n",
        "        mask[:, idx_to_remove] = 0\n",
        "\n",
        "        probs = probs * mask\n",
        "        weighted_probs = probs / torch.sum(probs, dim = -1)\n",
        "        return weighted_probs\n",
        "\n",
        "def persistent_generation(prompt, max_tokens, temperature = 1, top_p = 1):\n",
        "    generated_text = prompt\n",
        "    model.eval()\n",
        "    tokens = torch.tensor(encode(prompt)).reshape(1, -1).to(device)\n",
        "    buffer = 10\n",
        "    token_count = 0\n",
        "    while token_count < max_tokens:\n",
        "        if tokens.shape[-1] >= seq_len:\n",
        "            tokens = tokens[:, tokens.shape[-1] - seq_len + 10: ]\n",
        "        logits = model.forward(tokens)\n",
        "        logit = logits[:, -1, :] # (B, C)\n",
        "\n",
        "        # temperature\n",
        "        logit = logit / temperature\n",
        "\n",
        "        # top_p\n",
        "        probs = F.softmax(logit, dim = -1) # (B, C)\n",
        "        weighted_probs = topPTransform(probs, top_p)\n",
        "        predicted_token = torch.multinomial(weighted_probs, num_samples = 1) # (B, 1)\n",
        "        generated_text = generated_text + decode(predicted_token[0].cpu().detach().tolist())\n",
        "        tokens = torch.cat((tokens, predicted_token), dim = -1) # (B, T + 1) # (1, 1)\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        print(generated_text)\n",
        "        token_count = token_count + 1\n",
        "\n",
        "        #time.sleep(0.01)\n",
        "\n",
        "print(persistent_generation(\"ACT I\\n\\nSCENE I. Elsinore. A platform before the Castle.\\n\\n\\nEnter Francisco and Barnardo, two sentinels.\", max_tokens = 700, top_p = 0.7))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HFn3hU0kqcu",
        "outputId": "6af36817-5148-4d9c-a91f-d65f3f0d1e43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ACT I\n",
            "\n",
            "SCENE I. Elsinore. A platform before the Castle.\n",
            "\n",
            "\n",
            "Enter Francisco and Barnardo, two sentinels.\n",
            "\n",
            "KING HENRY VI:\n",
            "Saw you will I know not where I was the defend?\n",
            "\n",
            "HENRY BOLINGBROKE:\n",
            "What you are you makes a gracious face?\n",
            "And that I know not of the world bear you?\n",
            "\n",
            "JOHN OF GAUNT:\n",
            "And with me thee with that strength so trouble to thee,\n",
            "Who should devotion me in means the bear.\n",
            "\n",
            "KING RICHARD II:\n",
            "What say you will prove this will come to any them?\n",
            "\n",
            "BISHOP OF ELY:\n",
            "What say you think?\n",
            "\n",
            "GLOUCESTER:\n",
            "\n",
            "Ghost of GARNE:\n",
            "\n",
            "Ghost of Ghost of of Gloucester the house\n",
            "of Gloucester of Gloucester house of the hand.\n",
            "\n",
            "Ghost of GGORY:\n",
            "Thou shalt have these thou stands of men\n",
            "Thy slain to him and him of the house of a doint:\n",
            "Which the was stay with my courteous to be death.\n",
            "\n",
            "HENRY BOLINGBROKE:\n",
            "She did not sh\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VPr8m4cMf6Aa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}