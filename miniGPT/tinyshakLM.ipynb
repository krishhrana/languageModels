{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0OQVdtmF0VS",
        "outputId": "3c2a4559-981f-414f-e517-1c71935992c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-10-04 16:57:41--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2023-10-04 16:57:42 (23.8 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7qKK114cKQi",
        "outputId": "0d1ed6be-7016-47ba-a7b8-eaffb13cad0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchsummaryX\n",
            "  Downloading torchsummaryX-1.3.0-py3-none-any.whl (3.6 kB)\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.15.11-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchsummaryX) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchsummaryX) (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from torchsummaryX) (1.5.3)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.37-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.0/190.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.31.0-py2.py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.8/224.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Collecting pathtools (from wandb)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->torchsummaryX) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->torchsummaryX) (2023.3.post1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchsummaryX) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchsummaryX) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchsummaryX) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchsummaryX) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchsummaryX) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchsummaryX) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchsummaryX) (3.27.5)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchsummaryX) (17.0.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchsummaryX) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchsummaryX) (1.3.0)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=0fd5de308ae320a3f56dbcdac7c1d82335c72f162bcabcf941f3eccfb279e851\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb, torchsummaryX\n",
            "Successfully installed GitPython-3.1.37 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.31.0 setproctitle-1.3.3 smmap-5.0.1 torchsummaryX-1.3.0 wandb-0.15.11\n"
          ]
        }
      ],
      "source": [
        "!pip install torchsummaryX wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipk92L2tEDKB",
        "outputId": "dbb3300b-245e-4fab-b647-3b412435ebb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNgc2JFotW2e"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPOCSCdc8m63"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import wandb\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3-KGlKJF-Sq",
        "outputId": "3caaa144-0de3-45f5-944c-e5eee5851405"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1115394\n"
          ]
        }
      ],
      "source": [
        "with open('input.txt', 'r') as f:\n",
        "    text = f.read()\n",
        "\n",
        "print(len(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1Gu_xIHGHen",
        "outputId": "3ff94f7c-f7fb-4ec0-f1fa-c8145d8ada60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "65\n"
          ]
        }
      ],
      "source": [
        "vocabulary = sorted(list(set(text)))\n",
        "vocab_size = len(vocabulary)\n",
        "print(vocabulary)\n",
        "print(vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b82YdqnFGX7I",
        "outputId": "7271fb61-832b-44a5-eb4e-bd7b3fcdc7aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[20, 47, 1, 58, 46, 43, 56, 43, 2]\n",
            "Hi there!\n"
          ]
        }
      ],
      "source": [
        "vocab_to_int = {v:i for i, v in enumerate(vocabulary)}\n",
        "int_to_vocab = {i:v for i, v in enumerate(vocabulary)}\n",
        "\n",
        "encode = lambda x: [vocab_to_int[i] for i in x]\n",
        "decode = lambda x: \"\".join([int_to_vocab[i] for i in x])\n",
        "\n",
        "enc_text = \"Hi there!\"\n",
        "enc = encode(enc_text)\n",
        "dec = decode(enc)\n",
        "print(enc)\n",
        "print(dec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "B0HRWqZWota-",
        "outputId": "fd1b7f4b-3518-4eda-8b69-4b67cda64e37"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Hi there!'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "decode([20, 47, 1, 58, 46, 43, 56, 43, 2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjajDl5TPGL1"
      },
      "outputs": [],
      "source": [
        "dataset = torch.tensor(encode(text), dtype = torch.long)\n",
        "train_data = dataset[:int(0.9 * len(dataset))]\n",
        "val_data = dataset[int(0.9 * len(dataset)): int(0.97 * len(dataset))]\n",
        "test_data = dataset[int(0.97 * len(dataset)): ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9Bx6PEctfhc"
      },
      "outputs": [],
      "source": [
        "class ShaksphereDataLoader(torch.utils.data.DataLoader):\n",
        "    def __init__(self, dataset, seq_len, batch_size):\n",
        "        self.dataset = dataset\n",
        "        self.seq_len = seq_len\n",
        "        self.batch_size = batch_size\n",
        "        self.sub_seq = (len(dataset) // self.seq_len)\n",
        "        self.num_batches = self.sub_seq // self.batch_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_batches\n",
        "\n",
        "    def __iter__(self):\n",
        "        offsets = torch.randperm(len(self.dataset) - self.seq_len)[:self.sub_seq]\n",
        "        inputs = torch.stack([self.dataset[i: i + self.seq_len] for i in offsets])\n",
        "        outputs = torch.stack([self.dataset[i + 1: i + 1 + self.seq_len] for i in offsets])\n",
        "        rem = inputs.shape[0] % self.batch_size\n",
        "        if rem != 0:\n",
        "            inputs = inputs[:-rem, :].reshape(self.num_batches, self.batch_size, self.seq_len)\n",
        "            outputs = outputs[:-rem, :].reshape(self.num_batches, self.batch_size, self.seq_len)\n",
        "        else:\n",
        "            inputs = inputs.reshape(self.num_batches, self.batch_size, self.seq_len)\n",
        "            outputs = outputs.reshape(self.num_batches, self.batch_size, self.seq_len)\n",
        "\n",
        "        batch_idx = 0\n",
        "        while batch_idx < self.num_batches:\n",
        "            yield inputs[batch_idx, : , :].to(device), outputs[batch_idx, :, :].to(device)\n",
        "            batch_idx = batch_idx + 1\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCvKqVdagWEV"
      },
      "outputs": [],
      "source": [
        "ModelConfig = {\n",
        "    'seq_len': 256,\n",
        "    \"batch_size\": 128,\n",
        "    'embed_dim': 512,\n",
        "    'qk_dim': 512\n",
        "}\n",
        "\n",
        "seq_len = ModelConfig['seq_len']\n",
        "batch_size = ModelConfig['batch_size']\n",
        "embed_dim = ModelConfig['embed_dim']\n",
        "qk_dim = ModelConfig['qk_dim']\n",
        "value_dim = ModelConfig['embed_dim']\n",
        "model_size = ModelConfig['embed_dim']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4KsyXeWwTFT",
        "outputId": "d6aa0c5f-c58b-4aef-e06b-8038f2ccc51a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "30\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "train_loader = ShaksphereDataLoader(train_data, seq_len = ModelConfig['seq_len'], batch_size = ModelConfig['batch_size'])\n",
        "val_loader = ShaksphereDataLoader(val_data, seq_len = ModelConfig['seq_len'], batch_size = ModelConfig['batch_size'])\n",
        "print(len(train_loader))\n",
        "print(len(val_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8PbJU1CPGTE",
        "outputId": "e70311ee-f064-4e07-880b-f5c15efb4d9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128, 256])\n",
            "torch.Size([128, 256])\n"
          ]
        }
      ],
      "source": [
        "for i in train_loader:\n",
        "    x, y = i[0], i[1]\n",
        "    break\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElD9FCq3reSB",
        "outputId": "fddcdf44-267d-4ce6-ac3c-10f02311659b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n",
            "cpu\n"
          ]
        }
      ],
      "source": [
        "print(x.device)\n",
        "print(y.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VC6Ulm-z061"
      },
      "outputs": [],
      "source": [
        "class MaskedAttention(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.query_layer = torch.nn.Linear(embed_dim, embed_dim, bias = False)\n",
        "        self.key_layer = torch.nn.Linear(embed_dim, qk_dim, bias = False)\n",
        "        self.value_layer = torch.nn.Linear(embed_dim, value_dim, bias = False)\n",
        "        self.mask = torch.tril(torch.ones(seq_len, seq_len)).to(device)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, tok_embeddings, return_attention_weights = False):\n",
        "        B, T, C = tok_embeddings.shape\n",
        "        Q = self.query_layer(tok_embeddings) # (B, T, qk)\n",
        "        K = self.key_layer(tok_embeddings)   # (B, T, qk)\n",
        "        V = self.value_layer(tok_embeddings) # (B, T, v)\n",
        "\n",
        "        affinities = (Q @ K.transpose(-1, -2)) * K.shape[-1] ** -0.5 # (B, T, T)\n",
        "        affinities = affinities.masked_fill(self.mask[:T, :T] == 0, float('-inf'))\n",
        "\n",
        "        attention_weights = F.softmax(affinities, dim = -1) # (B, T, T)\n",
        "\n",
        "        if return_attention_weights:\n",
        "            return attention_weights @ V, attention_weights\n",
        "        return attention_weights @ V  # (B, T, v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qe23hrp2BHIp"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(torch.nn.Module):\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.head_size = head_size\n",
        "        self.mini_head_size = int(self.head_size / self.num_heads)\n",
        "\n",
        "        self.query = torch.nn.Linear(embed_dim, self.head_size)\n",
        "        self.key = torch.nn.Linear(embed_dim, self.head_size)\n",
        "        self.value = torch.nn.Linear(embed_dim, self.head_size)\n",
        "        self.up_project = torch.nn.Linear(self.num_heads * self.mini_head_size, head_size)\n",
        "        self.mask = torch.tril(torch.ones(seq_len, seq_len)).to(device)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, tok_embeddings, return_attention_weights = False):\n",
        "        B, T, C = tok_embeddings.shape\n",
        "        Q = self.query(tok_embeddings)\n",
        "        K = self.key(tok_embeddings)\n",
        "        V = self.value(tok_embeddings)\n",
        "\n",
        "        # Reshape into N sub heads for parallel processing\n",
        "        mini_Q = Q.view(B, T, self.num_heads, self.mini_head_size).permute(0, 2, 1, 3) # (B, nh, T, mini_head)\n",
        "        mini_K = K.view(B, T, self.num_heads, self.mini_head_size).permute(0, 2, 1, 3) # (B, nh, T, mini_head)\n",
        "        mini_V = V.view(B, T, self.num_heads, self.mini_head_size).permute(0, 2, 1, 3) # (B, nh, T, mini_head)\n",
        "\n",
        "        # Scaled dot Product\n",
        "        affinities = (mini_Q @ mini_K.transpose(-1, -2)) * (self.mini_head_size ** -0.5) #  (B, nh, T, T)\n",
        "        # Makes it causal decoder\n",
        "        affinities = affinities.masked_fill(self.mask[:T, :T] == 0, float(\"-inf\"))\n",
        "        attention_weights = F.softmax(affinities, dim = -1) # (B, nh, T, T)\n",
        "\n",
        "        # weighted vlaues for each head\n",
        "        mini_head_weighted_values = attention_weights @ mini_V # (B, nh, T, mini_head)\n",
        "        # Concatenating each mini_head outputs\n",
        "        mini_head_weighted_values = mini_head_weighted_values.permute(0, 2, 1, 3)\n",
        "        head_weighted_values = mini_head_weighted_values.reshape(B, T, self.mini_head_size * self.num_heads) # (B, T, head_size)\n",
        "\n",
        "        if return_attention_weights:\n",
        "            return self.up_project(head_weighted_values), attention_weights\n",
        "        return self.up_project(head_weighted_values) # (B, T, head_size)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72653NNeNqAZ"
      },
      "outputs": [],
      "source": [
        "class DecoderBlock(torch.nn.Module):\n",
        "    def __init__(self, num_heads):\n",
        "        super().__init__()\n",
        "        self.attention = MultiHeadAttention(num_heads=num_heads, head_size=model_size)\n",
        "        self.layer_norm_1 = torch.nn.LayerNorm(model_size)\n",
        "        self.linear_1 = torch.nn.Linear(model_size, model_size)\n",
        "        self.linear_2 = torch.nn.Linear(model_size, model_size)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.layer_norm_2 = torch.nn.LayerNorm(model_size)\n",
        "        self.dropout_1 = torch.nn.Dropout(0.1)\n",
        "        self.dropout_2 = torch.nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, embeddings, return_attention_weights = False):\n",
        "        # tokens ---> (B, T, embed_size)\n",
        "        B, T, C = embeddings.shape\n",
        "\n",
        "        # Attention\n",
        "        if return_attention_weights:\n",
        "            weighted_values, attention_weights = self.attention.forward(embeddings, return_attention_weights)\n",
        "        else:\n",
        "            weighted_values = self.attention.forward(embeddings) # (B, T, embed_dim)\n",
        "\n",
        "        # Attention Norm + dropout\n",
        "        weighted_values_drp = self.dropout_1(weighted_values)\n",
        "        norm_values = self.layer_norm_1(weighted_values_drp + embeddings) # (B, T, embed_dim)\n",
        "\n",
        "        # FFN + dropout\n",
        "        linear_1 = self.linear_1(norm_values)\n",
        "        act_vals = self.relu(linear_1)\n",
        "        linear_2 = self.linear_2(act_vals)\n",
        "        linear_2_drp = self.dropout_2(linear_2)\n",
        "\n",
        "        # LayerNorm\n",
        "        ffn_norm = self.layer_norm_2(norm_values + linear_2_drp) # (B, T, embed_dim)\n",
        "\n",
        "\n",
        "        if return_attention_weights:\n",
        "            return ffn_norm, attention_weights\n",
        "        return ffn_norm # (B, T, embed_dim)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CibOSqOQTL4q"
      },
      "outputs": [],
      "source": [
        "class LanguageModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.embedding_layer = torch.nn.Embedding(vocab_size, embed_dim)\n",
        "        self.positional_embedding = torch.nn.Embedding(seq_len, embed_dim)\n",
        "        self.dropout_0 = torch.nn.Dropout(0.1)\n",
        "        self.decoder_block_1 = DecoderBlock(num_heads=8)\n",
        "        self.decoder_block_2 = DecoderBlock(num_heads=8)\n",
        "        self.decoder_block_3 = DecoderBlock(num_heads=8)\n",
        "\n",
        "        self.projection = torch.nn.Linear(model_size, vocab_size)\n",
        "        self.projection.weight = self.embedding_layer.weight\n",
        "\n",
        "    def forward(self, tokens, return_attention_weights = False):\n",
        "        B, T = tokens.shape\n",
        "        # Token and Positional Embeddings + dropout\n",
        "        tok_embs = self.embedding_layer(tokens) # (B, T, embed_dim)\n",
        "        pos_embs = self.positional_embedding(torch.arange(T).to(device))\n",
        "        pos_tok_embs = tok_embs + pos_embs # (B, T, embed_dim)\n",
        "        pos_tok_embs_drp = self.dropout_0(pos_tok_embs)\n",
        "\n",
        "        # Decoder Blocks\n",
        "        decoder_1 = self.decoder_block_1.forward(pos_tok_embs)\n",
        "        decoder_2 = self.decoder_block_2.forward(decoder_1)\n",
        "        if return_attention_weights:\n",
        "            decoder_3, last_layer_attention_weights = self.decoder_block_3.forward(decoder_2, return_attention_weights=True)\n",
        "        else:\n",
        "            decoder_3 = self.decoder_block_3.forward(decoder_2)\n",
        "\n",
        "        # projection layer\n",
        "        logits = self.projection(decoder_3) # (B, T, vocab_size)\n",
        "\n",
        "        if return_attention_weights:\n",
        "            return logits, last_layer_attention_weights\n",
        "        return logits # (B, T, vocab_size)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fllG6UIz-kMK",
        "outputId": "b694eb1b-32e7-45cb-d528-57ce0a81cb8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=================================================================================================\n",
            "                                               Kernel Shape     Output Shape  \\\n",
            "Layer                                                                          \n",
            "0_embedding_layer                                 [512, 65]  [128, 256, 512]   \n",
            "1_positional_embedding                           [512, 256]       [256, 512]   \n",
            "2_dropout_0                                               -  [128, 256, 512]   \n",
            "3_decoder_block_1.attention.Linear_query         [512, 512]  [128, 256, 512]   \n",
            "4_decoder_block_1.attention.Linear_key           [512, 512]  [128, 256, 512]   \n",
            "5_decoder_block_1.attention.Linear_value         [512, 512]  [128, 256, 512]   \n",
            "6_decoder_block_1.attention.Linear_up_project    [512, 512]  [128, 256, 512]   \n",
            "7_decoder_block_1.Dropout_dropout_1                       -  [128, 256, 512]   \n",
            "8_decoder_block_1.LayerNorm_layer_norm_1              [512]  [128, 256, 512]   \n",
            "9_decoder_block_1.Linear_linear_1                [512, 512]  [128, 256, 512]   \n",
            "10_decoder_block_1.ReLU_relu                              -  [128, 256, 512]   \n",
            "11_decoder_block_1.Linear_linear_2               [512, 512]  [128, 256, 512]   \n",
            "12_decoder_block_1.Dropout_dropout_2                      -  [128, 256, 512]   \n",
            "13_decoder_block_1.LayerNorm_layer_norm_2             [512]  [128, 256, 512]   \n",
            "14_decoder_block_2.attention.Linear_query        [512, 512]  [128, 256, 512]   \n",
            "15_decoder_block_2.attention.Linear_key          [512, 512]  [128, 256, 512]   \n",
            "16_decoder_block_2.attention.Linear_value        [512, 512]  [128, 256, 512]   \n",
            "17_decoder_block_2.attention.Linear_up_project   [512, 512]  [128, 256, 512]   \n",
            "18_decoder_block_2.Dropout_dropout_1                      -  [128, 256, 512]   \n",
            "19_decoder_block_2.LayerNorm_layer_norm_1             [512]  [128, 256, 512]   \n",
            "20_decoder_block_2.Linear_linear_1               [512, 512]  [128, 256, 512]   \n",
            "21_decoder_block_2.ReLU_relu                              -  [128, 256, 512]   \n",
            "22_decoder_block_2.Linear_linear_2               [512, 512]  [128, 256, 512]   \n",
            "23_decoder_block_2.Dropout_dropout_2                      -  [128, 256, 512]   \n",
            "24_decoder_block_2.LayerNorm_layer_norm_2             [512]  [128, 256, 512]   \n",
            "25_decoder_block_3.attention.Linear_query        [512, 512]  [128, 256, 512]   \n",
            "26_decoder_block_3.attention.Linear_key          [512, 512]  [128, 256, 512]   \n",
            "27_decoder_block_3.attention.Linear_value        [512, 512]  [128, 256, 512]   \n",
            "28_decoder_block_3.attention.Linear_up_project   [512, 512]  [128, 256, 512]   \n",
            "29_decoder_block_3.Dropout_dropout_1                      -  [128, 256, 512]   \n",
            "30_decoder_block_3.LayerNorm_layer_norm_1             [512]  [128, 256, 512]   \n",
            "31_decoder_block_3.Linear_linear_1               [512, 512]  [128, 256, 512]   \n",
            "32_decoder_block_3.ReLU_relu                              -  [128, 256, 512]   \n",
            "33_decoder_block_3.Linear_linear_2               [512, 512]  [128, 256, 512]   \n",
            "34_decoder_block_3.Dropout_dropout_2                      -  [128, 256, 512]   \n",
            "35_decoder_block_3.LayerNorm_layer_norm_2             [512]  [128, 256, 512]   \n",
            "36_projection                                     [512, 65]   [128, 256, 65]   \n",
            "\n",
            "                                                  Params Mult-Adds  \n",
            "Layer                                                               \n",
            "0_embedding_layer                                 33.28k    33.28k  \n",
            "1_positional_embedding                          131.072k  131.072k  \n",
            "2_dropout_0                                            -         -  \n",
            "3_decoder_block_1.attention.Linear_query        262.656k  262.144k  \n",
            "4_decoder_block_1.attention.Linear_key          262.656k  262.144k  \n",
            "5_decoder_block_1.attention.Linear_value        262.656k  262.144k  \n",
            "6_decoder_block_1.attention.Linear_up_project   262.656k  262.144k  \n",
            "7_decoder_block_1.Dropout_dropout_1                    -         -  \n",
            "8_decoder_block_1.LayerNorm_layer_norm_1          1.024k     512.0  \n",
            "9_decoder_block_1.Linear_linear_1               262.656k  262.144k  \n",
            "10_decoder_block_1.ReLU_relu                           -         -  \n",
            "11_decoder_block_1.Linear_linear_2              262.656k  262.144k  \n",
            "12_decoder_block_1.Dropout_dropout_2                   -         -  \n",
            "13_decoder_block_1.LayerNorm_layer_norm_2         1.024k     512.0  \n",
            "14_decoder_block_2.attention.Linear_query       262.656k  262.144k  \n",
            "15_decoder_block_2.attention.Linear_key         262.656k  262.144k  \n",
            "16_decoder_block_2.attention.Linear_value       262.656k  262.144k  \n",
            "17_decoder_block_2.attention.Linear_up_project  262.656k  262.144k  \n",
            "18_decoder_block_2.Dropout_dropout_1                   -         -  \n",
            "19_decoder_block_2.LayerNorm_layer_norm_1         1.024k     512.0  \n",
            "20_decoder_block_2.Linear_linear_1              262.656k  262.144k  \n",
            "21_decoder_block_2.ReLU_relu                           -         -  \n",
            "22_decoder_block_2.Linear_linear_2              262.656k  262.144k  \n",
            "23_decoder_block_2.Dropout_dropout_2                   -         -  \n",
            "24_decoder_block_2.LayerNorm_layer_norm_2         1.024k     512.0  \n",
            "25_decoder_block_3.attention.Linear_query       262.656k  262.144k  \n",
            "26_decoder_block_3.attention.Linear_key         262.656k  262.144k  \n",
            "27_decoder_block_3.attention.Linear_value       262.656k  262.144k  \n",
            "28_decoder_block_3.attention.Linear_up_project  262.656k  262.144k  \n",
            "29_decoder_block_3.Dropout_dropout_1                   -         -  \n",
            "30_decoder_block_3.LayerNorm_layer_norm_1         1.024k     512.0  \n",
            "31_decoder_block_3.Linear_linear_1              262.656k  262.144k  \n",
            "32_decoder_block_3.ReLU_relu                           -         -  \n",
            "33_decoder_block_3.Linear_linear_2              262.656k  262.144k  \n",
            "34_decoder_block_3.Dropout_dropout_2                   -         -  \n",
            "35_decoder_block_3.LayerNorm_layer_norm_2         1.024k     512.0  \n",
            "36_projection                                    33.345k    33.28k  \n",
            "-------------------------------------------------------------------------------------------------\n",
            "                         Totals\n",
            "Total params          4.931649M\n",
            "Trainable params      4.931649M\n",
            "Non-trainable params        0.0\n",
            "Mult-Adds             4.919296M\n",
            "=================================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchsummaryX/torchsummaryX.py:101: FutureWarning: The default value of numeric_only in DataFrame.sum is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
            "  df_sum = df.sum()\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-16045281-9929-4897-832a-a429929ef616\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Kernel Shape</th>\n",
              "      <th>Output Shape</th>\n",
              "      <th>Params</th>\n",
              "      <th>Mult-Adds</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Layer</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0_embedding_layer</th>\n",
              "      <td>[512, 65]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>33280.0</td>\n",
              "      <td>33280.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1_positional_embedding</th>\n",
              "      <td>[512, 256]</td>\n",
              "      <td>[256, 512]</td>\n",
              "      <td>131072.0</td>\n",
              "      <td>131072.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2_dropout_0</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3_decoder_block_1.attention.Linear_query</th>\n",
              "      <td>[512, 512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>262656.0</td>\n",
              "      <td>262144.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_decoder_block_1.attention.Linear_key</th>\n",
              "      <td>[512, 512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>262656.0</td>\n",
              "      <td>262144.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_decoder_block_1.attention.Linear_value</th>\n",
              "      <td>[512, 512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>262656.0</td>\n",
              "      <td>262144.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6_decoder_block_1.attention.Linear_up_project</th>\n",
              "      <td>[512, 512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>262656.0</td>\n",
              "      <td>262144.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7_decoder_block_1.Dropout_dropout_1</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8_decoder_block_1.LayerNorm_layer_norm_1</th>\n",
              "      <td>[512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>512.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9_decoder_block_1.Linear_linear_1</th>\n",
              "      <td>[512, 512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>262656.0</td>\n",
              "      <td>262144.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10_decoder_block_1.ReLU_relu</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11_decoder_block_1.Linear_linear_2</th>\n",
              "      <td>[512, 512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>262656.0</td>\n",
              "      <td>262144.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12_decoder_block_1.Dropout_dropout_2</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13_decoder_block_1.LayerNorm_layer_norm_2</th>\n",
              "      <td>[512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>512.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14_decoder_block_2.attention.Linear_query</th>\n",
              "      <td>[512, 512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>262656.0</td>\n",
              "      <td>262144.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15_decoder_block_2.attention.Linear_key</th>\n",
              "      <td>[512, 512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>262656.0</td>\n",
              "      <td>262144.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16_decoder_block_2.attention.Linear_value</th>\n",
              "      <td>[512, 512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>262656.0</td>\n",
              "      <td>262144.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17_decoder_block_2.attention.Linear_up_project</th>\n",
              "      <td>[512, 512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>262656.0</td>\n",
              "      <td>262144.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18_decoder_block_2.Dropout_dropout_1</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19_decoder_block_2.LayerNorm_layer_norm_1</th>\n",
              "      <td>[512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>512.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20_decoder_block_2.Linear_linear_1</th>\n",
              "      <td>[512, 512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>262656.0</td>\n",
              "      <td>262144.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21_decoder_block_2.ReLU_relu</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22_decoder_block_2.Linear_linear_2</th>\n",
              "      <td>[512, 512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>262656.0</td>\n",
              "      <td>262144.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23_decoder_block_2.Dropout_dropout_2</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24_decoder_block_2.LayerNorm_layer_norm_2</th>\n",
              "      <td>[512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>512.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25_decoder_block_3.attention.Linear_query</th>\n",
              "      <td>[512, 512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>262656.0</td>\n",
              "      <td>262144.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26_decoder_block_3.attention.Linear_key</th>\n",
              "      <td>[512, 512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>262656.0</td>\n",
              "      <td>262144.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27_decoder_block_3.attention.Linear_value</th>\n",
              "      <td>[512, 512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>262656.0</td>\n",
              "      <td>262144.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28_decoder_block_3.attention.Linear_up_project</th>\n",
              "      <td>[512, 512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>262656.0</td>\n",
              "      <td>262144.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29_decoder_block_3.Dropout_dropout_1</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30_decoder_block_3.LayerNorm_layer_norm_1</th>\n",
              "      <td>[512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>512.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31_decoder_block_3.Linear_linear_1</th>\n",
              "      <td>[512, 512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>262656.0</td>\n",
              "      <td>262144.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32_decoder_block_3.ReLU_relu</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33_decoder_block_3.Linear_linear_2</th>\n",
              "      <td>[512, 512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>262656.0</td>\n",
              "      <td>262144.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34_decoder_block_3.Dropout_dropout_2</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35_decoder_block_3.LayerNorm_layer_norm_2</th>\n",
              "      <td>[512]</td>\n",
              "      <td>[128, 256, 512]</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>512.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36_projection</th>\n",
              "      <td>[512, 65]</td>\n",
              "      <td>[128, 256, 65]</td>\n",
              "      <td>33345.0</td>\n",
              "      <td>33280.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16045281-9929-4897-832a-a429929ef616')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-16045281-9929-4897-832a-a429929ef616 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-16045281-9929-4897-832a-a429929ef616');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b1720b02-6cd6-468d-b997-57bfb51d91d3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b1720b02-6cd6-468d-b997-57bfb51d91d3')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b1720b02-6cd6-468d-b997-57bfb51d91d3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                               Kernel Shape     Output Shape  \\\n",
              "Layer                                                                          \n",
              "0_embedding_layer                                 [512, 65]  [128, 256, 512]   \n",
              "1_positional_embedding                           [512, 256]       [256, 512]   \n",
              "2_dropout_0                                               -  [128, 256, 512]   \n",
              "3_decoder_block_1.attention.Linear_query         [512, 512]  [128, 256, 512]   \n",
              "4_decoder_block_1.attention.Linear_key           [512, 512]  [128, 256, 512]   \n",
              "5_decoder_block_1.attention.Linear_value         [512, 512]  [128, 256, 512]   \n",
              "6_decoder_block_1.attention.Linear_up_project    [512, 512]  [128, 256, 512]   \n",
              "7_decoder_block_1.Dropout_dropout_1                       -  [128, 256, 512]   \n",
              "8_decoder_block_1.LayerNorm_layer_norm_1              [512]  [128, 256, 512]   \n",
              "9_decoder_block_1.Linear_linear_1                [512, 512]  [128, 256, 512]   \n",
              "10_decoder_block_1.ReLU_relu                              -  [128, 256, 512]   \n",
              "11_decoder_block_1.Linear_linear_2               [512, 512]  [128, 256, 512]   \n",
              "12_decoder_block_1.Dropout_dropout_2                      -  [128, 256, 512]   \n",
              "13_decoder_block_1.LayerNorm_layer_norm_2             [512]  [128, 256, 512]   \n",
              "14_decoder_block_2.attention.Linear_query        [512, 512]  [128, 256, 512]   \n",
              "15_decoder_block_2.attention.Linear_key          [512, 512]  [128, 256, 512]   \n",
              "16_decoder_block_2.attention.Linear_value        [512, 512]  [128, 256, 512]   \n",
              "17_decoder_block_2.attention.Linear_up_project   [512, 512]  [128, 256, 512]   \n",
              "18_decoder_block_2.Dropout_dropout_1                      -  [128, 256, 512]   \n",
              "19_decoder_block_2.LayerNorm_layer_norm_1             [512]  [128, 256, 512]   \n",
              "20_decoder_block_2.Linear_linear_1               [512, 512]  [128, 256, 512]   \n",
              "21_decoder_block_2.ReLU_relu                              -  [128, 256, 512]   \n",
              "22_decoder_block_2.Linear_linear_2               [512, 512]  [128, 256, 512]   \n",
              "23_decoder_block_2.Dropout_dropout_2                      -  [128, 256, 512]   \n",
              "24_decoder_block_2.LayerNorm_layer_norm_2             [512]  [128, 256, 512]   \n",
              "25_decoder_block_3.attention.Linear_query        [512, 512]  [128, 256, 512]   \n",
              "26_decoder_block_3.attention.Linear_key          [512, 512]  [128, 256, 512]   \n",
              "27_decoder_block_3.attention.Linear_value        [512, 512]  [128, 256, 512]   \n",
              "28_decoder_block_3.attention.Linear_up_project   [512, 512]  [128, 256, 512]   \n",
              "29_decoder_block_3.Dropout_dropout_1                      -  [128, 256, 512]   \n",
              "30_decoder_block_3.LayerNorm_layer_norm_1             [512]  [128, 256, 512]   \n",
              "31_decoder_block_3.Linear_linear_1               [512, 512]  [128, 256, 512]   \n",
              "32_decoder_block_3.ReLU_relu                              -  [128, 256, 512]   \n",
              "33_decoder_block_3.Linear_linear_2               [512, 512]  [128, 256, 512]   \n",
              "34_decoder_block_3.Dropout_dropout_2                      -  [128, 256, 512]   \n",
              "35_decoder_block_3.LayerNorm_layer_norm_2             [512]  [128, 256, 512]   \n",
              "36_projection                                     [512, 65]   [128, 256, 65]   \n",
              "\n",
              "                                                  Params  Mult-Adds  \n",
              "Layer                                                                \n",
              "0_embedding_layer                                33280.0    33280.0  \n",
              "1_positional_embedding                          131072.0   131072.0  \n",
              "2_dropout_0                                          NaN        NaN  \n",
              "3_decoder_block_1.attention.Linear_query        262656.0   262144.0  \n",
              "4_decoder_block_1.attention.Linear_key          262656.0   262144.0  \n",
              "5_decoder_block_1.attention.Linear_value        262656.0   262144.0  \n",
              "6_decoder_block_1.attention.Linear_up_project   262656.0   262144.0  \n",
              "7_decoder_block_1.Dropout_dropout_1                  NaN        NaN  \n",
              "8_decoder_block_1.LayerNorm_layer_norm_1          1024.0      512.0  \n",
              "9_decoder_block_1.Linear_linear_1               262656.0   262144.0  \n",
              "10_decoder_block_1.ReLU_relu                         NaN        NaN  \n",
              "11_decoder_block_1.Linear_linear_2              262656.0   262144.0  \n",
              "12_decoder_block_1.Dropout_dropout_2                 NaN        NaN  \n",
              "13_decoder_block_1.LayerNorm_layer_norm_2         1024.0      512.0  \n",
              "14_decoder_block_2.attention.Linear_query       262656.0   262144.0  \n",
              "15_decoder_block_2.attention.Linear_key         262656.0   262144.0  \n",
              "16_decoder_block_2.attention.Linear_value       262656.0   262144.0  \n",
              "17_decoder_block_2.attention.Linear_up_project  262656.0   262144.0  \n",
              "18_decoder_block_2.Dropout_dropout_1                 NaN        NaN  \n",
              "19_decoder_block_2.LayerNorm_layer_norm_1         1024.0      512.0  \n",
              "20_decoder_block_2.Linear_linear_1              262656.0   262144.0  \n",
              "21_decoder_block_2.ReLU_relu                         NaN        NaN  \n",
              "22_decoder_block_2.Linear_linear_2              262656.0   262144.0  \n",
              "23_decoder_block_2.Dropout_dropout_2                 NaN        NaN  \n",
              "24_decoder_block_2.LayerNorm_layer_norm_2         1024.0      512.0  \n",
              "25_decoder_block_3.attention.Linear_query       262656.0   262144.0  \n",
              "26_decoder_block_3.attention.Linear_key         262656.0   262144.0  \n",
              "27_decoder_block_3.attention.Linear_value       262656.0   262144.0  \n",
              "28_decoder_block_3.attention.Linear_up_project  262656.0   262144.0  \n",
              "29_decoder_block_3.Dropout_dropout_1                 NaN        NaN  \n",
              "30_decoder_block_3.LayerNorm_layer_norm_1         1024.0      512.0  \n",
              "31_decoder_block_3.Linear_linear_1              262656.0   262144.0  \n",
              "32_decoder_block_3.ReLU_relu                         NaN        NaN  \n",
              "33_decoder_block_3.Linear_linear_2              262656.0   262144.0  \n",
              "34_decoder_block_3.Dropout_dropout_2                 NaN        NaN  \n",
              "35_decoder_block_3.LayerNorm_layer_norm_2         1024.0      512.0  \n",
              "36_projection                                    33345.0    33280.0  "
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torchsummaryX import summary\n",
        "model = LanguageModel()\n",
        "model.to(device)\n",
        "#model.load_state_dict(torch.load('/content/drive/MyDrive/ShakGPT_3_512.pt', map_location = device))\n",
        "summary(model, x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIqFrxOjexh-",
        "outputId": "33c8c875-6598-4c23-8860-2a557edc21d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128, 256, 65])\n",
            "torch.Size([32768, 65])\n"
          ]
        }
      ],
      "source": [
        "#x, y = get_batch('train')\n",
        "logits, attention_weights = model.forward(x, return_attention_weights=True)\n",
        "print(logits.shape)\n",
        "B, T, vocab_size = logits.shape\n",
        "logits = logits.view(B*T, vocab_size)\n",
        "print(logits.shape)\n",
        "y = y.view(B*T)\n",
        "loss = F.cross_entropy(logits, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOwIedqW6vGd",
        "outputId": "10f1920a-6a1c-406c-d37e-78be514b356f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(1.2572, grad_fn=<NllLossBackward0>)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhU8Y1xbnVyv"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
        "criterion = torch.nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "scheduler =  torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=4) #TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvNgfzVkYqpI"
      },
      "outputs": [],
      "source": [
        "optimizer.param_groups[0]['lr'] = 5e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2hmCO00dJWD"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot(attention_weights):\n",
        "    plt.figure(figsize=(64, 64))\n",
        "    fig, ax = plt.subplots()\n",
        "    cax = ax.matshow(attention_weights[0, 0, :50, :50].detach().cpu().numpy(), cmap='viridis')\n",
        "\n",
        "# Set the axis labels (optional)\n",
        "    ax.set_xticks(np.arange(50))\n",
        "    ax.set_yticks(np.arange(50))\n",
        "    ax.set_xticklabels(decode(x[0][:50].detach().cpu().numpy()))\n",
        "    ax.set_yticklabels(decode(x[0][:50].detach().cpu().numpy()))\n",
        "\n",
        "    # Rotate the tick labels and set their alignment (optional)\n",
        "    plt.setp(ax.get_xticklabels(), rotation=90, ha=\"right\", rotation_mode=\"anchor\")\n",
        "\n",
        "    # Add a colorbar\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "HcO1zS6TonjZ",
        "outputId": "cc8c8ef1-223f-4329-a6c5-d2b7a08d12de"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Figure size 6400x6400 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot(attention_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GA6HkdLy6zXm"
      },
      "outputs": [],
      "source": [
        "class Trainer():\n",
        "    def __init__(self, model, train_loader, val_loader, optimizer, criterion):\n",
        "        self.model = model\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.epoch = 0\n",
        "        self.optimizer = optimizer\n",
        "        self.criterion = criterion\n",
        "        train_loss = 0\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "        for x, y in self.train_loader:\n",
        "            logits, attention_weights = self.model.forward(x, return_attention_weights=True)\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            y = y.view(B*T)\n",
        "            loss = self.criterion(logits, y)\n",
        "            total_loss = total_loss + loss.item()\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "\n",
        "        epoch_loss = total_loss / len(train_loader)\n",
        "        self.epoch = self.epoch + 1\n",
        "        print(f\"Epoch: {self.epoch}\\nTrain Loss: {epoch_loss}, Train Perplexity: {np.exp(epoch_loss)}, LR: {self.optimizer.param_groups[0]['lr']}\")\n",
        "        return epoch_loss\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def validate(self):\n",
        "        self.model.eval()\n",
        "        total_loss = 0\n",
        "        for x, y in self.val_loader:\n",
        "            logits = self.model.forward(x)\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            y = y.view(B*T)\n",
        "            val_loss = self.criterion(logits, y)\n",
        "            total_loss = total_loss + val_loss.item()\n",
        "\n",
        "        epoch_loss = total_loss / len(self.val_loader)\n",
        "        print(f'Validation Loss: {epoch_loss}')\n",
        "        return epoch_loss\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def generate(self, max_tokens, prompt, temperature = 1, top_p = 1):\n",
        "        self.model.eval()\n",
        "        for i in range(max_tokens):\n",
        "            logits = self.model.forward(prompt)\n",
        "            logit = logits[:, -1, :] # (B, C)\n",
        "            logit = logit / temperature\n",
        "            probs = F.softmax(logit, dim = -1)\n",
        "            weighted_probs = self.topPTransform(probs, top_p)\n",
        "            #token = torch.argmax(probs, dim = -1).view(-1, 1)\n",
        "            token = torch.multinomial(weighted_probs, num_samples = 1) # (B, 1)\n",
        "            prompt = torch.cat((prompt, token), dim = -1) # (B, T + 1)\n",
        "        return prompt\n",
        "\n",
        "    def topPTransform(self, probs, top_p):\n",
        "        probs_sorted_vals, probs_sort_idx = torch.sort(probs, descending=True)\n",
        "        prob_cumsum = torch.cumsum(probs_sorted_vals, dim = -1)\n",
        "\n",
        "        absolute_diff = torch.abs(prob_cumsum - top_p)\n",
        "        closest_index = torch.argmin(absolute_diff).item()\n",
        "        idx_to_remove = probs_sort_idx[:, closest_index + 1:]\n",
        "\n",
        "        mask = torch.ones_like(probs)\n",
        "        mask[:, idx_to_remove] = 0\n",
        "\n",
        "        probs = probs * mask\n",
        "        weighted_probs = probs / torch.sum(probs, dim = -1)\n",
        "        return weighted_probs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def save(self, path):\n",
        "        torch.save(self.model.state_dict(), path)\n",
        "        print(\"Model saved at \" + path)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxYfUAJKNpnR"
      },
      "outputs": [],
      "source": [
        "def wandb_config(epochs):\n",
        "        d = dict()\n",
        "        d['epochs'] = epochs\n",
        "        d['lr'] = 1e-4\n",
        "\n",
        "        return d\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4zQ0X0sNymy",
        "outputId": "57f4197d-075d-413f-a4c2-16507874e5e7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login(key=\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "zsRAEBSFN227",
        "outputId": "6ca93067-cc18-4d39-c02f-52be54208bc7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkrana\u001b[0m (\u001b[33mllm-tuning\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.11"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20231004_001820-True</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Resuming run <strong><a href='https://wandb.ai/llm-tuning/shakespeare/runs/True' target=\"_blank\">shakGPT-decoder_3_512</a></strong> to <a href='https://wandb.ai/llm-tuning/shakespeare' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/llm-tuning/shakespeare' target=\"_blank\">https://wandb.ai/llm-tuning/shakespeare</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/llm-tuning/shakespeare/runs/True' target=\"_blank\">https://wandb.ai/llm-tuning/shakespeare/runs/True</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "epochs = 800\n",
        "run = wandb.init(\n",
        "    name = \"shakGPT-decoder_3_512\", ## Wandb creates random run names if you skip this field\n",
        "    #reinit = True, ### Allows reinitalizing runs when you re-run this cell\n",
        "    #run_id = \"hr8c7o0i\", ### Insert specific run id here if you want to resume a previous run\n",
        "    resume = \"True\", ### You need this to resume previous runs, but comment out reinit = True when using this\n",
        "    project = \"shakespeare\", ### Project should be created in your wandb account\n",
        "    config = wandb_config(epochs) ### Wandb Config for your run\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fWiLDswz_KCJ",
        "outputId": "706fbe81-567c-47f6-cf17-6bc903bd9150"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(model = model, train_loader=train_loader, val_loader=val_loader, optimizer=optimizer, criterion = criterion)\n",
        "best_val_loss = float('inf')\n",
        "for epoch in range(epochs):\n",
        "    train_loss = trainer.train()\n",
        "    val_loss = trainer.validate()\n",
        "    #scheduler.step(val_loss)\n",
        "    if val_loss < best_val_loss:\n",
        "        trainer.save('/content/drive/MyDrive/ShakGPT_3_512.pt')\n",
        "        best_val_loss = val_loss\n",
        "    print(\"Generation: \" + decode(trainer.generate(prompt =\n",
        "                            torch.tensor(encode(\"BARNARDO: Who's there?\\nFRANCISCO: Nay, answer me. Stand and unfold yourself.\\nBARNARDO:\")).view(1, -1).to(device),\n",
        "                            max_tokens=170,\n",
        "                            top_p = 0.7)[0].tolist()))\n",
        "    wandb.log({\n",
        "            'train_loss': train_loss,\n",
        "            'val_loss': val_loss,\n",
        "            'lr'        : optimizer.param_groups[0]['lr'],\n",
        "        })\n",
        "\n",
        "    print('\\n')\n",
        "    if epoch == 700:\n",
        "        optimizer.param_groups[0]['lr'] = 1e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HFn3hU0kqcu",
        "outputId": "6af36817-5148-4d9c-a91f-d65f3f0d1e43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ACT I\n",
            "\n",
            "SCENE I. Elsinore. A platform before the Castle.\n",
            "\n",
            "\n",
            "Enter Francisco and Barnardo, two sentinels.\n",
            "\n",
            "KING HENRY VI:\n",
            "Saw you will I know not where I was the defend?\n",
            "\n",
            "HENRY BOLINGBROKE:\n",
            "What you are you makes a gracious face?\n",
            "And that I know not of the world bear you?\n",
            "\n",
            "JOHN OF GAUNT:\n",
            "And with me thee with that strength so trouble to thee,\n",
            "Who should devotion me in means the bear.\n",
            "\n",
            "KING RICHARD II:\n",
            "What say you will prove this will come to any them?\n",
            "\n",
            "BISHOP OF ELY:\n",
            "What say you think?\n",
            "\n",
            "GLOUCESTER:\n",
            "\n",
            "Ghost of GARNE:\n",
            "\n",
            "Ghost of Ghost of of Gloucester the house\n",
            "of Gloucester of Gloucester house of the hand.\n",
            "\n",
            "Ghost of GGORY:\n",
            "Thou shalt have these thou stands of men\n",
            "Thy slain to him and him of the house of a doint:\n",
            "Which the was stay with my courteous to be death.\n",
            "\n",
            "HENRY BOLINGBROKE:\n",
            "She did not sh\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "from random import uniform\n",
        "import time\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "def topPTransform(probs, top_p):\n",
        "        probs_sorted_vals, probs_sort_idx = torch.sort(probs, descending=True)\n",
        "        prob_cumsum = torch.cumsum(probs_sorted_vals, dim = -1)\n",
        "\n",
        "        absolute_diff = torch.abs(prob_cumsum - top_p)\n",
        "        closest_index = torch.argmin(absolute_diff).item()\n",
        "        idx_to_remove = probs_sort_idx[:, closest_index + 1:]\n",
        "\n",
        "        mask = torch.ones_like(probs)\n",
        "        mask[:, idx_to_remove] = 0\n",
        "\n",
        "        probs = probs * mask\n",
        "        weighted_probs = probs / torch.sum(probs, dim = -1)\n",
        "        return weighted_probs\n",
        "\n",
        "def persistent_generation(prompt, max_tokens, temperature = 1, top_p = 1):\n",
        "    generated_text = prompt\n",
        "    model.eval()\n",
        "    tokens = torch.tensor(encode(prompt)).reshape(1, -1).to(device)\n",
        "    buffer = 10\n",
        "    token_count = 0\n",
        "    while token_count < max_tokens:\n",
        "        if tokens.shape[-1] >= seq_len:\n",
        "            tokens = tokens[:, tokens.shape[-1] - seq_len + 10: ]\n",
        "        logits = model.forward(tokens)\n",
        "        logit = logits[:, -1, :] # (B, C)\n",
        "\n",
        "        # temperature\n",
        "        logit = logit / temperature\n",
        "\n",
        "        # top_p\n",
        "        probs = F.softmax(logit, dim = -1) # (B, C)\n",
        "        weighted_probs = topPTransform(probs, top_p)\n",
        "        predicted_token = torch.multinomial(weighted_probs, num_samples = 1) # (B, 1)\n",
        "        generated_text = generated_text + decode(predicted_token[0].cpu().detach().tolist())\n",
        "        tokens = torch.cat((tokens, predicted_token), dim = -1) # (B, T + 1) # (1, 1)\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        print(generated_text)\n",
        "        token_count = token_count + 1\n",
        "\n",
        "        #time.sleep(0.01)\n",
        "\n",
        "print(persistent_generation(\"ACT I\\n\\nSCENE I. Elsinore. A platform before the Castle.\\n\\n\\nEnter Francisco and Barnardo, two sentinels.\", max_tokens = 700, top_p = 0.7))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPr8m4cMf6Aa"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
